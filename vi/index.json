[
{
	"uri": "https://phucdat25.github.io/OJT/vi/",
	"title": "Báo cáo thực tập",
	"tags": [],
	"description": "",
	"content": "Báo cáo thực tập Thông tin sinh viên: Họ và tên: Nguyễn Phúc Đạt\nSố điện thoại: 0584825767\nEmail: datnpse182125@fpt.edu.vn\nTrường: Đại học FPT\nNgành: Công nghệ thông tin\nLớp: AWS082025\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 08/09/2025 đến ngày 08/12/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/3-blogstranslated/3.1-blog1/",
	"title": "Blog 1",
	"tags": [],
	"description": "",
	"content": "Cách Heroku di chuyển hàng trăm nghìn cơ sở dữ liệu PostgreSQL tự quản lý sang Amazon Aurora Bởi: Stefan Pieterse, Rocket (John), Jonathan K. Brown và Justin Downing\nNgày: 10 tháng 4, 2025\nChủ đề: Advanced (300), Amazon Aurora, Customer Solutions, Migration, PostgreSQL compatible\nTrong bài viết này, chúng tôi sẽ thảo luận cách Heroku đã di chuyển multi-tenant PostgreSQL database từ môi trường tự quản lý PostgreSQL trên Amazon Elastic Compute Cloud (Amazon EC2) sang Amazon Aurora PostgreSQL-Compatible Edition. Heroku đã hoàn tất quá trình này mà không gây ảnh hưởng đến khách hàng, đồng thời tăng độ tin cậy nền tảng và giảm gánh nặng vận hành. Chúng tôi sẽ phân tích kiến trúc tự quản lý trước đây, kiến trúc mới, cách hàng trăm nghìn cơ sở dữ liệu được di chuyển, và những cải thiện trong trải nghiệm khách hàng sau khi hoàn tất.\nTổng quan về Heroku Heroku là một nền tảng PaaS (platform as a service) được quản lý hoàn thiện, xây dựng trên Amazon Web Services (AWS), giúp triển khai, vận hành và mở rộng ứng dụng dễ dàng. Heroku được thành lập năm 2007 và được Salesforce mua lại năm 2010. Ngày nay, Heroku là nền tảng được lựa chọn cho hơn 13 triệu ứng dụng, từ các startup nhỏ đến doanh nghiệp có triển khai quy mô lớn.\nHeroku không chỉ đơn giản hóa việc triển khai và mở rộng ứng dụng bằng Dynos (container do Heroku quản lý) mà còn cung cấp các data solution add-ons như Heroku Postgres, Apache Kafka on Heroku, và Heroku Key-Value Store. Các dịch vụ này xử lý bảo mật, vá lỗi server, failovers, backups và các cấu hình phức tạp khác, giúp khách hàng tập trung phát triển ứng dụng thay vì quản lý hạ tầng dữ liệu. Tất cả các add-on của Heroku Data Services có thể được provision chỉ bằng một lệnh CLI hoặc click, tăng tính tích hợp, độ tin cậy và khả năng mở rộng.\nMột trong những add-on là Heroku Postgres — cung cấp cơ sở dữ liệu PostgreSQL có khả năng mở rộng, chi phí hợp lý, backup tự động, quản lý, tối ưu hiệu suất và tất cả những gì cần để vận hành database. Ví dụ Heroku Connect cho phép đồng bộ hóa dữ liệu Salesforce với Heroku Postgres một cách liền mạch.\nĐể giữ ứng dụng của khách hàng vận hành ổn định, Heroku phải đầu tư lớn. Đầu năm 2025, đội ngũ Heroku Data Services đã di chuyển dịch vụ Heroku Postgres Essential từ môi trường self-managed trên Amazon EC2 sang Amazon Aurora, loại bỏ gánh nặng vận hành và cho phép kỹ sư tập trung vào đổi mới.\nKiến trúc PostgreSQL tự quản lý trước đây và những thách thức Sơ đồ dưới đây minh họa kiến trúc cũ của Heroku:\nNhóm Heroku Data điều hành nhiều control plane để quản lý tài nguyên khách hàng. Khi một khách hàng tạo add-on Heroku Postgres, control plane gửi các API request tới AWS để tạo VPC, EC2 instances, Amazon Elastic Block Store (Amazon EBS) volumes, và Amazon Simple Storage Service (S3) paths theo yêu cầu gói add-on.\nKhi hạ tầng sẵn sàng, control plane thiết lập dịch vụ PostgreSQL và quản lý timeline, credentials, và continuous protection. Heroku có tự động hóa để kết nối vào các instance, đặt file cấu hình và thực thi lệnh để hoàn thành setup database. Khi database hoạt động, họ đẩy thông tin connection string vào cấu hình ứng dụng. Sau đó, control plane giám sát liên tục trạng thái instance, dịch vụ, usage và telemetry khác để giữ độ khả dụng và hiệu suất.\nKiến trúc này phục vụ Heroku hơn 10 năm. Nhưng khi quản lý một fleet các database instances quy mô lớn, độ phức tạp và gánh nặng vận hành tăng lên. Heroku phải viết nhiều mã để giám sát, phát hiện và khắc phục các lỗi hệ điều hành, cập nhật PostgreSQL, hỏng phần cứng.\nDù đã tự động hóa nhiều phần, kỹ sư Heroku vẫn ngày càng dành thời gian nhiều hơn cho bảo trì hạ tầng thay vì phát triển tính năng mới. Khi tìm giải pháp thay thế, Aurora trở thành lựa chọn rõ rệt.\nKiến trúc PostgreSQL mới với Aurora Minh họa kiến trúc mới:\nMột lợi thế nền tảng là control plane của Heroku được thiết kế để tương tác hiệu quả với các dịch vụ AWS Cloud. Hệ thống lấy cảm hứng từ mô hình finite-state machine — mỗi tài nguyên tồn tại ở một trạng thái và có thể chuyển sang trạng thái khác khi có hành động. Ví dụ: khi provision EC2 instance với tham số nhất định, nó vào trạng thái pending cho đến khi AWS hoàn tất yêu cầu, rồi vào trạng thái running.\nKhi chọn Aurora làm backend cho Heroku Postgres, Heroku Data không còn phải dựng và duy trì server infrastructure, custom AMIs, cài đặt và vá lỗi hệ điều hành hoặc di chuyển sang type mới. Khi khách hàng gửi yêu cầu provision, Heroku chỉ cần tạo và thiết lập một Aurora cluster; các phần bên dưới như instance, disk, replication, snapshot được AWS xử lý.\nĐiều này phù hợp với triết lý ephemeralization của Heroku: dùng ít tài nguyên nhưng làm được nhiều hơn. Bằng việc giảm độ phức tạp quản lý hạ tầng database tùy chỉnh, họ có thể ưu tiên giá trị gia tăng như enhanced observability, hỗ trợ database thông minh và tăng interoperability dữ liệu.\nCách Heroku di chuyển hơn 200.000 cơ sở dữ liệu Nhóm Heroku Data phải di chuyển hơn 200.000 cơ sở dữ liệu PostgreSQL tự quản lý sang Aurora. Đây là thách thức lớn, nhưng họ đã hoàn thành chỉ trong 4 tháng với tác động tối thiểu đến khách hàng.\nMặc dù thành thạo PostgreSQL, họ mới với Aurora. Vì vậy, AWS hợp tác đào tạo hơn 40 kỹ sư Heroku.\nNhóm sử dụng hai control plane song song:\nLegacy control plane cho hệ thống cũ Modern control plane cho hệ thống Aurora Heroku xây dựng hệ thống transfer chuyên biệt trong modern control plane, dùng công cụ pgcopydb để sao chép dữ liệu từ PostgreSQL cũ sang Aurora. So với pg_dump/pg_restore, cách này vượt trội nhờ parallel operations. Thời gian trung bình cho khóa, copy, cập nhật pointer và mở khóa \u0026lt; 2.2 phút (p50).\nĐể đảm bảo migration trơn tru, nhóm phát triển khả năng kiểm thử toàn diện: mô phỏng end-to-end migration, kiểm tra dữ liệu, xử lý sự cố trước khi ảnh hưởng khách hàng. Migration diễn ra liên tục, trung bình 2.000 database mỗi ngày. Nhờ kiểm tra kỹ, họ phát hiện và xử lý vấn đề trước khi ảnh hưởng người dùng.\nKhi hệ thống transfer sẵn sàng production, khách có hai lựa chọn:\nSelf-serve migration – khách yêu cầu di chuyển qua việc thay đổi gói dịch vụ Automated migration – hệ thống tự động di chuyển dần từng phần để tránh gián đoạn Heroku đã di chuyển thành công hàng trăm nghìn database từ PostgreSQL self-managed sang Aurora PostgreSQL với ảnh hưởng tối thiểu. Họ còn dùng AWS Countdown, chương trình hỗ trợ Enterprise của AWS để chuẩn bị và thực hiện các sự kiện như migration và launch, hỗ trợ quản lý quotas, capacity planning và hỗ trợ vận hành.\nLợi ích và ưu điểm của kiến trúc mới Chuyển sang kiến trúc database mới là đầu tư lâu dài của Heroku nhằm mang đến trải nghiệm đẳng cấp cho khách hàng.\nHeroku khi vận hành fleet PostgreSQL trên EC2 dành nhiều nỗ lực để cạnh tranh với việc phát triển tính năng mới. Kiến trúc mới trên Aurora giảm gánh nặng vận hành: không còn phải quản lý cập nhật phần mềm, vá lỗi hệ điều hành, PostgreSQL service hay các thư viện hỗ trợ.\nTổ chức giờ đây biết AWS giữ database khách hàng an toàn, ổn định và luôn sẵn sàng. Heroku có thêm thời gian phát triển tính năng mới, lắng nghe khách hàng và củng cố hợp tác với AWS.\nKiến trúc mới cho phép Heroku Data cung cấp tính năng tương lai như AI-enabled database administrator, auto scaling, sleep mode, near-zero downtime, tăng số lượng connection, mở rộng storage lên 128 TB, và hơn thế nữa. Với sự đơn giản của Heroku, việc gắn một database mạnh mẽ như vậy vào ứng dụng thực hiện chỉ bằng một dòng code.\nMigration sang Amazon Aurora cũng nâng cao bảo mật: mã hóa at rest dùng AWS KMS, in transit dùng SSL/TLS, vá lỗi tự động không cần maintenance window, kiểm soát quyền qua IAM authentication, cách ly mạng và ghi nhận hoạt động qua AWS CloudTrail. Các tính năng bảo mật doanh nghiệp này được tích hợp tự động trong Aurora mà không cần cấu hình thêm.\nKết luận Quá trình di chuyển từ PostgreSQL tự quản lý trên EC2 sang Aurora thể hiện sự chuẩn bị kỹ lưỡng và hợp tác giữa Heroku và AWS. Sau khi triển khai thành công cho hàng trăm nghìn database multi-tenant, bước tiếp theo của Heroku là di chuyển cơ sở dữ liệu single-tenant trong Heroku Private Spaces sang Aurora vào cuối năm 2025.\nVề các tác giả Stefan Pieterse là Principal Customer Solutions Manager tại AWS, người đã hỗ trợ nhiều khách hàng chiến lược trong quá trình di chuyển và hiện đại hóa workloads lên đám mây. Khi không làm việc, ông thường chạy bộ hoặc chơi cùng con trai ba tuổi.\nJohn “Rocket” Nichols là Solutions Architect tại AWS, nơi anh giúp các doanh nghiệp lớn xây dựng hệ thống resilient, hiệu suất cao và tối ưu chi phí. Anh cũng tổ chức livestream và làm rượu trong thời gian rảnh.\nJonathan K. Brown là Senior Product Manager tại Heroku, phụ trách Heroku Data Services. Anh có nền tảng vững chắc từ hàng không vũ trụ đến công nghệ cao, có BS/MS Engineering và MBA từ UC Berkeley, và yêu thích paragliding.\nJustin Downing là Software Engineer Architect tại Salesforce, tập trung vào kiến trúc và hệ thống Heroku Data Services. Khi không làm việc, anh khám phá thiên nhiên và trượt tuyết.\n"
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/3-blogstranslated/3.2-blog2/",
	"title": "Blog 2",
	"tags": [],
	"description": "",
	"content": "Đẩy nhanh nghiên cứu bệnh Alzheimer thông qua phân tích bộ gen chức năng quy mô lớn được hỗ trợ bởi điện toán đám mây AWS Bởi: Meghan Buder và Karthik Narasimhan\nNgày: 14 tháng 4, 2025\nChuyên mục: Amazon EC2, Customer Solutions, Healthcare, Public Sector\nBệnh Alzheimer là một rối loạn thoái hóa thần kinh tiến triển ảnh hưởng tới hàng triệu người trên toàn thế giới. Hiệp hội Alzheimer ước tính hơn 6 triệu người Mỹ đang mắc bệnh và con số này được dự đoán sẽ lên gần 13 triệu vào năm 2050. Sự gia tăng này đã thúc đẩy các nỗ lực nghiên cứu toàn cầu, với các nhà khoa học làm việc để hiểu các cơ chế phức tạp của bệnh, xác định các tác nhân tiềm tàng, và phát triển các liệu pháp hiệu quả hơn.\nĐi đầu trong nghiên cứu quan trọng này là Tiến sĩ Gao Wang, Phó Giáo sư Khoa Thần kinh học tại Đại học Columbia. Ông dẫn đầu Lab of Statistical Functional Genomics, nơi sử dụng sức mạnh của Amazon Web Services (AWS) cloud computing để thực hiện nghiên cứu genomics đột phá, giải mã các cơ sở di truyền phức tạp của bệnh Alzheimer và xác định các mục tiêu trị liệu tiềm năng.\nFunctional genetics trong nghiên cứu Alzheimer Nghiên cứu của Tiến sĩ Wang tập trung vào functional genetics, nơi mục tiêu không chỉ là xác định các thay đổi di truyền liên quan đến Alzheimer mà còn hiểu lý do những thay đổi này dẫn tới khởi phát bệnh. Phương pháp này đòi hỏi phân tích dữ liệu có chiều cao và quy mô lớn bằng các mô hình sinh học tính toán và thống kê tinh vi.\nNhờ máy tính đám mây, Tiến sĩ Wang tăng tốc độ phân tích, cho phép hiểu sâu hơn và tiến bộ nhanh hơn trong việc khám phá cơ chế phức tạp của Alzheimer. Ông nhấn mạnh:\n“Nếu toàn ngành có thể cho kết quả nhanh hơn và nếu kết quả là quan trọng, bạn có thể truyền cảm hứng cho các nghiên cứu tiếp theo và thúc đẩy lĩnh vực này tiến lên, hy vọng là nhiều năm trước đó. Các nhà nghiên cứu khác dựa vào dữ liệu chúng tôi sản xuất hoặc những điều chúng tôi tìm ra ban đầu vì chúng tôi có thể mở một số câu hỏi người khác có thể tập trung vào nghiên cứu của họ.”\nDự án FunGen-xQTL: Một nỗ lực hợp tác Một sáng kiến chính là FunGen-xQTL Project, hợp tác giữa 14 viện nghiên cứu, 28 học viên và 19 giảng viên tại Mỹ. Dự án tập trung nghiên cứu molecular quantitative trait loci (QTLs) trong các não lão hóa, trải rộng qua 62 bối cảnh phân tử trong tế bào và mô não.\nNhóm nghiên cứu tạo ra hồ sơ phân tử toàn diện gồm methyl hóa DNA, chỉnh sửa histone, biểu hiện gen, và mức protein từ mẫu não người. Qua đó, cung cấp cho cộng đồng khoa học Alzheimer dữ liệu genomics chức năng từ các nhóm người lão hóa được tuyển chọn và phân tích đa omics.\nMục tiêu là xác định các yếu tố di truyền ảnh hưởng đến bệnh Alzheimer, thiết lập các con đường nhân quả liên kết biến dị gen với nguy cơ bệnh, đồng thời phát triển nguồn QTL toàn diện hỗ trợ nghiên cứu các bệnh thoái hóa thần kinh và não lão hóa. Dự án đã bản đồ hóa các tính trạng phân tử trong các loại tế bào não khác nhau (microglia, astrocytes, neurons), đem lại hiểu biết chưa từng có về điều hòa di truyền theo loại tế bào.\nTăng tốc các đột phá khoa học với AWS Cloud Dự án FunGen-xQTL đòi hỏi hạ tầng vượt xa khả năng on-premises truyền thống. Một trở ngại lớn là nhu cầu tính toán khổng lồ: áp dụng mô hình Bayesian trên hàng chục nghìn biến di truyền, dưới hàng trăm kết hợp tế bào, mô, tổ tiên, và bệnh lý, được đánh giá trên ~30.000 gen.\nFunctional genetics còn đòi hỏi xử lý và phân tích lượng dữ liệu phức tạp, có chiều cao, để khám phá mối quan hệ giữa biến dị gen và khởi phát bệnh. Ngoài ra, việc chia sẻ dữ liệu quy mô lớn giữa các viện nghiên cứu mà không sao chép hoặc trùng lặp là một thách thức cả về kỹ thuật và hậu cần.\nTiến sĩ Wang sử dụng AWS cloud computing, cụ thể là MMCloud từ đối tác AWS MemVerge, để triển khai các ứng dụng container hóa trên AWS:\nXử lý song song quy mô lớn: MMCloud cho phép gửi hàng trăm nghìn job lên AWS và chạy trên các Amazon EC2 Spot Instances tiết kiệm chi phí. Giảm đáng kể thời gian xử lý: phân tích phức tạp giảm từ vài tuần xuống còn vài ngày. Hiệu quả chi phí: sử dụng Spot Instances tiết kiệm 50-80% so với On-Demand. Hợp tác dễ dàng: triển khai và quản lý các ứng dụng Jupyter và RStudio cho nhiều cộng tác viên học thuật. Khai thác sức mạnh của AWS Cloud cho các đột phá khoa học Cloud computing giúp các nhà nghiên cứu như Tiến sĩ Wang:\nXử lý và phân tích các tập dữ liệu genomics lớn hiệu quả. Tăng tốc thời gian công bố nghiên cứu và tác động khoa học. Áp dụng các mô hình thống kê và sinh học tính toán phức tạp để hiểu biến dị gen chức năng. Hợp tác toàn cầu dễ dàng thông qua chia sẻ dữ liệu và kết quả. Mở rộng tài nguyên linh hoạt, chi phí-hiệu quả, chỉ trả cho những gì sử dụng. Kết luận Nghiên cứu của Tiến sĩ Gao Wang tại Đại học Columbia, với sự hỗ trợ của AWS Cloud, đại diện cho phương pháp hiện đại để hiểu Alzheimer thông qua functional genetics. Công trình này mang lại hy vọng phát triển các liệu pháp hiệu quả và cuối cùng có thể tìm ra cách chữa căn bệnh kinh niên này.\nThông tin tác giả Meghan Buder – Quản lý phát triển kinh doanh kỹ thuật chính tại AWS, hỗ trợ các nhà nghiên cứu tận dụng cloud để thúc đẩy đổi mới. Trước đây cô làm việc trong lĩnh vực giáo dục và có bằng Thạc sĩ Mind, Brain, and Education từ Harvard Graduate School of Education.\nKarthik Narasimhan – Quản lý phát triển kinh doanh cao cấp cho genomics và life sciences tại AWS, hỗ trợ các nhà nghiên cứu tại các tổ chức giáo dục tăng tốc nghiên cứu. Anh có Tiến sĩ Khoa học Sinh học từ National University of Singapore và MBA từ University of Texas at Austin.\n"
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/3-blogstranslated/3.3-blog3/",
	"title": "Blog 3",
	"tags": [],
	"description": "",
	"content": "AWS Marketplace được đánh giá là “Awardable” cho các dự án của DoD trong P1 Solutions Marketplace Bởi: AWS Public Sector Blog Team\nNgày: 14 tháng 4, 2025\nChuyên mục: Announcements, AWS Marketplace, Compliance, Defense, Government, Public Sector, Security\nAmazon Web Services (AWS) vui mừng thông báo rằng AWS Marketplace đã được cấp trạng thái “Awardable” trong Department of Defense (DoD) Platform One (P1) Solutions Marketplace. Quy định này cho phép các tổ chức DoD dễ dàng truy cập và mua các giải pháp thông qua AWS Marketplace bằng các con đường mua sắm đã được thiết lập.\nTruy cập quan trọng cho nhiệm vụ P1 Solutions Marketplace là kho lưu trữ kỹ thuật số các video pitch dài năm phút được chọn sau cạnh tranh, nhằm đáp ứng các yêu cầu lớn của chính phủ về phần cứng, phần mềm và dịch vụ. Tất cả các giải pháp “awardable” đều đã được đánh giá thông qua ma trận điểm phức tạp và quy trình cạnh tranh.\nViệc AWS Marketplace được đưa vào mang lại cho khách hàng DoD khả năng tiếp cận hơn 4.000 nhà cung cấp đã được tin cậy và đáp ứng yêu cầu bảo mật và tuân thủ liên bang.\nQuy trình mua sắm được đơn giản hóa Với trạng thái này, các tổ chức DoD giờ đây có thể dùng các nhà cung cấp AWS Marketplace để:\nTruy cập các giải pháp đã được phê duyệt qua các công cụ hợp đồng sẵn có Tăng tốc thời gian triển khai công nghệ Duy trì tuân thủ các quy định mua sắm liên bang Tập trung hóa quản lý hóa đơn và giấy phép Theo dõi và tối ưu chi tiêu CNTT giữa các phòng ban Josh Weatherly, Giám đốc toàn cầu về hợp tác công nghiệp công khai và go-to-market cho AWS Marketplace, cho biết:\n“Việc đưa AWS Marketplace vào P1 Solutions Marketplace là bước tiến mang tính chuyển đổi trong việc kết nối DoD với đổi mới thương mại…”\nKhi lãnh đạo DoD thúc đẩy cải cách mua sắm và đẩy mạnh việc áp dụng các công nghệ mới, trạng thái awardable của AWS Marketplace sẽ đơn giản hóa và tăng tốc việc tiếp cận các đổi mới tiên tiến cho các nhiệm vụ quan trọng.\nTiến về phía trước với AWS Marketplace Các tổ chức DoD có thể truy cập các giải pháp AWS Marketplace qua cổng P1 Solutions Marketplace. Video của AWS Marketplace, “Amazon Web Services, Inc. Streamline Defense Procurement and License Management with AWS Marketplace”, chỉ dành cho khách hàng chính phủ trên P1 Solutions Marketplace, trình diễn một trường hợp sử dụng thực tế.\nAWS Marketplace đã được công nhận trong số các đơn đăng ký cạnh tranh vào P1 Solutions Marketplace, nơi các giải pháp phải thể hiện đổi mới, khả năng mở rộng và tác động tiềm năng đối với nhiệm vụ DoD. Thành tựu này dựa trên cam kết liên tục của AWS trong việc hỗ trợ nhu cầu công nghệ của chính phủ và quốc phòng thông qua các giải pháp đám mây an toàn, tuân thủ và dễ tiếp cận.\nKhách hàng chính phủ quan tâm đến việc truy cập AWS Marketplace qua P1 Solutions Marketplace có thể tạo tài khoản tại trang P1 Marketplace.\nĐể biết thêm thông tin về giải pháp AWS Marketplace dành cho ứng dụng quốc phòng và chính phủ, vui lòng liên hệ icmp@amazon.com.\n"
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/3-blogstranslated/3.4-blog4/",
	"title": "Blog 4",
	"tags": [],
	"description": "",
	"content": "\r⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/3-blogstranslated/3.5-blog5/",
	"title": "Blog 5",
	"tags": [],
	"description": "",
	"content": "\r⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/3-blogstranslated/3.6-blog6/",
	"title": "Blog 6",
	"tags": [],
	"description": "",
	"content": "\r⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/5-workshop/5.4-s3-onprem/5.4.1-prepare/",
	"title": "Chuẩn bị tài nguyên",
	"tags": [],
	"description": "",
	"content": "Để chuẩn bị cho phần này của workshop, bạn sẽ cần phải:\nTriển khai CloudFormation stack Sửa đổi bảng định tuyến VPC. Các thành phần này hoạt động cùng nhau để mô phỏng DNS forwarding và name resolution.\nTriển khai CloudFormation stack Mẫu CloudFormation sẽ tạo các dịch vụ bổ sung để hỗ trợ mô phỏng môi trường truyền thống:\nMột Route 53 Private Hosted Zone lưu trữ các bản ghi Bí danh (Alias records) cho điểm cuối PrivateLink S3 Một Route 53 Inbound Resolver endpoint cho phép \u0026ldquo;VPC Cloud\u0026rdquo; giải quyết các yêu cầu resolve DNS gửi đến Private Hosted Zone Một Route 53 Outbound Resolver endpoint cho phép \u0026ldquo;VPC On-prem\u0026rdquo; chuyển tiếp các yêu cầu DNS cho S3 sang \u0026ldquo;VPC Cloud\u0026rdquo; Click link sau để mở AWS CloudFormation console. Mẫu yêu cầu sẽ được tải sẵn vào menu. Chấp nhận tất cả mặc định và nhấp vào Tạo stack. Có thể mất vài phút để triển khai stack hoàn tất. Bạn có thể tiếp tục với bước tiếp theo mà không cần đợi quá trình triển khai kết thúc.\nCập nhật bảng định tuyến private on-premise Workshop này sử dụng StrongSwan VPN chạy trên EC2 instance để mô phỏng khả năng kết nối giữa trung tâm dữ liệu truyền thống và môi trường cloud AWS. Hầu hết các thành phần bắt buộc đều được cung cấp trước khi bạn bắt đầu. Để hoàn tất cấu hình VPN, bạn sẽ sửa đổi bảng định tuyến \u0026ldquo;VPC on-prem\u0026rdquo; để hướng lưu lượng đến cloud đi qua StrongSwan VPN instance.\nMở Amazon EC2 console\nChọn instance tên infra-vpngw-test. Từ Details tab, copy Instance ID và paste vào text editor của bạn để sử dụng ở những bước tiếp theo\nĐi đến VPC menu bằng cách gõ \u0026ldquo;VPC\u0026rdquo; vào Search box\nClick vào Route Tables, chọn RT Private On-prem route table, chọn Routes tab, và click Edit Routes.\nClick Add route. Destination: CIDR block của Cloud VPC Target: ID của infra-vpngw-test instance (bạn đã lưu lại ở bước trên) Click Save changes "
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/4-eventparticipated/4.1-event1/",
	"title": "Event 1",
	"tags": [],
	"description": "",
	"content": "Báo cáo tóm tắt sự kiện: Vietnam Cloud Day 2025 :Ho Chi Minh City Connect Edition for Builders Mục tiêu sự kiện Cung cấp cái nhìn về ứng dụng Generative AI trong doanh nghiệp Chia sẻ best practices về hiện đại hóa ứng dụng và di chuyển lên cloud Trình diễn công cụ AI giúp tăng tốc Software Development Lifecycle (SDLC) Khám phá chiến lược bảo mật và chuyển đổi VMware lên cloud Hỗ trợ lãnh đạo và kỹ sư đưa các dự án AI phù hợp với mục tiêu kinh doanh Diễn giả Eric Yeo – Country General Manager, Vietnam, Cambodia, Laos \u0026amp; Myanmar, AWS Dr. Jens Lottner – CEO, Techcombank Ms. Trang Phung – CEO \u0026amp; Co-Founder, U2U Network Jaime Valles – Vice President, General Manager Asia Pacific and Japan, AWS Jeff Johnson – Managing Director, ASEAN, AWS Vu Van – Co-founder \u0026amp; CEO, ELSA Corp Nguyen Hoa Binh – Chairman, Nexttech Group Dieter Botha – CEO, TymeX Hung Nguyen Gia – Head of Solutions Architect, AWS Son Do – Technical Account Manager, AWS Nguyen Van Hai – Director of Software Engineering, Techcombank Phuc Nguyen – Solutions Architect, AWS Alex Tran – AI Director, OCB Nguyen Minh Ngan – AI Specialist, OCB Nguyen Manh Tuyen – Head of Data Application, LPBank Securities Vinh Nguyen – Co-Founder \u0026amp; CTO, Ninety Eight Hung Hoang – Customer Solutions Manager, AWS Taiki Dang – Solutions Architect, AWS Nội dung chính Khai mạc \u0026amp; Keynotes Phát biểu khai mạc từ Đại diện Chính phủ Keynote – Eric Yeo: Chiến lược cloud adoption và AI tại Đông Nam Á Customer Keynote 1 – Dr. Jens Lottner: Hành trình chuyển đổi số của Techcombank Customer Keynote 2 – Ms. Trang Phung: Giải pháp fintech sáng tạo từ U2U Network AWS Keynote – Jaime Valles: Góc nhìn khu vực về Generative AI và hiện đại hóa cloud Thảo luận Panel: Navigating the GenAI Revolution Điều phối: Jeff Johnson, AWS Diễn giả: Vu Van, Nguyen Hoa Binh, Dieter Botha Nội dung: Lãnh đạo tổ chức trong thời kỳ GenAI bùng nổ Xây dựng văn hóa đổi mới Đồng bộ AI với chiến lược kinh doanh Quản lý thay đổi tổ chức khi áp dụng AI Track: Migration \u0026amp; Modernization Hoàn tất di chuyển và hiện đại hóa quy mô lớn với AWS Diễn giả: Son Do, Nguyen Van Hai Bài học từ các doanh nghiệp đã di chuyển workloads Best practices và con đường hiện đại hóa Case study: Xây dựng nền tảng vững chắc và roadmap chiến lược Hiện đại hóa ứng dụng với công cụ AI Diễn giả: Phuc Nguyen, Alex Tran Amazon Q Developer: Tăng tốc sinh code, nâng chất lượng phần mềm Tích hợp liền mạch với IDE, CLI, DevSecOps Tự động tạo tài liệu và unit test Trở thành collaborator thông minh sử dụng LLM Demo: Phân tích code phức tạp, đề xuất tối ưu, tự động hóa tasks Panel: Application Modernization Điều phối: Hung Nguyen Gia, AWS Diễn giả: Nguyen Minh Ngan, Nguyen Manh Tuyen, Vinh Nguyen Nội dung: Dùng AI để phát triển nhanh và chất lượng hơn Đồng bộ hóa hiện đại hóa ứng dụng với chiến lược kinh doanh Tự động hóa SDLC và nâng độ tin cậy phần mềm Transforming VMware với AI-driven Cloud Modernization Diễn giả: Hung Hoang, AWS Thúc đẩy adoption cloud cho VMware AWS Transform: migration nhanh, an toàn, tiết kiệm chi phí Playbook: patterns giảm downtime, roadmap lên EKS, RDS, serverless AWS Security at Scale Diễn giả: Taiki Dang, AWS Tăng cường bảo mật từ phát triển đến production Các nguyên tắc: nhận diện, phòng ngừa, phát hiện, phản hồi, khắc phục Ứng dụng AI trong phân tích và tự động hóa bảo mật Xây dựng hệ thống resilient, scalable, an toàn Key Takeaways / Bài học rút ra GenAI cần đồng bộ với chiến lược kinh doanh để đạt hiệu quả Công cụ AI như Q Developer tăng tốc SDLC, nâng chất lượng phần mềm Migration và hiện đại hóa trên AWS tăng tính linh hoạt, bền vững, hiệu quả vận hành Di chuyển VMware lên AWS giúp adoption cloud thuận lợi Security-by-design và AI-assisted operations nâng cao bảo mật doanh nghiệp "
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/4-eventparticipated/4.2-event2/",
	"title": "Event 2",
	"tags": [],
	"description": "",
	"content": "Báo Cáo Tổng Kết Sự Kiện: “AI/ML/GenAI on AWS Workshop (AWS Cloud Mastery Series #1)” Mục Tiêu Sự Kiện Giới thiệu tổng quan về AI, Machine Learning và GenAI trên AWS Trình bày các dịch vụ AI/ML của AWS và ứng dụng thực tế Minh họa cách xây dựng ứng dụng GenAI với Amazon Bedrock và AI Agent Giải thích về Retrieval-Augmented Generation (RAG) trong doanh nghiệp Giới thiệu Bedrock AgentCore và khả năng xây dựng AI agent cấp doanh nghiệp Diễn Giả Lâm Tuấn Kiệt – Chuyên gia AI Đinh Lê Hoàng Anh – Chuyên gia AI Danh Hoàng Hiếu Nghị – Chuyên gia DevOp Nội Dung Nổi Bật 1. Kiến Thức Cơ Bản về ML \u0026amp; AI (Lâm Tuấn Kiệt) Giới thiệu các khái niệm AI và Machine Learning Các kỹ thuật prompt quan trọng: Few-shot prompting Chain-of-thought prompting Tìm hiểu về Retrieval-Augmented Generation (RAG): Tăng độ chính xác nhờ dữ liệu nội bộ Hỗ trợ xây dựng AI agent thông minh AWS có sẵn nhiều công cụ hỗ trợ tích hợp RAG 2. Bộ Dịch Vụ AI của AWS (Đinh Lê Hoàng Anh) AWS cung cấp bộ dịch vụ AI mạnh mẽ, dùng ngay không cần đào tạo mô hình:\nAmazon Rekognition\nPhân tích hình ảnh/video, nhận diện khuôn mặt, vật thể Amazon Translate\nDịch đa ngôn ngữ bằng mô hình học sâu Amazon Textract\nTrích xuất văn bản từ tài liệu Giữ nguyên bố cục và cấu trúc Amazon Transcribe\nChuyển giọng nói thành văn bản Nhận diện người nói trong cuộc hội thoại Amazon Polly\nChuyển văn bản thành giọng nói tự nhiên Amazon Comprehend\nNLP: phân tích cảm xúc, thực thể, từ khóa Amazon Kendra\nCông cụ tìm kiếm doanh nghiệp thông minh Amazon Lookout Family\nPhát hiện bất thường cho thiết bị và dữ liệu IoT Amazon Personalize\nGợi ý cá nhân hóa theo thời gian thực 3. Bedrock AgentCore (Danh Hoàng Hiếu Nghị) Giới thiệu Bedrock AgentCore – công nghệ lõi xây dựng AI Agent Tự động điều phối reasoning, truy xuất dữ liệu, gọi API Kết hợp chặt chẽ với RAG và Foundation Models trên Bedrock Tạo ra chatbot, trợ lý ảo và agent nghiệp vụ mạnh mẽ Bài Học Chính Tư Duy Thiết Kế Luôn bắt đầu từ nhu cầu nghiệp vụ trước khi chọn mô hình AI Prompt engineering (few-shot, CoT) giúp cải thiện độ chính xác Dữ liệu chuẩn rất quan trọng khi xây dựng RAG Kiến Trúc Kỹ Thuật Các dịch vụ AI fully-managed giúp giảm vận hành Bedrock + AgentCore tạo nền tảng mạnh mẽ cho AI enterprise Kết hợp Rekognition, Textract, Kendra và Transcribe để xây dựng pipeline AI hoàn chỉnh Chiến Lược Hiện Đại Hóa Triển khai AI theo từng giai đoạn để tối ưu hiệu quả Ưu tiên dịch vụ quản lý sẵn để giảm độ phức tạp RAG giúp khai thác dữ liệu nội bộ an toàn và hiệu quả Ứng Dụng Vào Công Việc Dùng Amazon Kendra tìm kiếm nội bộ Tự động hóa xử lý tài liệu với Textract + Comprehend Xây dựng AI agent bằng Bedrock AgentCore Phân tích cuộc gọi: Transcribe → Comprehend → Kendra Dùng Rekognition cho xác thực hình ảnh/video Trải Nghiệm Sự Kiện Học Từ Chuyên Gia Từ cơ bản ML đến prompt nâng cao và GenAI workflow Hiểu rõ cách tích hợp dịch vụ AI của AWS vào thực tế Hiểu Sâu Kỹ Thuật Nắm bắt pipeline xử lý hình ảnh – âm thanh – văn bản – tìm kiếm Hiểu cách Bedrock AgentCore + RAG vận hành trong AI hiện đại Thảo Luận \u0026amp; Kết Nối Giao lưu với chuyên gia và người tham dự về các bài toán AI Hiểu rõ hơn cách chọn dịch vụ AWS phù hợp từng use case Bài Học Rút Ra AWS là hệ sinh thái đầy đủ cho xây dựng hệ thống AI GenAI mạnh nhất khi kết hợp dữ liệu nội bộ doanh nghiệp Bedrock AgentCore giúp đơn giản hóa việc xây dựng AI agent quy mô lớn "
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/4-eventparticipated/4.3-event3/",
	"title": "Event 3",
	"tags": [],
	"description": "",
	"content": "Báo Cáo Tổng Kết Sự Kiện: “DevOps on AWS (AWS Cloud Mastery Series #2)” Mục tiêu sự kiện Hiểu về văn hoá DevOps và các nguyên tắc cốt lõi Nắm vững CI/CD pipeline và GitHub workflow Tìm hiểu Infrastructure as Code (IaC) bằng CloudFormation và CDK Áp dụng DevOps best practices và tối ưu chi phí So sánh các công cụ IaC và cách chọn công cụ phù hợp Diễn giả Trương Quang Tính – AWS Community Builder, Platform Engineer (Timex) Hoàng Kha – DevOps Specialist Nguyễn Bảo – Chuyên gia Infrastructure \u0026amp; IaC Nguyễn Thịnh – Chuyên gia AWS CDK Các điểm nổi bật 1. Văn hoá DevOps và nền tảng (Trương Quang Tính) Dev → DevOps → Operations Các yếu tố văn hoá DevOps: Hợp tác \u0026amp; trách nhiệm chung Tự động hoá mọi thứ Học tập \u0026amp; thử nghiệm liên tục Đo lường minh bạch DevOps thế hệ mới: DevOps, Cloud, Platform, SRE DevOps metrics: độ ổn định deployment, độ linh hoạt, hiệu suất Tổng quan DevOps journey 2. CI/CD \u0026amp; DevOps Practices (Hoàng Kha) Kiến trúc CI/CD pipeline GitHub workflow tối ưu Tối ưu chi phí Sử dụng open-source trong DevOps CI – Phân chia \u0026amp; quản lý repo, quy trình làm việc của developer CD – khái niệm và quy trình Centralized CI Best practices khi branching/merging Lý do build bị fail Testing ở mọi stage CI với containers: module hoá container Code rules: Khi nào tạo branch Quy tắc pull request Quy tắc đặt tên Tổ chức source code 3. IaC với CloudFormation (Nguyễn Bảo) ClickOps vs IaC: dùng code thay vì bấm trên console CloudFormation: Công cụ IaC của AWS Stack \u0026amp; Template Template YAML CloudFormation workflow Configuration drift \u0026amp; drift detection 4. AWS CDK – IaC hiện đại (Nguyễn Thịnh) Khái niệm Construct (L1, L2, L3) App và Stack AWS CLI với --profile AWS Amplify chạy trên CloudFormation + CDK Production \u0026amp; Sandbox là hai stack riêng Sequence diagram, giải thích code Circular dependency với SDK và CloudFormation 5. Lựa chọn công cụ IaC (Bảo) Terraform OpenTofu Pulumi ACC Sandbox (ghi chú ngắn) Giải pháp thay thế Những bài học rút ra Tư duy thiết kế DevOps là thay đổi văn hoá, không chỉ công cụ Tự động hóa và trách nhiệm chung cải thiện chất lượng Học tập liên tục thúc đẩy đổi mới Kiến trúc kỹ thuật CI/CD đảm bảo chất lượng và tốc độ release IaC loại bỏ sai lệch cấu hình Container hoá giúp dễ scale và module hoá CDK giúp đơn giản hóa CloudFormation Chiến lược hiện đại hoá Thay thế ClickOps bằng IaC Sử dụng Git để quản lý pipeline Áp dụng best practices cho branching/testing Chọn công cụ IaC dựa trên nhu cầu thực tế Áp dụng vào công việc Tăng cường hợp tác theo văn hoá DevOps Triển khai CI/CD với GitHub Actions Chuyển sang IaC với CloudFormation/CDK Module hoá hệ thống bằng containers Chuẩn hoá quy trình quản lý code Đánh giá công cụ IaC phù hợp Trải nghiệm sự kiện Buổi chia sẻ “DevOps on AWS” giúp tôi hiểu rõ hơn về văn hoá DevOps, CI/CD, IaC và cách áp dụng vào thực tế. Các diễn giả đưa ra nhiều ví dụ thực tiễn về tối ưu workflow, cải thiện chất lượng và nâng cao tốc độ triển khai.\nNhững kiến thức về container, branching, testing và IaC giúp tôi định hướng rõ hơn cho việc hiện đại hóa quy trình DevOps trong dự án của mình.\n"
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/4-eventparticipated/4.4-event4/",
	"title": "Event 4",
	"tags": [],
	"description": "",
	"content": "Báo Cáo Tổng Kết Sự Kiện: “AWS Cloud Mastery Series #3” Mục Tiêu Sự Kiện Hiểu các khái niệm cốt lõi về AWS IAM. Nắm được mô hình bảo mật đa lớp trên AWS. Khám phá GuardDuty, Security Hub, KMS, mã hóa và quy trình ứng phó sự cố. Học cách kiểm soát truy cập, phát hiện mối đe dọa và bảo vệ dữ liệu. Cải thiện bảo mật hệ thống trên quy mô doanh nghiệp. Diễn Giả Chan Doan Cong Ly Le Duc Anh TranHuynh Hoang Long Hoang Kevin Tran Duc Anh Nguyen Tuan Thinh Nguyen Do Thanh Dat Thinh Dat Kha Van Thinh Lam Viet Nguyen Long Mendel Grabski Tinh Truong Điểm Nổi Bật IAM – Identity \u0026amp; Access Management (TranHuynh Hoang Long) Quản lý user và group. Best practices: tránh \u0026ldquo;*\u0026rdquo;, dùng nguyên tắc quyền tối thiểu, bật MFA. Bảo mật đăng nhập AWS. SSO cho nhiều ứng dụng. Service Control Policies (Hoang) Chính sách cấp tổ chức dành cho doanh nghiệp. Permission Boundaries để giới hạn quyền tối đa. Dải credentials: long-term vs short-term (STS). MFA: TOTP, FIDO2. Quay vòng credentials bằng Secrets Manager. IAM Access Analyzer. CloudTrail Organization-Level (Kevin, Thinh, Dat) Theo dõi toàn tổ chức. Quan sát bảo mật đa lớp. EventBridge cho cảnh báo và tự động hóa. GuardDuty (Thinh) Các vấn đề doanh nghiệp gặp phải. Nguồn dữ liệu từ CloudTrail và AWS services. Advanced Protection Plans. Runtime Monitoring bằng GuardDuty Agent. AWS Security Hub (Dat) CSPM – quản lý tư thế bảo mật trên cloud. Network Security (Kha Van) Tấn công theo hướng outbound, inbound và east-west. Security Group: stateful, default deny. Bảo mật tầng ứng dụng. SG Sharing qua VPC và Transit Gateway. NACLs: hoạt động ở subnet. Route 53 DNS. SG/NACL/firewall chống lại các vector tấn công. Data Protection \u0026amp; KMS (Thinh Lam, Viet Nguyen) Quy trình và policy của KMS. AWS managed key vs CMK. Rotation key theo chu kỳ. Phân loại dữ liệu. Access guardrails. Encryption \u0026amp; Secrets (Viet Nguyen) Mã hóa khi truyền: S3, DynamoDB. Quản lý secrets bằng ACM. Incident Response (Mendel, Tinh Truong) Mối đe dọa hiện đại → cần giải pháp hiện đại. Foundations và các lớp kiểm soát. Chiến lược phòng ngừa. Bài Học Rút Ra IAM là nền tảng bảo mật AWS; phải bật MFA và dùng least privilege. SCPs \u0026amp; permission boundaries giúp quản lý doanh nghiệp hiệu quả. GuardDuty + CloudTrail + EventBridge tạo chuỗi giám sát tự động. Security Group \u0026amp; NACL cần được dùng kết hợp đúng cách. KMS và key rotation giúp bảo vệ dữ liệu quan trọng. Security đa lớp gồm identity, network, data và incident response. Cloud security hiện đại dựa trên automation và phân tích hành vi. Ứng Dụng Vào Công Việc Áp dụng MFA, least privilege và IAM best practices vào DevOps \u0026amp; vận hành. Bật CloudTrail toàn tổ chức cho logging đầy đủ. Dùng GuardDuty và Security Hub để phát hiện mối đe dọa. Áp dụng best practice VPC: SG, NACL, DNS protection. Mã hóa dữ liệu bằng KMS và quản lý secrets bằng Secrets Manager/ACM. Tự động hóa cảnh báo qua EventBridge. Xây dựng quy trình incident response theo chuẩn AWS. Trải Nghiệm Sự Kiện Sự kiện mang lại lượng kiến thức thực tế về bảo mật doanh nghiệp trên AWS. Các diễn giả chia sẻ trực quan và bám sát nhu cầu thực tiễn. Bao phủ từ IAM cơ bản đến bảo mật nâng cao. Rất phù hợp cho cloud engineer, DevOps, security analyst cần tăng cường kiến thức bảo mật AWS. "
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/5-workshop/5.1-workshop-overview/",
	"title": "Giới thiệu",
	"tags": [],
	"description": "",
	"content": "Giới thiệu về VPC Endpoint Điểm cuối VPC (endpoint) là thiết bị ảo. Chúng là các thành phần VPC có thể mở rộng theo chiều ngang, dự phòng và có tính sẵn sàng cao. Chúng cho phép giao tiếp giữa tài nguyên điện toán của bạn và dịch vụ AWS mà không gây ra rủi ro về tính sẵn sàng. Tài nguyên điện toán đang chạy trong VPC có thể truy cập Amazon S3 bằng cách sử dụng điểm cuối Gateway. Interface Endpoint PrivateLink có thể được sử dụng bởi tài nguyên chạy trong VPC hoặc tại TTDL. Tổng quan về workshop Trong workshop này, bạn sẽ sử dụng hai VPC.\n\u0026ldquo;VPC Cloud\u0026rdquo; dành cho các tài nguyên cloud như Gateway endpoint và EC2 instance để kiểm tra. \u0026ldquo;VPC On-Prem\u0026rdquo; mô phỏng môi trường truyền thống như nhà máy hoặc trung tâm dữ liệu của công ty. Một EC2 Instance chạy phần mềm StrongSwan VPN đã được triển khai trong \u0026ldquo;VPC On-prem\u0026rdquo; và được cấu hình tự động để thiết lập đường hầm VPN Site-to-Site với AWS Transit Gateway. VPN này mô phỏng kết nối từ một vị trí tại TTDL (on-prem) với AWS cloud. Để giảm thiểu chi phí, chỉ một phiên bản VPN được cung cấp để hỗ trợ workshop này. Khi lập kế hoạch kết nối VPN cho production workloads của bạn, AWS khuyên bạn nên sử dụng nhiều thiết bị VPN để có tính sẵn sàng cao. "
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/1-worklog/",
	"title": "Nhật ký công việc",
	"tags": [],
	"description": "",
	"content": "Trong trang này bạn sẽ cần giới thiệu worklog của bạn như thế nào? Bạn hoàn thành chương trình trong vòng bao nhiêu tuần? Bạn đã làm gì trong các tuần đó?\nThông thường và cũng là tiêu chuẩn, một worklog được thực hiện trong khoảng 3 tháng (trong suốt thời gian thực tập) với nội dung các tuần như sau:\nWeek 1: Tìm hiểu về AWS và các dịch vụ điện toán đám mây cơ bản\n→ Tìm hiểu kiến thức cơ bản về AWS, các mô hình điện toán đám mây, và thực hành các dịch vụ cốt lõi như EC2, S3, và VPC.\nWeek 2: Thực hành với IAM, EC2 và S3\n→ Thực hành cấu hình IAM, quản lý EC2 instance và thao tác lưu trữ, truy xuất dữ liệu với Amazon S3.\nWeek 3: Cấu hình bảo mật mạng và lưu trữ dữ liệu\n→ Hiểu về bảo mật mạng trong AWS, tạo và quản lý key pairs, gắn EBS volumes vào EC2 instance.\nWeek 4: Triển khai ứng dụng web và cấu hình Elastic IP\n→ Triển khai và quản lý web server trên EC2, cấu hình Elastic IP và lưu trữ website tĩnh hoặc động.\nWeek 5: Quản lý cơ sở dữ liệu và sao lưu với Amazon RDS\n→ Tạo và cấu hình cơ sở dữ liệu RDS, thực hiện sao lưu snapshot và kết nối RDS với ứng dụng web.\nWeek 6: Triển khai WordPress và thực hành nhập/xuất máy ảo (VM)\n→ Cài đặt và triển khai WordPress trên AWS EC2, thiết lập AMI, Load Balancer và Auto Scaling Group.\n→ Học và thực hành nhập/xuất máy ảo (VM) giữa môi trường on-premises và AWS.\nWeek 7: Triển khai WordPress và thực hành nhập/xuất máy ảo (VM)\n→ Tự động hóa việc khởi động/dừng EC2 bằng AWS Lambda kết hợp Slack webhook.\n→ Giám sát tài nguyên AWS bằng Grafana và CloudWatch.\n→ Quản lý tài nguyên AWS hiệu quả hơn bằng cách sử dụng thẻ (tag) và nhóm tài nguyên (resource group).\nTuần 8: Quản lý truy cập EC2 và làm quen với AWS Systems Manager\nTuần 9: Giám sát mạng với VPC Flow Logs, ủy quyền truy cập bảng điều khiển thanh toán, quản lý sử dụng tài nguyên và phát hiện bất thường sao lưu\nTuần 10: Bảo mật AWS\nTuần 11: Quản lý dữ liệu và bảo mật\nTuần 12: Tối ưu chi phí và thực hành cơ sở dữ liệu AWS\n"
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/1-worklog/1.1-week1/",
	"title": "Nhật ký công việc Tuần 1",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 1: Hiểu các dịch vụ cơ bản của AWS. Tạo tài khoản AWS Free Tier. Các công việc cần thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Tìm hiểu về AWS và các nhóm dịch vụ của nó + Compute (Tính toán) + Storage (Lưu trữ) + Networking (Mạng) + Database (Cơ sở dữ liệu) 09/08/2025 09/08/2025 https://www.youtube.com/@AWSStudyGroup 3 - Tạo tài khoản AWS Free Tier - Thực hành: + Tạo tài khoản AWS mới + Bật xác thực đa yếu tố (MFA) cho AWS + Tạo nhóm Admin và người dùng Admin 09/09/2025 11/09/2025 https://000001.awsstudygroup.com/ Thứ 7 - Quản lý chi phí với AWS Budgets - Thực hành: + Tạo Budget bằng Template + Tạo Cost Budget + Tạo RI Budget + Tạo Usage Budget + Tạo Savings Plans Budget 09/13/2025 09/13/2025 https://000007.awsstudygroup.com/ CN - Kiến thức cơ bản về mạng với Amazon Virtual Private Cloud (VPC) - Thực hành: + Giới thiệu Amazon VPC + Cấu hình tường lửa trong VPC 09/14/2025 09/15/2025 https://000003.awsstudygroup.com/1-introduce/ Kết quả đạt được trong tuần 1: Hiểu được AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute (Tính toán) Storage (Lưu trữ) Networking (Mạng) Database (Cơ sở dữ liệu) Tạo và cấu hình thành công tài khoản AWS Free Tier.\nHiểu cách quản lý chi phí bằng AWS Budgets.\nLàm quen với Amazon VPC (Virtual Private Cloud).\n"
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/1-worklog/1.2-week2/",
	"title": "Nhật ký công việc Tuần 2",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 2: Hiểu các kiến thức cơ bản về mạng với Amazon Virtual Private Cloud (VPC). Tìm hiểu các kiến thức cơ bản về tính toán (Compute) với Amazon Elastic Compute Cloud (EC2). Các công việc cần thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Tiếp tục các bước cơ bản với VPC - Thực hành: + Tạo VPC + Tạo Subnet + Tạo Internet Gateway + Tạo Route Table + Tạo Security Group + Kích hoạt VPC Flow Logs 09/15/2025 09/15/2025 https://000003.awsstudygroup.com/3-prerequisite/ 3 - Triển khai Amazon EC2 Instances - Thực hành: + Tạo máy chủ EC2 + Kiểm tra kết nối 09/16/2025 09/16/2025 https://000003.awsstudygroup.com/4-createec2server/ 4 - Tiếp tục triển khai Amazon EC2 Instances - Thực hành: + Tạo NAT Gateway + Sử dụng Reachability Analyzer + Tạo EC2 Instance Connect Endpoint 09/17/2025 09/17/2025 https://000003.awsstudygroup.com/4-createec2server/ 6 - Tiếp tục triển khai Amazon EC2 Instances - Thực hành: + AWS Systems Manager Session Manager + Giám sát và cảnh báo bằng CloudWatch 09/19/2025 09/19/2025 https://000003.awsstudygroup.com/4-createec2server/ Thứ 7 - Thiết lập kết nối VPN Site-to-Site trong AWS - Thực hành: + Tạo VPC cho VPN + Tạo EC2 làm Customer Gateway + Tạo Virtual Private Gateway + Tạo Customer Gateway + Tạo VPN Connection + Cấu hình Customer Gateway + Chỉnh sửa AWS VPN Tunnel + Tạo Transit Gateway + Tạo Transit Gateway Attachment + Cấu hình Route Tables 09/20/2025 09/20/2025 https://000003.awsstudygroup.com/5-vpnsitetosite/ CN - Kiến thức cơ bản về Amazon Elastic Compute Cloud (EC2) - Thực hành: + Tạo VPC và Security Group cho Linux và Windows + Khởi chạy Microsoft Windows Server 2022 Instance + Khởi chạy Amazon Linux Instance + Tạo Customer Gateway + Làm quen với các thao tác cơ bản trên EC2 09/21/2025 09/21/2025 https://000004.awsstudygroup.com/ Kết quả đạt được trong tuần 2: Hiểu về VPC và biết cách:\nTạo VPC Tạo Subnet Tạo Internet Gateway Tạo Route Table Tạo Security Group Biết cách tạo và kiểm tra kết nối EC2.\nHiểu cách sử dụng EC2 Instance Connect Endpoint để giúp EC2 private kết nối Internet mà không cần public IP.\nNắm được cách kết nối trung tâm dữ liệu On-premise với Amazon VPC thông qua VPN cứng (hard VPN) hoặc VPN mềm (soft VPN) tùy yêu cầu cụ thể.\nThực hành khởi chạy Instance:\nKhởi chạy Microsoft Windows Server 2022 Instance Khởi chạy Amazon Linux Instance "
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/1-worklog/1.3-week3/",
	"title": "Nhật ký công việc Tuần 3",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Tuần 3: Tiếp tục học về các khái niệm cơ bản của điện toán với Amazon Elastic Compute Cloud (EC2). Tìm hiểu cách cấp quyền cho ứng dụng truy cập vào các dịch vụ AWS. Hiểu và thực hành với Amazon S3 và RDS. Học cách xây dựng ứng dụng trên Amazon Lightsail. Các công việc thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Thực hành: + Khôi phục quyền truy cập vào Windows Instances + Khôi phục quyền truy cập vào Linux Instances + Kết nối Remote Desktop tới EC2-Ubuntu + Lưu trữ bản sao Amazon EBS Snapshots + Chia sẻ AMI 22/09/2025 22/09/2025 https://000004.awsstudygroup.com/5-amazonec2basic/ 3 - Triển khai ứng dụng Quản lý Người dùng AWS trên Amazon Linux 2 - Triển khai ứng dụng Node.js trên Amazon EC2 Windows - Thực hành: + Chuẩn bị máy chủ LAMP + Kiểm tra máy chủ LAMP + Cấu hình máy chủ cơ sở dữ liệu + Cài đặt phpMyAdmin + Cài đặt Node.js trên Amazon Linux 2 + Triển khai ứng dụng trên Linux Instance + Cài đặt XAMPP trên Windows Instance + Cài đặt Node.js trên Windows Instance + Triển khai ứng dụng Quản lý Người dùng AWS trên Windows Server + Quản trị chi phí \u0026amp; mức sử dụng với IAM 23/09/2025 23/09/2025 https://000004.awsstudygroup.com/6-awsfcjmanagement-linux/ 4 - Cấp quyền cho ứng dụng truy cập dịch vụ AWS bằng IAM Role. - Thực hành: + Tạo EC2 Instance + Tạo S3 bucket + Tạo người dùng IAM và cặp Access Key + Sử dụng Access Key + Tạo IAM Role + Gán IAM Role cho EC2 24/09/2025 24/09/2025 https://000048.awsstudygroup.com/ 5 - Tìm hiểu về Simple Storage Service (S3) - Tìm hiểu về Amazon Relational Database Service (RDS) Thực hành: + Tạo S3 và tải dữ liệu lên S3 + Kích hoạt tính năng website tĩnh + Cấu hình chặn truy cập công khai + Cấu hình truy cập công khai cho đối tượng + Kiểm tra website + Chặn toàn bộ truy cập công khai + Cấu hình Amazon CloudFront + Kiểm tra Amazon CloudFront + Bật phiên bản bucket (Bucket Versioning) + Di chuyển đối tượng + Tạo RDS Security Group (sau khi tạo VPC và EC2) + Tạo DB Subnet Group + Triển khai ứng dụng + Sao lưu và khôi phục 25/09/2025 25/09/2025 https://000057.awsstudygroup.com/ https://000005.awsstudygroup.com/ 6 - Workshop Amazon Lightsail - Thực hành: + Triển khai cơ sở dữ liệu trên Lightsail + Triển khai WordPress Instance + Cấu hình Ubuntu + Cấu hình mạng + Cấu hình WordPress + Triển khai lại WordPress Instance + Cấu hình mạng + Triển khai WordPress + Triển khai ứng dụng thương mại điện tử Prestashop + Cấu hình mạng 26/09/2025 26/09/2025 https://000045.awsstudygroup.com/ Thành tựu đạt được trong Tuần 3: Biết cách cấp quyền cho ứng dụng thông qua Access Key / Secret Access Key. Biết cách cấp quyền cho ứng dụng thông qua IAM Role trên EC2. Hiểu và thực hành Amazon S3 và RDS, bao gồm: Tạo S3 và tải dữ liệu lên S3 Cấu hình chặn truy cập công khai Di chuyển các đối tượng trong S3 Tạo instance cơ sở dữ liệu RDS Xây dựng 3 ứng dụng trên Lightsail: Triển khai WordPress Instance Triển khai Prestashop E-Commerce Instance Triển khai Akaunting Instance "
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/1-worklog/1.4-week4/",
	"title": "Nhật ký công việc Tuần 4",
	"tags": [],
	"description": "",
	"content": "Mục tiêu trong Tuần 4 Tìm hiểu về Lightsail Container Học cách triển khai ứng dụng với Amazon EC2 Auto Scaling Xây dựng hệ thống DNS lai (Hybrid DNS) Các nhiệm vụ thực hiện trong tuần Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Tiếp tục Workshop Amazon Lightsail + Bảo mật ứng dụng (Application Security) + Tạo Snapshot + Tạo Alarm 29/09/2025 29/09/2025 https://000045.awsstudygroup.com/ 3 - Chạy ứng dụng trên Amazon Lightsail Container - Thực hành: + Tạo dịch vụ Container trên AWS + Triển khai image công khai + Tạo Lightsail Instance + Cấu hình AWS CLI + Cài đặt Docker trên Ubuntu cho AWS Lightsail + Xây dựng image container + Push image container + Thực hiện triển khai mới (New Deploy) 30/09/2025 30/09/2025 https://000046.awsstudygroup.com/ 4 - Học về Auto Scaling cho ứng dụng với Amazon EC2 Auto Scaling - Thực hành: + Thiết lập hạ tầng mạng (Network Infrastructure) + Khởi tạo EC2 Instance + Tạo cơ sở dữ liệu với RDS + Chuẩn bị dữ liệu cho Database + Triển khai Web Server + Cấu hình metric cho Predictive Scaling + Tạo Launch Template + Tạo Target Group + Tạo Load Balancer + Kiểm thử + Tạo Auto Scaling Group + Kiểm thử scaling thủ công, theo lịch và tự động + Đọc các metric của Predictive Scaling 01/10/2025 01/10/2025 https://000006.awsstudygroup.com/ 5 - AWS CloudWatch Workshop: + Xem Metrics + Biểu thức tìm kiếm (Search expressions) + Biểu thức toán học (Math expressions) + Nhãn động (Dynamic Labels) + CloudWatch Logs + CloudWatch Logs Insights + CloudWatch Metric Filter + CloudWatch Alarms + CloudWatch Dashboards 02/10/2025 02/10/2025 https://000008.awsstudygroup.com/ Thứ 7 - Thiết lập Hybrid DNS với Route 53 Resolver + Tạo Key Pair + Khởi tạo CloudFormation Template + Cấu hình Security Group + Kết nối RDGW + Triển khai Microsoft AD + Tạo Route 53 Outbound Endpoint + Tạo Route 53 Resolver Rules + Tạo Route 53 Inbound Endpoints + Kiểm tra kết quả 04/10/2025 04/10/2025 https://000010.awsstudygroup.com/ Thành tựu đạt được trong Tuần 4 Triển khai và vận hành thành công ứng dụng trên Amazon Lightsail Container, bao gồm:\nTạo và cấu hình dịch vụ container trên AWS. Triển khai image container công khai. Cấu hình AWS CLI để quản lý container trong Lightsail. Triển khai thành công ứng dụng với Amazon EC2 Auto Scaling, giúp hệ thống có khả năng mở rộng tự động theo tải.\nSử dụng AWS CloudWatch để giám sát và thiết lập cảnh báo (Monitoring \u0026amp; Alerting).\nCấu hình hệ thống DNS lai (Hybrid DNS) bằng Route 53 Resolver, bao gồm:\nTạo cặp khóa (Key Pair) và triển khai CloudFormation Template. Cấu hình Security Group và kết nối đến RDGW. Triển khai Microsoft Active Directory và thiết lập các Endpoint (Outbound/InBound) cho Route 53 Resolver. Tạo và kiểm thử các Route 53 Resolver Rules để đảm bảo việc phân giải DNS hoạt động ổn định giữa môi trường On-premises và AWS. "
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/1-worklog/1.5-week5/",
	"title": "Nhật ký công việc Tuần 5",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 5: Học cách sử dụng AWS Command Line Interface (CLI) Tìm hiểu kiến thức cơ bản và thực hành về Amazon ElastiCache - Redis Học và thực hành triển khai AWS Managed Directory Service Nhiệm vụ thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Học cách sử dụng CLI - Thực hành + Cài đặt AWS CLI + Xem tài nguyên qua CLI + AWS CLI với Amazon S3 + AWS CLI với Amazon SNS + AWS CLI với IAM + AWS CLI với VPC + AWS CLI với Internet Gateway + Tạo EC2 bằng AWS CLI - Học kiến thức cơ bản và thực hành về Amazon DynamoDB\n+ Tạo bảng + Ghi dữ liệu + Đọc dữ liệu + Cập nhật dữ liệu + Truy vấn dữ liệu + Tạo chỉ mục phụ toàn cục (GSI) + Truy vấn chỉ mục phụ toàn cục + Sử dụng AWS CloudShell + Cấu hình AWS CLI 06/10/2025 06/10/2025 https://000011.awsstudygroup.com/ https://000060.awsstudygroup.com/ 3 - Học kiến thức cơ bản và thực hành Amazon ElastiCache - Redis + Tạo subnet group bằng console và CLI + Tạo cluster bằng console và CLI + Cấp quyền truy cập cho cluster + Kết nối đến cluster node 07/10/2025 07/10/2025 https://000061.awsstudygroup.com/ 4 - Học và thực hành lưu trữ trang web tĩnh trên Amazon S3 + Tạo bucket S3 + Tải tệp index.html mẫu lên + Cấu hình Amazon CloudFront - Thực hành AWS WorkSpaces + Chuẩn bị triển khai Amazon WorkSpaces + Triển khai Amazon WorkSpaces + Truy cập WorkSpaces bằng trình duyệt + Truy cập WorkSpaces bằng ứng dụng WorkSpaces Client 08/10/2025 08/10/2025 https://000094.awsstudygroup.com/ https://000093.awsstudygroup.com/ 5 - Thực hành Edge Computing với CloudFront và Lambda@Edge + Tạo CloudFront Distribution + Thêm EC2 Origin + Kiểm thử ứng dụng + Kiểm thử xóa bộ nhớ đệm (Distribution Invalidations) + Cấu hình trang lỗi tùy chỉnh + Tạo Origin Group + Cấu hình Response Headers + Tạo Cache Behavior + Tạo hàm Lambda@Edge + Triển khai Lambda@Edge lên CloudFront 09/10/2025 09/10/2025 https://000130.awsstudygroup.com/ T7 - Học và thực hành triển khai AWS Managed Directory Service + Triển khai AWS Managed Directory Service + Triển khai EC2 + Đổi tên máy tính + Cấu hình EC2 + Kiểm tra kết nối giữa các máy chủ 11/10/2025 11/10/2025 https://000095.awsstudygroup.com/ Thành tựu đạt được trong tuần 5: AWS CLI và CloudShell\nĐã cài đặt và cấu hình thành công AWS CLI Thực hành sử dụng AWS CloudShell để quản lý tài nguyên qua dòng lệnh Amazon DynamoDB\nTạo và quản lý bảng dữ liệu DynamoDB Thực hiện thành công các thao tác CRUD (Tạo, Đọc, Cập nhật, Xóa) Lưu trữ trang web tĩnh \u0026amp; WorkSpaces\nLưu trữ nội dung web tĩnh bằng Amazon S3 Cấu hình CloudFront để phân phối nội dung toàn cầu Triển khai và truy cập Amazon WorkSpaces qua trình duyệt và ứng dụng client Điện toán biên (Edge Computing) với CloudFront và Lambda@Edge\nTạo và cấu hình CloudFront Distribution Thiết lập EC2 origin, cache behavior và trang lỗi tùy chỉnh Phát triển và triển khai hàm Lambda@Edge để xử lý tại biên Dịch vụ thư mục quản lý (Managed Microsoft Active Directory)\nTriển khai thành công AWS Managed Directory Service Cấu hình và kết nối EC2 với thư mục quản lý Kiểm thử giao tiếp giữa các máy chủ trong môi trường Directory "
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/1-worklog/1.6-week6/",
	"title": "Nhật ký công việc Tuần 6",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 6: Học và triển khai triển khai WordPress trên AWS Cloud Thực hành tạo và quản lý Máy ảo (Virtual Machines) Học và thực hành quy trình nhập/xuất máy ảo (VM Import/Export) giữa hệ thống tại chỗ và AWS Nhiệm vụ thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 3 - Học và triển khai cài đặt WordPress trên AWS Cloud + Cài đặt WordPress trên EC2 + Tạo AMI từ Webserver Instance + Tạo Launch Template + Tạo Load Balancer + Tạo Auto Scaling Group + Tạo bản sao cơ sở dữ liệu (DB snapshot) + Khôi phục từ DB snapshot + Tạo CloudFront cho Web Server 14/10/2025 14/10/2025 https://000101.awsstudygroup.com/ 4 - Thực hành: Tạo một Máy ảo mới 15/10/2025 15/10/2025 https://000014.awsstudygroup.com/1-deploy-application-server/ 6 - Thực hành quy trình VM Import/Export + Xuất máy ảo từ hệ thống tại chỗ + Tải máy ảo lên AWS + Nhập máy ảo vào AWS + Triển khai Instance từ AMI + Thiết lập quyền truy cập (ACL) cho S3 bucket + Xuất máy ảo từ AMI 17/10/2025 17/10/2025 https://000014.awsstudygroup.com/ Thành tựu tuần 6: Đã triển khai thành công WordPress trên AWS EC2 Đã thực hành tạo và cấu hình máy ảo Hoàn thành quy trình nhập/xuất máy ảo (VM Import/Export): Xuất máy ảo từ hệ thống tại chỗ Tải lên và nhập vào AWS dưới dạng AMI Triển khai và kiểm thử các instance mới thành công "
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/1-worklog/1.7-week7/",
	"title": "Nhật ký công việc Tuần 7",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 7: Học và thực hành về hàm Lambda trong AWS để tự động hóa và tối ưu chi phí Cài đặt và sử dụng Grafana để giám sát tài nguyên trên AWS Học cách quản lý tài nguyên AWS bằng cách sử dụng thẻ (tags) một cách hiệu quả Nhiệm vụ thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 3 - Học và thực hành về các hàm Lambda để tăng hiệu quả chi phí trong môi trường AWS. + Tạo Web-hook Slack + Tạo thẻ cho Instance + Tạo Role cho Lambda + Hàm dừng Instance + Hàm khởi động Instance + Kiểm tra kết quả 21/10/2025 21/10/2025 https://000022.awsstudygroup.com/ 4 - Thực hành sử dụng Grafana để giám sát tài nguyên trên AWS + Cài đặt Grafana + Giám sát bằng Grafana 22/10/2025 22/10/2025 https://000029.awsstudygroup.com/ 5 - Thực hành với Amazon CloudWatch + Xem các chỉ số (Metrics) + Biểu thức tìm kiếm (Search expressions) + Biểu thức toán học (Math expressions) + Nhãn động (Dynamic Labels) + Nhật ký CloudWatch (CloudWatch Logs) 23/10/2025 23/10/2025 https://000036.awsstudygroup.com/ 6 - Thực hành quản lý tài nguyên bằng thẻ (Tags) + Tạo EC2 Instance với thẻ + Quản lý thẻ trong tài nguyên AWS + Lọc tài nguyên theo thẻ + Tạo nhóm tài nguyên (Resource Group) 24/10/2025 24/10/2025 https://000027.awsstudygroup.com/ Thành tựu tuần 7: Đã triển khai các hàm Lambda để tự động khởi động và dừng EC2 Instance Cấu hình tích hợp Slack với Lambda bằng cách sử dụng Web-hook Cài đặt và thiết lập Grafana để trực quan hóa các chỉ số AWS Thực hành các tính năng của CloudWatch như xem chỉ số, biểu thức toán học và nhãn động Tạo và quản lý các thẻ tài nguyên, đồng thời xây dựng nhóm tài nguyên để tổ chức hiệu quả hơn "
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/1-worklog/1.8-week8/",
	"title": "Nhật ký công việc Tuần 8",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 8: Thực hành kiểm soát truy cập EC2 bằng Resource Tags và IAM Policy Làm quen với AWS Systems Manager, bao gồm Patch Manager, Run Command và Session Manager Nhiệm vụ thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Thực hành quy trình kiểm soát truy cập dịch vụ EC2 bằng Resource Tags + Tạo IAM Policy + Tạo IAM Role + Chuyển đổi Role + Truy cập bảng điều khiển EC2 tại vùng Tokyo + Truy cập bảng điều khiển EC2 tại vùng Bắc Virginia + Tạo EC2 instance khi có và không có Tag phù hợp + Chỉnh sửa Tag của EC2 Instance + Kiểm tra Policy 27/10/2025 27/10/2025 https://000028.awsstudygroup.com/ 3 - Thực hành với AWS Systems Manager + Patch Manager + Run Command 28/10/2025 28/10/2025 https://000031.awsstudygroup.com/ 4 - Ôn tập giữa kỳ 29/10/2025 29/10/2025 5 - Ôn tập giữa kỳ 30/10/2025 30/10/2025 6 - Tìm hiểu và thực hành Amazon Systems Manager - Session Manager + Chuẩn bị VPC và EC2 + Kết nối đến Public Instance + Kích hoạt DNS hostnames + Tạo VPC Endpoint + Kết nối đến Instance + Cập nhật IAM Role + Tạo S3 Bucket + Giám sát nhật ký phiên làm việc + Thực hiện Port Forwarding 31/10/2025 31/10/2025 https://000058.awsstudygroup.com/ Thành tựu tuần 8: Đã tạo và kiểm thử thành công IAM Policy, Role và Tag để giới hạn truy cập EC2 theo vùng Sử dụng AWS Systems Manager để quản lý và vá lỗi EC2 từ xa Cấu hình và kết nối EC2 thông qua Session Manager, lưu nhật ký phiên làm việc vào S3 và thực hiện port forwarding "
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/1-worklog/1.9-week9/",
	"title": "Nhật ký công việc Tuần 9",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Tuần 9: Hiểu và thực hành VPC Flow Logs để giám sát lưu lượng mạng Tìm hiểu cách phân quyền truy cập bảng điều khiển thanh toán (Billing Console) bằng IAM Policies Thực hành quản lý giới hạn tài nguyên và chi phí bằng IAM Restrictions Thực hành phát hiện bất thường trong sao lưu EBS (EBS Backup Anomaly Detection) Nhiệm vụ thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Tìm hiểu và thực hành tính năng VPC Flow Logs + Tạo Stack\n+ Tạo VPC Flow Logs\n+ Kích hoạt VPC Flow Logs\n+ Giám sát hạ tầng mạng (Network Infrastructure Monitoring)\n- Thực hành phân quyền truy cập bảng điều khiển thanh toán (Billing Console)\n+ Tạo nhóm người dùng IAM\n+ Kích hoạt quyền truy cập\n+ Tạo IAM Policy\n+ Gán Policy\n+ Kiểm tra truy cập 03/11/2025 03/11/2025 https://000074.awsstudygroup.com/ https://000075.awsstudygroup.com/ 3 - Tìm hiểu và thực hành quản lý tài nguyên và chi phí bằng IAM trên AWS + Giới hạn theo Region + Giới hạn theo họ EC2 + Giới hạn theo kích thước Instance + Giới hạn theo dung lượng EBS Volume 04/11/2025 04/11/2025 https://000064.awsstudygroup.com/ 4 - Thực hành tự động hóa sao lưu và lưu trữ snapshot bằng Data Lifecycle Manager + Sử dụng lịch trình một chính sách (Single Policy Schedule) + Sử dụng nhiều lịch trình (Multiple Policy Schedules) + Kiểm tra kết quả 05/11/2025 05/11/2025 https://000088.awsstudygroup.com/ 5 - Thực hành phát hiện bất thường trong sao lưu AWS Backup cho EBS Volumes + Chuẩn bị S3, EBS, CloudFormation + Kiểm tra tài nguyên đã tạo + Tạo bản sao lưu (Backup) 06/11/2025 06/11/2025 https://000089.awsstudygroup.com/ 6 - Thực hành AWS Toolkit cho VS Code: Amazon Q \u0026amp; CodeWhisperer + Cài đặt AWS Toolkit for Visual Studio Code + Kết nối tài khoản AWS + Thay đổi vùng (Region) + Xác thực người dùng (Authentication) + Tương tác với các dịch vụ AWS (Interacting with Services) 07/11/2025 07/11/2025 https://000087.awsstudygroup.com/ Kết quả đạt được trong Tuần 9: Tạo và kích hoạt thành công VPC Flow Logs để giám sát lưu lượng mạng Phân quyền truy cập bảng điều khiển thanh toán bằng IAM Roles và Policies tùy chỉnh Cấu hình giới hạn tài nguyên sử dụng theo Region, loại Instance, và dung lượng EBS Tự động hóa việc tạo và lưu trữ snapshot bằng Data Lifecycle Manager Thực hiện phát hiện bất thường trong sao lưu (Backup Anomaly Detection) cho EBS Kết nối tài khoản AWS với VS Code Toolkit, trải nghiệm Amazon Q và CodeWhisperer để hỗ trợ phát triển "
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/5-workshop/5.3-s3-vpc/5.3.1-create-gwe/",
	"title": "Tạo một Gateway Endpoint",
	"tags": [],
	"description": "",
	"content": " Mở Amazon VPC console Trong thanh điều hướng, chọn Endpoints, click Create Endpoint: Bạn sẽ thấy 6 điểm cuối VPC hiện có hỗ trợ AWS Systems Manager (SSM). Các điểm cuối này được Mẫu CloudFormation triển khai tự động cho workshop này.\nTrong Create endpoint console: Đặt tên cho endpoint: s3-gwe Trong service category, chọn aws services Trong Services, gõ \u0026ldquo;s3\u0026rdquo; trong hộp tìm kiếm và chọn dịch vụ với loại gateway Đối với VPC, chọn VPC Cloud từ drop-down menu. Đối với Route tables, chọn bảng định tuyến mà đã liên kết với 2 subnets (lưu ý: đây không phải là bảng định tuyến chính cho VPC mà là bảng định tuyến thứ hai do CloudFormation tạo). Đối với Policy, để tùy chọn mặc định là Full access để cho phép toàn quyền truy cập vào dịch vụ. Bạn sẽ triển khai VPC endpoint policy trong phần sau để chứng minh việc hạn chế quyền truy cập vào S3 bucket dựa trên các policies. Không thêm tag vào VPC endpoint. Click Create endpoint, click x sau khi nhận được thông báo tạo thành công. "
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/2-proposal/",
	"title": "Bản đề xuất",
	"tags": [],
	"description": "",
	"content": "\r⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTại phần này, bạn cần tóm tắt các nội dung trong workshop mà bạn dự tính sẽ làm.\nIoT Weather Platform for Lab Research Giải pháp AWS Serverless hợp nhất cho giám sát thời tiết thời gian thực 1. Tóm tắt điều hành IoT Weather Platform được thiết kế dành cho nhóm ITea Lab tại TP. Hồ Chí Minh nhằm nâng cao khả năng thu thập và phân tích dữ liệu thời tiết. Nền tảng hỗ trợ tối đa 5 trạm thời tiết, có khả năng mở rộng lên 10–15 trạm, sử dụng thiết bị biên Raspberry Pi kết hợp cảm biến ESP32 để truyền dữ liệu qua MQTT. Nền tảng tận dụng các dịch vụ AWS Serverless để cung cấp giám sát thời gian thực, phân tích dự đoán và tiết kiệm chi phí, với quyền truy cập giới hạn cho 5 thành viên phòng lab thông qua Amazon Cognito.\n2. Tuyên bố vấn đề Vấn đề hiện tại\nCác trạm thời tiết hiện tại yêu cầu thu thập dữ liệu thủ công, khó quản lý khi có nhiều trạm. Không có hệ thống tập trung cho dữ liệu hoặc phân tích thời gian thực, và các nền tảng bên thứ ba thường tốn kém và quá phức tạp.\nGiải pháp\nNền tảng sử dụng AWS IoT Core để tiếp nhận dữ liệu MQTT, AWS Lambda và API Gateway để xử lý, Amazon S3 để lưu trữ (bao gồm data lake), và AWS Glue Crawlers cùng các tác vụ ETL để trích xuất, chuyển đổi, tải dữ liệu từ S3 data lake sang một S3 bucket khác để phân tích. AWS Amplify với Next.js cung cấp giao diện web, và Amazon Cognito đảm bảo quyền truy cập an toàn. Tương tự như Thingsboard và CoreIoT, người dùng có thể đăng ký thiết bị mới và quản lý kết nối, nhưng nền tảng này hoạt động ở quy mô nhỏ hơn và phục vụ mục đích sử dụng nội bộ. Các tính năng chính bao gồm bảng điều khiển thời gian thực, phân tích xu hướng và chi phí vận hành thấp.\nLợi ích và hoàn vốn đầu tư (ROI)\nGiải pháp tạo nền tảng cơ bản để các thành viên phòng lab phát triển một nền tảng IoT lớn hơn, đồng thời cung cấp nguồn dữ liệu cho những người nghiên cứu AI phục vụ huấn luyện mô hình hoặc phân tích. Nền tảng giảm bớt báo cáo thủ công cho từng trạm thông qua hệ thống tập trung, đơn giản hóa quản lý và bảo trì, đồng thời cải thiện độ tin cậy dữ liệu. Chi phí hàng tháng ước tính 0,66 USD (theo AWS Pricing Calculator), tổng cộng 7,92 USD cho 12 tháng. Tất cả thiết bị IoT đã được trang bị từ hệ thống trạm thời tiết hiện tại, không phát sinh chi phí phát triển thêm. Thời gian hoàn vốn 6–12 tháng nhờ tiết kiệm đáng kể thời gian thao tác thủ công.\n3. Kiến trúc giải pháp Nền tảng áp dụng kiến trúc AWS Serverless để quản lý dữ liệu từ 5 trạm dựa trên Raspberry Pi, có thể mở rộng lên 15 trạm. Dữ liệu được tiếp nhận qua AWS IoT Core, lưu trữ trong S3 data lake và xử lý bởi AWS Glue Crawlers và ETL jobs để chuyển đổi và tải vào một S3 bucket khác cho mục đích phân tích. Lambda và API Gateway xử lý bổ sung, trong khi Amplify với Next.js cung cấp bảng điều khiển được bảo mật bởi Cognito.\nDịch vụ AWS sử dụng\nAWS IoT Core: Tiếp nhận dữ liệu MQTT từ 5 trạm, mở rộng lên 15. AWS Lambda: Xử lý dữ liệu và kích hoạt Glue jobs (2 hàm). Amazon API Gateway: Giao tiếp với ứng dụng web. Amazon S3: Lưu trữ dữ liệu thô (data lake) và dữ liệu đã xử lý (2 bucket). AWS Glue: Crawlers lập chỉ mục dữ liệu, ETL jobs chuyển đổi và tải dữ liệu. AWS Amplify: Lưu trữ giao diện web Next.js. Amazon Cognito: Quản lý quyền truy cập cho người dùng phòng lab. Thiết kế thành phần\nThiết bị biên: Raspberry Pi thu thập và lọc dữ liệu cảm biến, gửi tới IoT Core. Tiếp nhận dữ liệu: AWS IoT Core nhận tin nhắn MQTT từ thiết bị biên. Lưu trữ dữ liệu: Dữ liệu thô lưu trong S3 data lake; dữ liệu đã xử lý lưu ở một S3 bucket khác. Xử lý dữ liệu: AWS Glue Crawlers lập chỉ mục dữ liệu; ETL jobs chuyển đổi để phân tích. Giao diện web: AWS Amplify lưu trữ ứng dụng Next.js cho bảng điều khiển và phân tích thời gian thực. Quản lý người dùng: Amazon Cognito giới hạn 5 tài khoản hoạt động. 4. Triển khai kỹ thuật Các giai đoạn triển khai\nDự án gồm 2 phần — thiết lập trạm thời tiết biên và xây dựng nền tảng thời tiết — mỗi phần trải qua 4 giai đoạn:\nNghiên cứu và vẽ kiến trúc: Nghiên cứu Raspberry Pi với cảm biến ESP32 và thiết kế kiến trúc AWS Serverless (1 tháng trước kỳ thực tập). Tính toán chi phí và kiểm tra tính khả thi: Sử dụng AWS Pricing Calculator để ước tính và điều chỉnh (Tháng 1). Điều chỉnh kiến trúc để tối ưu chi phí/giải pháp: Tinh chỉnh (ví dụ tối ưu Lambda với Next.js) để đảm bảo hiệu quả (Tháng 2). Phát triển, kiểm thử, triển khai: Lập trình Raspberry Pi, AWS services với CDK/SDK và ứng dụng Next.js, sau đó kiểm thử và đưa vào vận hành (Tháng 2–3). Yêu cầu kỹ thuật\nTrạm thời tiết biên: Cảm biến (nhiệt độ, độ ẩm, lượng mưa, tốc độ gió), vi điều khiển ESP32, Raspberry Pi làm thiết bị biên. Raspberry Pi chạy Raspbian, sử dụng Docker để lọc dữ liệu và gửi 1 MB/ngày/trạm qua MQTT qua Wi-Fi. Nền tảng thời tiết: Kiến thức thực tế về AWS Amplify (lưu trữ Next.js), Lambda (giảm thiểu do Next.js xử lý), AWS Glue (ETL), S3 (2 bucket), IoT Core (gateway và rules), và Cognito (5 người dùng). Sử dụng AWS CDK/SDK để lập trình (ví dụ IoT Core rules tới S3). Next.js giúp giảm tải Lambda cho ứng dụng web fullstack. 5. Lộ trình \u0026amp; Mốc triển khai Trước thực tập (Tháng 0): 1 tháng lên kế hoạch và đánh giá trạm cũ. Thực tập (Tháng 1–3): Tháng 1: Học AWS và nâng cấp phần cứng. Tháng 2: Thiết kế và điều chỉnh kiến trúc. Tháng 3: Triển khai, kiểm thử, đưa vào sử dụng. Sau triển khai: Nghiên cứu thêm trong vòng 1 năm. 6. Ước tính ngân sách Có thể xem chi phí trên AWS Pricing Calculator\nHoặc tải tệp ước tính ngân sách.\nChi phí hạ tầng\nAWS Lambda: 0,00 USD/tháng (1.000 request, 512 MB lưu trữ). S3 Standard: 0,15 USD/tháng (6 GB, 2.100 request, 1 GB quét). Truyền dữ liệu: 0,02 USD/tháng (1 GB vào, 1 GB ra). AWS Amplify: 0,35 USD/tháng (256 MB, request 500 ms). Amazon API Gateway: 0,01 USD/tháng (2.000 request). AWS Glue ETL Jobs: 0,02 USD/tháng (2 DPU). AWS Glue Crawlers: 0,07 USD/tháng (1 crawler). MQTT (IoT Core): 0,08 USD/tháng (5 thiết bị, 45.000 tin nhắn). Tổng: 0,7 USD/tháng, 8,40 USD/12 tháng\nPhần cứng: 265 USD một lần (Raspberry Pi 5 và cảm biến). 7. Đánh giá rủi ro Ma trận rủi ro\nMất mạng: Ảnh hưởng trung bình, xác suất trung bình. Hỏng cảm biến: Ảnh hưởng cao, xác suất thấp. Vượt ngân sách: Ảnh hưởng trung bình, xác suất thấp. Chiến lược giảm thiểu\nMạng: Lưu trữ cục bộ trên Raspberry Pi với Docker. Cảm biến: Kiểm tra định kỳ, dự phòng linh kiện. Chi phí: Cảnh báo ngân sách AWS, tối ưu dịch vụ. Kế hoạch dự phòng\nQuay lại thu thập thủ công nếu AWS gặp sự cố. Sử dụng CloudFormation để khôi phục cấu hình liên quan đến chi phí. 8. Kết quả kỳ vọng Cải tiến kỹ thuật: Dữ liệu và phân tích thời gian thực thay thế quy trình thủ công. Có thể mở rộng tới 10–15 trạm.\nGiá trị dài hạn: Nền tảng dữ liệu 1 năm cho nghiên cứu AI, có thể tái sử dụng cho các dự án tương lai.\n"
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/5-workshop/5.2-prerequiste/",
	"title": "Các bước chuẩn bị",
	"tags": [],
	"description": "",
	"content": "IAM permissions Gắn IAM permission policy sau vào tài khoản aws user của bạn để triển khai và dọn dẹp tài nguyên trong workshop này.\n{\r\u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;,\r\u0026#34;Statement\u0026#34;: [\r{\r\u0026#34;Sid\u0026#34;: \u0026#34;VisualEditor0\u0026#34;,\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Action\u0026#34;: [\r\u0026#34;cloudformation:*\u0026#34;,\r\u0026#34;cloudwatch:*\u0026#34;,\r\u0026#34;ec2:AcceptTransitGatewayPeeringAttachment\u0026#34;,\r\u0026#34;ec2:AcceptTransitGatewayVpcAttachment\u0026#34;,\r\u0026#34;ec2:AllocateAddress\u0026#34;,\r\u0026#34;ec2:AssociateAddress\u0026#34;,\r\u0026#34;ec2:AssociateIamInstanceProfile\u0026#34;,\r\u0026#34;ec2:AssociateRouteTable\u0026#34;,\r\u0026#34;ec2:AssociateSubnetCidrBlock\u0026#34;,\r\u0026#34;ec2:AssociateTransitGatewayRouteTable\u0026#34;,\r\u0026#34;ec2:AssociateVpcCidrBlock\u0026#34;,\r\u0026#34;ec2:AttachInternetGateway\u0026#34;,\r\u0026#34;ec2:AttachNetworkInterface\u0026#34;,\r\u0026#34;ec2:AttachVolume\u0026#34;,\r\u0026#34;ec2:AttachVpnGateway\u0026#34;,\r\u0026#34;ec2:AuthorizeSecurityGroupEgress\u0026#34;,\r\u0026#34;ec2:AuthorizeSecurityGroupIngress\u0026#34;,\r\u0026#34;ec2:CreateClientVpnEndpoint\u0026#34;,\r\u0026#34;ec2:CreateClientVpnRoute\u0026#34;,\r\u0026#34;ec2:CreateCustomerGateway\u0026#34;,\r\u0026#34;ec2:CreateDhcpOptions\u0026#34;,\r\u0026#34;ec2:CreateFlowLogs\u0026#34;,\r\u0026#34;ec2:CreateInternetGateway\u0026#34;,\r\u0026#34;ec2:CreateLaunchTemplate\u0026#34;,\r\u0026#34;ec2:CreateNetworkAcl\u0026#34;,\r\u0026#34;ec2:CreateNetworkInterface\u0026#34;,\r\u0026#34;ec2:CreateNetworkInterfacePermission\u0026#34;,\r\u0026#34;ec2:CreateRoute\u0026#34;,\r\u0026#34;ec2:CreateRouteTable\u0026#34;,\r\u0026#34;ec2:CreateSecurityGroup\u0026#34;,\r\u0026#34;ec2:CreateSubnet\u0026#34;,\r\u0026#34;ec2:CreateSubnetCidrReservation\u0026#34;,\r\u0026#34;ec2:CreateTags\u0026#34;,\r\u0026#34;ec2:CreateTransitGateway\u0026#34;,\r\u0026#34;ec2:CreateTransitGatewayPeeringAttachment\u0026#34;,\r\u0026#34;ec2:CreateTransitGatewayPrefixListReference\u0026#34;,\r\u0026#34;ec2:CreateTransitGatewayRoute\u0026#34;,\r\u0026#34;ec2:CreateTransitGatewayRouteTable\u0026#34;,\r\u0026#34;ec2:CreateTransitGatewayVpcAttachment\u0026#34;,\r\u0026#34;ec2:CreateVpc\u0026#34;,\r\u0026#34;ec2:CreateVpcEndpoint\u0026#34;,\r\u0026#34;ec2:CreateVpcEndpointConnectionNotification\u0026#34;,\r\u0026#34;ec2:CreateVpcEndpointServiceConfiguration\u0026#34;,\r\u0026#34;ec2:CreateVpnConnection\u0026#34;,\r\u0026#34;ec2:CreateVpnConnectionRoute\u0026#34;,\r\u0026#34;ec2:CreateVpnGateway\u0026#34;,\r\u0026#34;ec2:DeleteCustomerGateway\u0026#34;,\r\u0026#34;ec2:DeleteFlowLogs\u0026#34;,\r\u0026#34;ec2:DeleteInternetGateway\u0026#34;,\r\u0026#34;ec2:DeleteNetworkInterface\u0026#34;,\r\u0026#34;ec2:DeleteNetworkInterfacePermission\u0026#34;,\r\u0026#34;ec2:DeleteRoute\u0026#34;,\r\u0026#34;ec2:DeleteRouteTable\u0026#34;,\r\u0026#34;ec2:DeleteSecurityGroup\u0026#34;,\r\u0026#34;ec2:DeleteSubnet\u0026#34;,\r\u0026#34;ec2:DeleteSubnetCidrReservation\u0026#34;,\r\u0026#34;ec2:DeleteTags\u0026#34;,\r\u0026#34;ec2:DeleteTransitGateway\u0026#34;,\r\u0026#34;ec2:DeleteTransitGatewayPeeringAttachment\u0026#34;,\r\u0026#34;ec2:DeleteTransitGatewayPrefixListReference\u0026#34;,\r\u0026#34;ec2:DeleteTransitGatewayRoute\u0026#34;,\r\u0026#34;ec2:DeleteTransitGatewayRouteTable\u0026#34;,\r\u0026#34;ec2:DeleteTransitGatewayVpcAttachment\u0026#34;,\r\u0026#34;ec2:DeleteVpc\u0026#34;,\r\u0026#34;ec2:DeleteVpcEndpoints\u0026#34;,\r\u0026#34;ec2:DeleteVpcEndpointServiceConfigurations\u0026#34;,\r\u0026#34;ec2:DeleteVpnConnection\u0026#34;,\r\u0026#34;ec2:DeleteVpnConnectionRoute\u0026#34;,\r\u0026#34;ec2:Describe*\u0026#34;,\r\u0026#34;ec2:DetachInternetGateway\u0026#34;,\r\u0026#34;ec2:DisassociateAddress\u0026#34;,\r\u0026#34;ec2:DisassociateRouteTable\u0026#34;,\r\u0026#34;ec2:GetLaunchTemplateData\u0026#34;,\r\u0026#34;ec2:GetTransitGatewayAttachmentPropagations\u0026#34;,\r\u0026#34;ec2:ModifyInstanceAttribute\u0026#34;,\r\u0026#34;ec2:ModifySecurityGroupRules\u0026#34;,\r\u0026#34;ec2:ModifyTransitGatewayVpcAttachment\u0026#34;,\r\u0026#34;ec2:ModifyVpcAttribute\u0026#34;,\r\u0026#34;ec2:ModifyVpcEndpoint\u0026#34;,\r\u0026#34;ec2:ReleaseAddress\u0026#34;,\r\u0026#34;ec2:ReplaceRoute\u0026#34;,\r\u0026#34;ec2:RevokeSecurityGroupEgress\u0026#34;,\r\u0026#34;ec2:RevokeSecurityGroupIngress\u0026#34;,\r\u0026#34;ec2:RunInstances\u0026#34;,\r\u0026#34;ec2:StartInstances\u0026#34;,\r\u0026#34;ec2:StopInstances\u0026#34;,\r\u0026#34;ec2:UpdateSecurityGroupRuleDescriptionsEgress\u0026#34;,\r\u0026#34;ec2:UpdateSecurityGroupRuleDescriptionsIngress\u0026#34;,\r\u0026#34;iam:AddRoleToInstanceProfile\u0026#34;,\r\u0026#34;iam:AttachRolePolicy\u0026#34;,\r\u0026#34;iam:CreateInstanceProfile\u0026#34;,\r\u0026#34;iam:CreatePolicy\u0026#34;,\r\u0026#34;iam:CreateRole\u0026#34;,\r\u0026#34;iam:DeleteInstanceProfile\u0026#34;,\r\u0026#34;iam:DeletePolicy\u0026#34;,\r\u0026#34;iam:DeleteRole\u0026#34;,\r\u0026#34;iam:DeleteRolePolicy\u0026#34;,\r\u0026#34;iam:DetachRolePolicy\u0026#34;,\r\u0026#34;iam:GetInstanceProfile\u0026#34;,\r\u0026#34;iam:GetPolicy\u0026#34;,\r\u0026#34;iam:GetRole\u0026#34;,\r\u0026#34;iam:GetRolePolicy\u0026#34;,\r\u0026#34;iam:ListPolicyVersions\u0026#34;,\r\u0026#34;iam:ListRoles\u0026#34;,\r\u0026#34;iam:PassRole\u0026#34;,\r\u0026#34;iam:PutRolePolicy\u0026#34;,\r\u0026#34;iam:RemoveRoleFromInstanceProfile\u0026#34;,\r\u0026#34;lambda:CreateFunction\u0026#34;,\r\u0026#34;lambda:DeleteFunction\u0026#34;,\r\u0026#34;lambda:DeleteLayerVersion\u0026#34;,\r\u0026#34;lambda:GetFunction\u0026#34;,\r\u0026#34;lambda:GetLayerVersion\u0026#34;,\r\u0026#34;lambda:InvokeFunction\u0026#34;,\r\u0026#34;lambda:PublishLayerVersion\u0026#34;,\r\u0026#34;logs:CreateLogGroup\u0026#34;,\r\u0026#34;logs:DeleteLogGroup\u0026#34;,\r\u0026#34;logs:DescribeLogGroups\u0026#34;,\r\u0026#34;logs:PutRetentionPolicy\u0026#34;,\r\u0026#34;route53:ChangeTagsForResource\u0026#34;,\r\u0026#34;route53:CreateHealthCheck\u0026#34;,\r\u0026#34;route53:CreateHostedZone\u0026#34;,\r\u0026#34;route53:CreateTrafficPolicy\u0026#34;,\r\u0026#34;route53:DeleteHostedZone\u0026#34;,\r\u0026#34;route53:DisassociateVPCFromHostedZone\u0026#34;,\r\u0026#34;route53:GetHostedZone\u0026#34;,\r\u0026#34;route53:ListHostedZones\u0026#34;,\r\u0026#34;route53domains:ListDomains\u0026#34;,\r\u0026#34;route53domains:ListOperations\u0026#34;,\r\u0026#34;route53domains:ListTagsForDomain\u0026#34;,\r\u0026#34;route53resolver:AssociateResolverEndpointIpAddress\u0026#34;,\r\u0026#34;route53resolver:AssociateResolverRule\u0026#34;,\r\u0026#34;route53resolver:CreateResolverEndpoint\u0026#34;,\r\u0026#34;route53resolver:CreateResolverRule\u0026#34;,\r\u0026#34;route53resolver:DeleteResolverEndpoint\u0026#34;,\r\u0026#34;route53resolver:DeleteResolverRule\u0026#34;,\r\u0026#34;route53resolver:DisassociateResolverEndpointIpAddress\u0026#34;,\r\u0026#34;route53resolver:DisassociateResolverRule\u0026#34;,\r\u0026#34;route53resolver:GetResolverEndpoint\u0026#34;,\r\u0026#34;route53resolver:GetResolverRule\u0026#34;,\r\u0026#34;route53resolver:ListResolverEndpointIpAddresses\u0026#34;,\r\u0026#34;route53resolver:ListResolverEndpoints\u0026#34;,\r\u0026#34;route53resolver:ListResolverRuleAssociations\u0026#34;,\r\u0026#34;route53resolver:ListResolverRules\u0026#34;,\r\u0026#34;route53resolver:ListTagsForResource\u0026#34;,\r\u0026#34;route53resolver:UpdateResolverEndpoint\u0026#34;,\r\u0026#34;route53resolver:UpdateResolverRule\u0026#34;,\r\u0026#34;s3:AbortMultipartUpload\u0026#34;,\r\u0026#34;s3:CreateBucket\u0026#34;,\r\u0026#34;s3:DeleteBucket\u0026#34;,\r\u0026#34;s3:DeleteObject\u0026#34;,\r\u0026#34;s3:GetAccountPublicAccessBlock\u0026#34;,\r\u0026#34;s3:GetBucketAcl\u0026#34;,\r\u0026#34;s3:GetBucketOwnershipControls\u0026#34;,\r\u0026#34;s3:GetBucketPolicy\u0026#34;,\r\u0026#34;s3:GetBucketPolicyStatus\u0026#34;,\r\u0026#34;s3:GetBucketPublicAccessBlock\u0026#34;,\r\u0026#34;s3:GetObject\u0026#34;,\r\u0026#34;s3:GetObjectVersion\u0026#34;,\r\u0026#34;s3:GetBucketVersioning\u0026#34;,\r\u0026#34;s3:ListAccessPoints\u0026#34;,\r\u0026#34;s3:ListAccessPointsForObjectLambda\u0026#34;,\r\u0026#34;s3:ListAllMyBuckets\u0026#34;,\r\u0026#34;s3:ListBucket\u0026#34;,\r\u0026#34;s3:ListBucketMultipartUploads\u0026#34;,\r\u0026#34;s3:ListBucketVersions\u0026#34;,\r\u0026#34;s3:ListJobs\u0026#34;,\r\u0026#34;s3:ListMultipartUploadParts\u0026#34;,\r\u0026#34;s3:ListMultiRegionAccessPoints\u0026#34;,\r\u0026#34;s3:ListStorageLensConfigurations\u0026#34;,\r\u0026#34;s3:PutAccountPublicAccessBlock\u0026#34;,\r\u0026#34;s3:PutBucketAcl\u0026#34;,\r\u0026#34;s3:PutBucketPolicy\u0026#34;,\r\u0026#34;s3:PutBucketPublicAccessBlock\u0026#34;,\r\u0026#34;s3:PutObject\u0026#34;,\r\u0026#34;secretsmanager:CreateSecret\u0026#34;,\r\u0026#34;secretsmanager:DeleteSecret\u0026#34;,\r\u0026#34;secretsmanager:DescribeSecret\u0026#34;,\r\u0026#34;secretsmanager:GetSecretValue\u0026#34;,\r\u0026#34;secretsmanager:ListSecrets\u0026#34;,\r\u0026#34;secretsmanager:ListSecretVersionIds\u0026#34;,\r\u0026#34;secretsmanager:PutResourcePolicy\u0026#34;,\r\u0026#34;secretsmanager:TagResource\u0026#34;,\r\u0026#34;secretsmanager:UpdateSecret\u0026#34;,\r\u0026#34;sns:ListTopics\u0026#34;,\r\u0026#34;ssm:DescribeInstanceProperties\u0026#34;,\r\u0026#34;ssm:DescribeSessions\u0026#34;,\r\u0026#34;ssm:GetConnectionStatus\u0026#34;,\r\u0026#34;ssm:GetParameters\u0026#34;,\r\u0026#34;ssm:ListAssociations\u0026#34;,\r\u0026#34;ssm:ResumeSession\u0026#34;,\r\u0026#34;ssm:StartSession\u0026#34;,\r\u0026#34;ssm:TerminateSession\u0026#34;\r],\r\u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;\r}\r]\r} Khởi tạo tài nguyên bằng CloudFormation Trong lab này, chúng ta sẽ dùng N.Virginia region (us-east-1).\nĐể chuẩn bị cho môi trường làm workshop, chúng ta deploy CloudFormation template sau (click link): PrivateLinkWorkshop . Để nguyên các lựa chọn mặc định.\nLựa chọn 2 mục acknowledgement Chọn Create stack Quá trình triển khai CloudFormation cần khoảng 15 phút để hoàn thành.\n2 VPCs đã được tạo 3 EC2s đã được tạo "
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/5-workshop/5.3-s3-vpc/5.3.2-test-gwe/",
	"title": "Kiểm tra Gateway Endpoint",
	"tags": [],
	"description": "",
	"content": "Tạo S3 bucket Đi đến S3 management console Trong Bucket console, chọn Create bucket Trong Create bucket console Đặt tên bucket: chọn 1 tên mà không bị trùng trong phạm vi toàn cầu (gợi ý: lab\u0026lt;số-lab\u0026gt;\u0026lt;tên-bạn\u0026gt;) Giữ nguyên giá trị của các fields khác (default) Kéo chuột xuống và chọn Create bucket Tạo thành công S3 bucket Kết nối với EC2 bằng session manager Trong workshop này, bạn sẽ dùng AWS Session Manager để kết nối đến các EC2 instances. Session Manager là 1 tính năng trong dịch vụ Systems Manager được quản lý hoàn toàn bởi AWS. System manager cho phép bạn quản lý Amazon EC2 instances và các máy ảo on-premises (VMs)thông qua 1 browser-based shell. Session Manager cung cấp khả năng quản lý phiên bản an toàn và có thể kiểm tra mà không cần mở cổng vào, duy trì máy chủ bastion host hoặc quản lý khóa SSH.\nFirst cloud journey Lab để hiểu sâu hơn về Session manager.\nTrong AWS Management Console, gõ Systems Manager trong ô tìm kiếm và nhấn Enter: Từ Systems Manager menu, tìm Node Management ở thanh bên trái và chọn Session Manager: Click Start Session, và chọn EC2 instance tên Test-Gateway-Endpoint. Phiên bản EC2 này đã chạy trong \u0026ldquo;VPC cloud\u0026rdquo; và sẽ được dùng để kiểm tra khả năng kết nối với Amazon S3 thông qua điểm cuối Cổng mà bạn vừa tạo (s3-gwe).\nSession Manager sẽ mở browser tab mới với shell prompt: sh-4.2 $\nBạn đã bắt đầu phiên kết nối đến EC2 trong VPC Cloud thành công. Trong bước tiếp theo, chúng ta sẽ tạo một S3 bucket và một tệp trong đó.\nCreate a file and upload to s3 bucket Đổi về ssm-user\u0026rsquo;s thư mục bằng lệnh \u0026ldquo;cd ~\u0026rdquo; Tạo 1 file để kiểm tra bằng lệnh \u0026ldquo;fallocate -l 1G testfile.xyz\u0026rdquo;, 1 file tên \u0026ldquo;testfile.xyz\u0026rdquo; có kích thước 1GB sẽ được tạo. Tải file mình vừa tạo lên S3 với lệnh \u0026ldquo;aws s3 cp testfile.xyz s3://your-bucket-name\u0026rdquo;. Thay your-bucket-name bằng tên S3 bạn đã tạo. Bạn đã tải thành công tệp lên bộ chứa S3 của mình. Bây giờ bạn có thể kết thúc session.\nKiểm tra object trong S3 bucket Đi đến S3 console. Click tên s3 bucket của bạn Trong Bucket console, bạn sẽ thấy tệp bạn đã tải lên S3 bucket của mình Tóm tắt Chúc mừng bạn đã hoàn thành truy cập S3 từ VPC. Trong phần này, bạn đã tạo gateway endpoint cho Amazon S3 và sử dụng AWS CLI để tải file lên. Quá trình tải lên hoạt động vì gateway endpoint cho phép giao tiếp với S3 mà không cần Internet gateway gắn vào \u0026ldquo;VPC Cloud\u0026rdquo;. Điều này thể hiện chức năng của gateway endpoint như một đường dẫn an toàn đến S3 mà không cần đi qua pub lic Internet.\n"
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/1-worklog/1.10-week10/",
	"title": "Nhật ký công việc Tuần 10",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Tuần 10: Hiểu và thực hành các chủ đề bảo mật AWS, bao gồm giới hạn vai trò, Security Hub và KMS. Kích hoạt, sử dụng và phân tích các phát hiện từ AWS Security Hub để đánh giá mức độ tuân thủ và tình trạng bảo mật. Triển khai mã hóa dữ liệu khi lưu trữ bằng AWS KMS trên các dịch vụ như Amazon S3, AWS CloudTrail và Amazon Athena. Các nhiệm vụ trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Tìm hiểu về IAM Permission Boundary + Tạo Restriction Policy + Tạo IAM Limited User + Kiểm tra giới hạn quyền của IAM User 10/11/2025 10/11/2025 https://000030.awsstudygroup.com/ 3 - Thực hành tạo Role và tăng cường bảo mật bằng cách đặt giới hạn theo địa chỉ IP và thời gian + Tạo IAM Group + Tạo IAM User + Tạo Admin IAM Role + Cấu hình Switch Role + Giới hạn quyền truy cập Role 11/11/2025 11/11/2025 https://000044.awsstudygroup.com/ 4 - Bắt đầu với AWS Security Hub + Kích hoạt Security Hub + Xem điểm số cho từng bộ tiêu chí 12/11/2025 12/11/2025 https://000018.awsstudygroup.com/ 5 - Mã hóa dữ liệu khi lưu trữ bằng AWS KMS + Tạo Key Management Service + Tạo Amazon S3 + Tạo AWS CloudTrail và Amazon Athena + Kiểm tra và chia sẻ dữ liệu đã mã hóa trên S3 13/11/2025 13/11/2025 https://cloudjourney.awsstudygroup.com/ Thành tựu Tuần 10: Đã cấu hình IAM Permission Boundaries bằng cách tạo Restriction Policy, tạo IAM Limited User và kiểm tra việc giới hạn quyền được áp dụng chính xác. Đã tạo IAM Roles, Groups và Users; áp dụng các giới hạn bổ sung như lọc theo địa chỉ IP và giới hạn theo thời gian; và cấu hình chuyển đổi Role. Đã kích hoạt AWS Security Hub, xem điểm đánh giá và phân tích các phát hiện từ nhiều bộ tiêu chí bảo mật khác nhau. Đã tạo và cấu hình KMS Key, áp dụng mã hóa dữ liệu lưu trữ cho Amazon S3, bật CloudTrail logging, truy vấn nhật ký bằng Athena và kiểm thử chia sẻ dữ liệu đã mã hóa trên S3. "
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/1-worklog/1.11-week11/",
	"title": "Nhật ký công việc Tuần 11",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 11: Thực hành sử dụng Amazon S3 và Amazon Macie để phân loại và bảo vệ dữ liệu Triển khai AWS Cognito trên nhiều site để quản lý xác thực tập trung Làm quen với AWS Backup để tạo kế hoạch sao lưu, cài đặt thông báo và thử nghiệm phục hồi dữ liệu Thực hành thiết lập kết nối VPC Peering giữa hai VPC Học và triển khai các biện pháp bảo mật tốt nhất cho Amazon S3, bao gồm mã hóa, kiểm soát truy cập và bắt buộc HTTPS Các nhiệm vụ trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Thực hành sử dụng S3 và Amazon Macie + Chuẩn bị S3 và bật Macie + Tạo Custom data identifiers + Tạo một Macie job + Chạy Macie job và kiểm tra kết quả 17/11/2025 17/11/2025 https://000090.awsstudygroup.com/ 3 - Triển khai AWS Cognito trên nhiều site + Chuẩn bị tài nguyên + Giải thích về code + Triển khai và kiểm tra Cognito Cross Sites 18/11/2025 18/11/2025 https://000141.awsstudygroup.com/ 4 - Làm quen với AWS Backup + Chuẩn bị S3 và triển khai hạ tầng + Tạo kế hoạch sao lưu + Cài đặt thông báo + Thử nghiệm phục hồi dữ liệu 19/11/2025 19/11/2025 https://000013.awsstudygroup.com/ 5 - Thực hành thiết lập VPC Peering giữa hai VPC + Chuẩn bị CloudFormation Template, SG, EC2 + Cập nhật Network ACL + VPC Peering + Cập nhật Route Tables + Thiết lập Cross-Peer DNS 20/11/2025 20/11/2025 https://000019.awsstudygroup.com/ 6 - Thực hành các biện pháp bảo mật tốt nhất để bảo vệ dữ liệu trên Amazon S3 + Chuẩn bị CloudFormation Template, thiết lập mạng an toàn, tạo access key, EC2, S3 + Bắt buộc HTTPS + Bắt buộc mã hóa SSE-S3 + Chặn Public ACLs + Cấu hình S3 Block Public Access + Giới hạn truy cập qua S3 VPC Endpoint 21/11/2025 21/11/2025 https://000069.awsstudygroup.com/ Thành tựu tuần 11: Cấu hình thành công S3 và Amazon Macie, tạo custom data identifiers, chạy Macie job và kiểm tra kết quả Triển khai và kiểm tra AWS Cognito trên nhiều site, đảm bảo xác thực và quản lý truy cập chính xác Tạo kế hoạch sao lưu với AWS Backup, cài đặt thông báo và thử nghiệm phục hồi dữ liệu thành công Thiết lập kết nối VPC Peering giữa hai VPC, cập nhật route tables, network ACLs và bật Cross-VPC DNS resolution Triển khai các biện pháp bảo mật S3: bắt buộc HTTPS, bật SSE-S3 encryption, chặn public ACLs, cấu hình S3 Block Public Access và giới hạn truy cập qua VPC Endpoint "
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/1-worklog/1.12-week12/",
	"title": "Nhật ký công việc Tuần 12",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Tuần 12: Thực hành kết nối nhiều VPC bằng AWS Transit Gateway, bao gồm tạo attachments và cấu hình route tables. Hiểu và thực hành các mô hình tối ưu chi phí của AWS: Savings Plans, Reserved Instances và Reserved DB Instances. Thực hành phân quyền truy cập Billing Console bằng IAM: tạo Group, Policy và kiểm thử quyền truy cập. Tìm hiểu và thực hành các thao tác cơ bản với Amazon DynamoDB: tạo bảng, đọc/ghi dữ liệu, cập nhật, truy vấn, tạo Global Secondary Index và sử dụng AWS CLI trong CloudShell để thao tác. Các nhiệm vụ thực hiện trong tuần này: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Sử dụng AWS Transit Gateway để kết nối nhiều VPC + Tạo Transit Gateway + Tạo Transit Gateway Attachments + Tạo Transit Gateway Route Tables + Thêm tuyến Transit Gateway vào Route Tables của VPC 24/11/2025 24/11/2025 https://000020.awsstudygroup.com/ 3 - Thực hành Savings Plans, Reserved Instance và Reserved DB Instance + Savings Plans Recommendation + Mua Savings Plans + Reserved Instance + Reserved DB Instances 25/11/2025 25/11/2025 https://000042.awsstudygroup.com/ 4 - Thực hành phân quyền truy cập Billing Console\n+ Tạo IAM User Group\n+ Bật quyền truy cập\n+ Tạo IAM Policy\n+ Gán Policy\n+ Kiểm thử quyền truy cập 26/11/2025 26/11/2025 https://000075.awsstudygroup.com/ 5 - Tìm hiểu và thực hành Amazon DynamoDB\n+ Tạo bảng + Ghi dữ liệu + Đọc dữ liệu + Cập nhật dữ liệu + Truy vấn dữ liệu + Tạo Global Secondary Index + Truy vấn GSI + Sử dụng AWS CloudShell + Cấu hình AWS CLI 27/11/2025 27/11/2025 https://000060.awsstudygroup.com/ Thành tựu Tuần 12: Tạo thành công AWS Transit Gateway, cấu hình attachments, tạo bảng định tuyến Transit Gateway và cập nhật route tables của VPC để kết nối nhiều VPC với nhau. Phân tích và áp dụng Savings Plans Recommendations, mua Savings Plans, thực hành tạo Reserved Instances và Reserved DB Instances nhằm tối ưu chi phí. Thiết lập phân quyền Billing Console bằng IAM: tạo nhóm người dùng, bật quyền truy cập, tạo IAM Policy tùy chỉnh, gán Policy và kiểm thử truy cập thành công. Thực hành với Amazon DynamoDB: tạo bảng, chèn dữ liệu, đọc và truy vấn dữ liệu, cập nhật mục dữ liệu, tạo và truy vấn Global Secondary Index; đồng thời sử dụng CloudShell và AWS CLI để thao tác DynamoDB qua dòng lệnh. "
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/5-workshop/5.4-s3-onprem/5.4.2-create-interface-enpoint/",
	"title": "Tạo một S3 Interface endpoint",
	"tags": [],
	"description": "",
	"content": "Trong phần này, bạn sẽ tạo và kiểm tra Interface Endpoint S3 bằng cách sử dụng môi trường truyền thống mô phỏng.\nQuay lại Amazon VPC menu. Trong thanh điều hướng bên trái, chọn Endpoints, sau đó click Create Endpoint.\nTrong Create endpoint console:\nĐặt tên interface endpoint Trong Service category, chọn aws services Trong Search box, gõ S3 và nhấn Enter. Chọn endpoint có tên com.amazonaws.us-east-1.s3. Đảm bảo rằng cột Type có giá trị Interface. Đối với VPC, chọn VPC Cloud từ drop-down. Đảm bảo rằng bạn chọn \u0026ldquo;VPC Cloud\u0026rdquo; và không phải \u0026ldquo;VPC On-prem\u0026rdquo;\nMở rộng Additional settings và đảm bảo rằng Enable DNS name không được chọn (sẽ sử dụng điều này trong phần tiếp theo của workshop) Chọn 2 subnets trong AZs sau: us-east-1a and us-east-1b Đối với Security group, chọn SGforS3Endpoint: Giữ default policy - full access và click Create endpoint Chúc mừng bạn đã tạo thành công S3 interface endpoint. Ở bước tiếp theo, chúng ta sẽ kiểm tra interface endpoint.\n"
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/3-blogstranslated/",
	"title": "Các bài blogs đã dịch",
	"tags": [],
	"description": "",
	"content": "Blog 1 - Heroku di chuyển cơ sở dữ liệu PostgreSQL sang Amazon Aurora Bài blog này giải thích cách Heroku di chuyển hàng trăm nghìn cơ sở dữ liệu PostgreSQL tự quản trên Amazon EC2 sang Amazon Aurora PostgreSQL-Compatible Edition. Bạn sẽ tìm hiểu những thách thức khi quản lý các hệ thống cơ sở dữ liệu quy mô lớn, cách Aurora giảm gánh nặng vận hành đồng thời tăng độ tin cậy và khả năng mở rộng, và cách Heroku sử dụng công cụ di chuyển song song cùng kiểm thử kỹ lưỡng để chuyển dữ liệu mà ảnh hưởng tối thiểu tới khách hàng. Bài viết cũng nêu các lợi ích của kiến trúc mới, bao gồm tăng khả năng quan sát, tính năng AI cho quản trị cơ sở dữ liệu, và gần như không gián đoạn dịch vụ.\nBlog 2 - Đẩy nhanh nghiên cứu Alzheimer thông qua phân tích bộ gen chức năng quy mô lớn với AWS Cloud Bài blog này cho thấy cách phòng thí nghiệm của Tiến sĩ Gao Wang tại Đại học Columbia sử dụng điện toán đám mây AWS để thúc đẩy nghiên cứu Alzheimer thông qua genomics chức năng. Bạn sẽ tìm hiểu cách phân tích QTL phân tử quy mô lớn giúp khám phá cơ chế di truyền của Alzheimer, cách các công cụ đám mây như MMCloud và EC2 Spot Instances cho phép xử lý song song hàng trăm nghìn công việc, đồng thời tăng tốc khám phá, giảm chi phí và hỗ trợ hợp tác toàn cầu. Bài viết còn đề cập việc tích hợp dữ liệu đa omics để xác định mục tiêu trị liệu và các dấu sinh học (biomarkers).\nBlog 3 - AWS Marketplace được đánh giá “Awardable” cho các dự án DoD trong P1 Solutions Marketplace Bài blog này giới thiệu cách AWS Marketplace đạt trạng thái “Awardable” trong Platform One (P1) Solutions Marketplace của Bộ Quốc phòng Mỹ (DoD). Bạn sẽ tìm hiểu cách trạng thái này giúp các tổ chức DoD truy cập dễ dàng hơn hơn 4.000 giải pháp đã được xác minh, tăng tốc triển khai công nghệ, đảm bảo tuân thủ quy định mua sắm liên bang, tập trung quản lý giấy phép và hóa đơn, đồng thời tối ưu chi phí CNTT. Bài viết cũng minh họa cách AWS Marketplace hỗ trợ các nhiệm vụ quốc phòng quan trọng bằng việc kết nối DoD với các công nghệ thương mại tiên tiến.\n"
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/5-workshop/5.4-s3-onprem/5.4.3-test-endpoint/",
	"title": "Kiểm tra Interface Endpoint",
	"tags": [],
	"description": "",
	"content": "Lấy regional DNS name (tên DNS khu vực) của S3 interface endpoint Trong Amazon VPC menu, chọn Endpoints.\nClick tên của endpoint chúng ta mới tạo ở mục 4.2: s3-interface-endpoint. Click details và lưu lại regional DNS name của endpoint (cái đầu tiên) vào text-editor của bạn để dùng ở các bước sau.\nKết nối đến EC2 instance ở trong \u0026ldquo;VPC On-prem\u0026rdquo; (giả lập môi trường truyền thống) Đi đến Session manager bằng cách gõ \u0026ldquo;session manager\u0026rdquo; vào ô tìm kiếm\nClick Start Session, chọn EC2 instance có tên Test-Interface-Endpoint. EC2 instance này đang chạy trên \u0026ldquo;VPC On-prem\u0026rdquo; và sẽ được sử dụng để kiểm tra kết nối đến Amazon S3 thông qua Interface endpoint. Session Manager sẽ mở 1 browser tab mới với shell prompt: sh-4.2 $\nĐi đến ssm-user\u0026rsquo;s home directory với lệnh \u0026ldquo;cd ~\u0026rdquo;\nTạo 1 file tên testfile2.xyz\nfallocate -l 1G testfile2.xyz Copy file vào S3 bucket mình tạo ở section 4.2 aws s3 cp --endpoint-url https://bucket.\u0026lt;Regional-DNS-Name\u0026gt; testfile2.xyz s3://\u0026lt;your-bucket-name\u0026gt; Câu lệnh này yêu cầu thông số \u0026ndash;endpoint-url, bởi vì bạn cần sử dụng DNS name chỉ định cho endpoint để truy cập vào S3 thông qua Interface endpoint. Không lấy \u0026rsquo; * \u0026rsquo; khi copy/paste tên DNS khu vực. Cung cấp tên S3 bucket của bạn Bây giờ tệp đã được thêm vào bộ chứa S3 của bạn. Hãy kiểm tra bộ chứa S3 của bạn trong bước tiếp theo.\nKiểm tra Object trong S3 bucket Đi đến S3 console Click Buckets Click tên bucket của bạn và bạn sẽ thấy testfile2.xyz đã được thêm vào s3 bucket của bạn "
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/5-workshop/5.3-s3-vpc/",
	"title": "Truy cập S3 từ VPC",
	"tags": [],
	"description": "",
	"content": "Sử dụng Gateway endpoint Trong phần này, bạn sẽ tạo một Gateway endpoint để truy cập Amazon S3 từ một EC2 instance. Gateway endpoint sẽ cho phép tải một object lên S3 bucket mà không cần sử dụng Internet Công cộng. Để tạo endpoint, bạn phải chỉ định VPC mà bạn muốn tạo endpoint và dịch vụ (trong trường hợp này là S3) mà bạn muốn thiết lập kết nối.\nNội dung Tạo gateway endpoint Test gateway endpoint "
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/4-eventparticipated/",
	"title": "Các events đã tham gia",
	"tags": [],
	"description": "",
	"content": "Trong quá trình thực tập, em đã tham gia 4 events, với mỗi event là một trải nghiệm đáng nhớ với những kiến thức mới, hay và bổ ích, cùng với đó là nhứng món quà và những khoảnh khắc rất tuyệt vời.\nEvent 1 Tên sự kiện: Vietnam Cloud Day 2025 : Ho Chi Minh City Connect Edition for Builders\nThời gian: 09:00 ngày 18/09/2025\nĐịa điểm: Tầng 26 \u0026amp; 36, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 2 Tên sự kiện: AI/ML/GenAI on AWS Workshop (AWS Cloud Mastery Series #1)\nThời gian: 09:00 ngày 15/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 3 Tên sự kiện: ​DevOps on AWS AWS Cloud Mastery Series #2\nThời gian: 08:30 ngày 17/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 4 Tên sự kiện: AWS Well-Architected Security Pillar AWS Cloud Mastery Series #3\nThời gian: 08:30 ngày 29/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\n"
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/5-workshop/5.4-s3-onprem/5.4.4-dns-simulation/",
	"title": "Mô phỏng On-premises DNS ",
	"tags": [],
	"description": "",
	"content": "AWS PrivateLink endpoint có một địa chỉ IP cố định trong từng AZ nơi chúng được triển khai, trong suốt thời gian tồn tại của endpoint (cho đến khi endpoint bị xóa). Các địa chỉ IP này được gắn vào Elastic network interface (ENI). AWS khuyến nghị sử dụng DNS để resolve địa chỉ IP cho endpoint để các ứng dụng downstream sử dụng địa chỉ IP mới nhất khi ENIs được thêm vào AZ mới hoặc bị xóa theo thời gian.\nTrong phần này, bạn sẽ tạo một quy tắc chuyển tiếp (forwarding rule) để gửi các yêu cầu resolve DNS từ môi trường truyền thống (mô phỏng) đến Private Hosted Zone trên Route 53. Phần này tận dụng cơ sở hạ tầng do CloudFormation triển khai trong phần Chuẩn bị môi trường.\nTạo DNS Alias Records cho Interface endpoint Click link để đi đến Route 53 management console (Hosted Zones section). Mẫu CloudFormation mà bạn triển khai trong phần Chuẩn bị môi trường đã tạo Private Hosted Zone này. Nhấp vào tên của Private Hosted Zone, s3.us-east-1.amazonaws.com: Tạo 1 record mới trong Private Hosted Zone: Giữ nguyên Record name và record type Alias Button: click để enable Route traffic to: Alias to VPC Endpoint Region: US East (N. Virginia) [us-east-1] Chọn endpoint: Paste tên (Regional VPC Endpoint DNS) bạn đã lưu lại ở phần 4.3 Click Add another record, và add 1 cái record thứ 2 sử dụng những thông số sau: Record name: *. Record type: giữ giá trị default (type A) Alias Button: Click để enable Route traffic to: Alias to VPC Endpoint Region: US East (N. Virginia) [us-east-1] Chọn endpoint: Paste tên (Regional VPC Endpoint DNS) bạn đã lưu lại ở phần 4.3 Click Create records Record mới xuất hiện trên giao diện Route 53.\nTạo một Resolver Forwarding Rule Route 53 Resolver Forwarding Rules cho phép bạn chuyển tiếp các DNS queries từ VPC của bạn đến các nguồn khác để resolve name. Bên ngoài môi trường workshop, bạn có thể sử dụng tính năng này để chuyển tiếp các DNS queries từ VPC của bạn đến các máy chủ DNS chạy trên on-premises. Trong phần này, bạn sẽ mô phỏng một on-premises conditional forwarder bằng cách tạo một forwarding rule để chuyển tiếp các DNS queries for Amazon S3 đến một Private Hosted Zone chạy trong \u0026ldquo;VPC Cloud\u0026rdquo; để resolve PrivateLink interface endpoint regional DNS name.\nTừ giao diện Route 53, chọn Inbound endpoints trên thanh bên trái\nTrong giao diện Inbound endpoint, Chọn ID của Inbound endpoint.\nSao chép 2 địa chỉ IP trong danh sách vào trình chỉnh sửa. Từ giao diện Route 53, chọn Resolver \u0026gt; Rules và chọn Create rule Trong giao diện Create rule Name: myS3Rule Rule type: Forward Domain name: s3.us-east-1.amazonaws.com VPC: VPC On-prem Outbound endpoint: VPCOnpremOutboundEndpoint Target IP Addresses: điền cả hai IP bạn đã lưu trữ trên trình soạn thảo (inbound endpoint addresses) và sau đó chọn Submit Bạn đã tạo thành công resolver forwarding rule.\nKiểm tra on-premises DNS mô phỏng. Kết nối đến Test-Interface-Endpoint EC2 instance với Session Manager Kiểm tra DNS resolution. Lệnh dig sẽ trả về địa chỉ IP được gán cho VPC endpoint interface đang chạy trên VPC (địa chỉ IP của bạn sẽ khác): dig +short s3.us-east-1.amazonaws.com Các địa chỉ IP được trả về là các địa chỉ IP VPC enpoint, KHÔNG phải là các địa chỉ IP Resolver mà bạn đã dán từ trình chỉnh sửa văn bản của mình. Các địa chỉ IP của Resolver endpoint và VPC endpoin trông giống nhau vì chúng đều từ khối CIDR VPC Cloud.\nTruy cập vào menu VPC (phần Endpoints), chọn S3 interface endpoint. Nhấp vào tab Subnets và xác nhận rằng các địa chỉ IP được trả về bởi lệnh Dig khớp với VPC endpoint: Hãy quay lại shell của bạn và sử dụng AWS CLI để kiểm tra danh sách các bucket S3 của bạn: aws s3 ls --endpoint-url https://s3.us-east-1.amazonaws.com Kết thúc phiên làm việc của Session Manager của bạn: Trong phần này, bạn đã tạo một Interface Endpoint cho Amazon S3. Điểm cuối này có thể được truy cập từ on-premises thông qua Site-to-Site VPN hoặc AWS Direct Connect. Các điểm cuối Route 53 Resolver outbound giả lập chuyển tiếp các yêu cầu DNS từ on-premises đến một Private Hosted Zone đang chạy trên đám mây. Các điểm cuối Route 53 inbound nhận yêu cầu giải quyết và trả về một phản hồi chứa địa chỉ IP của Interface Endpoint VPC. Sử dụng DNS để giải quyết các địa chỉ IP của điểm cuối cung cấp tính sẵn sàng cao trong trường hợp một Availability Zone gặp sự cố.\n"
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/5-workshop/5.4-s3-onprem/",
	"title": "Truy cập S3 từ môi trường truyền thống",
	"tags": [],
	"description": "",
	"content": "Tổng quan Trong phần này, bạn sẽ tạo một Interface Endpoint để truy cập Amazon S3 từ môi trường truyền thống mô phỏng. Interface Endpoint sẽ cho phép bạn định tuyến đến Amazon S3 qua kết nối VPN từ môi trường truyền thống mô phỏng của bạn.\nTại sao nên sử dụng Interface Endpoint:\nCác Gateway endpoints chỉ hoạt động với các tài nguyên đang chạy trong VPC nơi chúng được tạo. Interface Endpoint hoạt động với tài nguyên chạy trong VPC và cả tài nguyên chạy trong môi trường truyền thống. Khả năng kết nối từ môi trường truyền thống của bạn với aws cloud có thể được cung cấp bởi AWS Site-to-Site VPN hoặc AWS Direct Connect. Interface Endpoint cho phép bạn kết nối với các dịch vụ do AWS PrivateLink cung cấp. Các dịch vụ này bao gồm một số dịch vụ AWS, dịch vụ do các đối tác và khách hàng AWS lưu trữ trong VPC của riêng họ (gọi tắt là Dịch vụ PrivateLink endpoints) và các dịch vụ Đối tác AWS Marketplace. Đối với workshop này, chúng ta sẽ tập trung vào việc kết nối với Amazon S3. "
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/5-workshop/5.5-policy/",
	"title": "VPC Endpoint Policies",
	"tags": [],
	"description": "",
	"content": "Khi bạn tạo một Interface Endpoint hoặc cổng, bạn có thể đính kèm một chính sách điểm cuối để kiểm soát quyền truy cập vào dịch vụ mà bạn đang kết nối. Chính sách VPC Endpoint là chính sách tài nguyên IAM mà bạn đính kèm vào điểm cuối. Nếu bạn không đính kèm chính sách khi tạo điểm cuối, thì AWS sẽ đính kèm chính sách mặc định cho bạn để cho phép toàn quyền truy cập vào dịch vụ thông qua điểm cuối.\nBạn có thể tạo chính sách chỉ hạn chế quyền truy cập vào các S3 bucket cụ thể. Điều này hữu ích nếu bạn chỉ muốn một số Bộ chứa S3 nhất định có thể truy cập được thông qua điểm cuối.\nTrong phần này, bạn sẽ tạo chính sách VPC Endpoint hạn chế quyền truy cập vào S3 bucket được chỉ định trong chính sách VPC Endpoint.\nKết nối tới EC2 và xác minh kết nối tới S3. Bắt đầu một phiên AWS Session Manager mới trên máy chủ có tên là Test-Gateway-Endpoint. Từ phiên này, xác minh rằng bạn có thể liệt kê nội dung của bucket mà bạn đã tạo trong Phần 1: Truy cập S3 từ VPC. aws s3 ls s3://\u0026lt;your-bucket-name\u0026gt; Nội dung của bucket bao gồm hai tệp có dung lượng 1GB đã được tải lên trước đó.\nTạo một bucket S3 mới; tuân thủ mẫu đặt tên mà bạn đã sử dụng trong Phần 1, nhưng thêm \u0026lsquo;-2\u0026rsquo; vào tên. Để các trường khác là mặc định và nhấp vào Create. Tạo bucket thành công. Policy mặc định cho phép truy cập vào tất cả các S3 Buckets thông qua VPC endpoint.\nTrong giao diện Edit Policy, sao chép và dán theo policy sau, thay thế yourbucketname-2 với tên bucket thứ hai của bạn. Policy này sẽ cho phép truy cập đến bucket mới thông qua VPC endpoint, nhưng không cho phép truy cập đến các bucket còn lại. Chọn Save để kích hoạt policy. {\r\u0026#34;Id\u0026#34;: \u0026#34;Policy1631305502445\u0026#34;,\r\u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;,\r\u0026#34;Statement\u0026#34;: [\r{\r\u0026#34;Sid\u0026#34;: \u0026#34;Stmt1631305501021\u0026#34;,\r\u0026#34;Action\u0026#34;: \u0026#34;s3:*\u0026#34;,\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Resource\u0026#34;: [\r\u0026#34;arn:aws:s3:::yourbucketname-2\u0026#34;,\r\u0026#34;arn:aws:s3:::yourbucketname-2/*\u0026#34;\r],\r\u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34;\r}\r]\r} Cấu hình policy thành công.\nTừ session của bạn trên Test-Gateway-Endpoint instance, kiểm tra truy cập đến S3 bucket bạn tạo ở bước đầu aws s3 ls s3://\u0026lt;yourbucketname\u0026gt; Câu lệnh trả về lỗi bởi vì truy cập vào S3 bucket không có quyền trong VPC endpoint policy.\nTrở lại home directory của bạn trên EC2 instance cd~ Tạo file fallocate -l 1G test-bucket2.xyz Sao chép file lên bucket thứ 2 aws s3 cp test-bucket2.xyz s3://\u0026lt;your-2nd-bucket-name\u0026gt; Thao tác này được cho phép bởi VPC endpoint policy.\nSau đó chúng ta kiểm tra truy cập vào S3 bucket đầu tiên\naws s3 cp test-bucket2.xyz s3://\u0026lt;your-1st-bucket-name\u0026gt;\nCâu lệnh xảy ra lỗi bởi vì bucket không có quyền truy cập bởi VPC endpoint policy.\nTrong phần này, bạn đã tạo chính sách VPC Endpoint cho Amazon S3 và sử dụng AWS CLI để kiểm tra chính sách. Các hoạt động AWS CLI liên quan đến bucket S3 ban đầu của bạn thất bại vì bạn áp dụng một chính sách chỉ cho phép truy cập đến bucket thứ hai mà bạn đã tạo. Các hoạt động AWS CLI nhắm vào bucket thứ hai của bạn thành công vì chính sách cho phép chúng. Những chính sách này có thể hữu ích trong các tình huống khi bạn cần kiểm soát quyền truy cập vào tài nguyên thông qua VPC Endpoint.\n"
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/5-workshop/",
	"title": "Workshop",
	"tags": [],
	"description": "",
	"content": "\r⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nĐảm bảo truy cập Hybrid an toàn đến S3 bằng cách sử dụng VPC endpoint Tổng quan AWS PrivateLink cung cấp kết nối riêng tư đến các dịch vụ aws từ VPCs hoặc trung tâm dữ liệu (on-premise) mà không làm lộ lưu lượng truy cập ra ngoài public internet.\nTrong bài lab này, chúng ta sẽ học cách tạo, cấu hình, và kiểm tra VPC endpoints để cho phép workload của bạn tiếp cận các dịch vụ AWS mà không cần đi qua Internet công cộng.\nChúng ta sẽ tạo hai loại endpoints để truy cập đến Amazon S3: gateway vpc endpoint và interface vpc endpoint. Hai loại vpc endpoints này mang đến nhiều lợi ích tùy thuộc vào việc bạn truy cập đến S3 từ môi trường cloud hay từ trung tâm dữ liệu (on-premise).\nGateway - Tạo gateway endpoint để gửi lưu lượng đến Amazon S3 hoặc DynamoDB using private IP addresses. Bạn điều hướng lưu lượng từ VPC của bạn đến gateway endpoint bằng các bảng định tuyến (route tables) Interface - Tạo interface endpoint để gửi lưu lượng đến các dịch vụ điểm cuối (endpoints) sử dụng Network Load Balancer để phân phối lưu lượng. Lưu lượng dành cho dịch vụ điểm cuối được resolved bằng DNS. Nội dung Tổng quan về workshop Chuẩn bị Truy cập đến S3 từ VPC Truy cập đến S3 từ TTDL On-premises VPC Endpoint Policies (làm thêm) Dọn dẹp tài nguyên "
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/5-workshop/5.6-cleanup/",
	"title": "Dọn dẹp tài nguyên",
	"tags": [],
	"description": "",
	"content": "Dọn dẹp tài nguyên Xin chúc mừng bạn đã hoàn thành xong lab này! Trong lab này, bạn đã học về các mô hình kiến trúc để truy cập Amazon S3 mà không sử dụng Public Internet.\nBằng cách tạo Gateway endpoint, bạn đã cho phép giao tiếp trực tiếp giữa các tài nguyên EC2 và Amazon S3, mà không đi qua Internet Gateway. Bằng cách tạo Interface endpoint, bạn đã mở rộng kết nối S3 đến các tài nguyên chạy trên trung tâm dữ liệu trên chỗ của bạn thông qua AWS Site-to-Site VPN hoặc Direct Connect. Dọn dẹp Điều hướng đến Hosted Zones trên phía trái của bảng điều khiển Route 53. Nhấp vào tên của s3.us-east-1.amazonaws.com zone. Nhấp vào Delete và xác nhận việc xóa bằng cách nhập từ khóa \u0026ldquo;delete\u0026rdquo;. Disassociate Route 53 Resolver Rule - myS3Rule from \u0026ldquo;VPC Onprem\u0026rdquo; and Delete it. 4.Mở console của CloudFormation và xóa hai stack CloudFormation mà bạn đã tạo cho bài thực hành này:\nPLOnpremSetup PLCloudSetup Xóa các S3 bucket Mở bảng điều khiển S3 Chọn bucket chúng ta đã tạo cho lab, nhấp chuột và xác nhận là empty. Nhấp Delete và xác nhận delete. "
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/6-self-evaluation/",
	"title": "Tự đánh giá",
	"tags": [],
	"description": "",
	"content": "Trong suốt thời gian thực tập tại Công ty TNHH Amazon Web Services Vietnam từ 08/09/2025 đến 08/12/2025, tôi đã có cơ hội học hỏi, rèn luyện và áp dụng kiến thức đã được trang bị tại trường vào môi trường làm việc thực tế.\nTôi đã tham gia tìm hiểu và thực hành về cloud và các dịch vụ của AWS, qua đó cải thiện kỹ năng lập trình, sử dụng dịch vụ của AWS, viết báo cáo, giao tiếp….\nVề tác phong, tôi luôn cố gắng hoàn thành tốt nhiệm vụ, tuân thủ nội quy, và tích cực trao đổi với đồng nghiệp để nâng cao hiệu quả công việc.\nĐể phản ánh một cách khách quan quá trình thực tập, tôi xin tự đánh giá bản thân dựa trên các tiêu chí dưới đây:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết về ngành, áp dụng kiến thức vào thực tế, kỹ năng sử dụng công cụ, chất lượng công việc ☐ ✅ ☐ 2 Khả năng học hỏi Tiếp thu kiến thức mới, học hỏi nhanh ☐ ✅ ☐ 3 Chủ động Tự tìm hiểu, nhận nhiệm vụ mà không chờ chỉ dẫn ☐ ✅ ☐ 4 Tinh thần trách nhiệm Hoàn thành công việc đúng hạn, đảm bảo chất lượng ☐ ✅ ☐ 5 Kỷ luật Tuân thủ giờ giấc, nội quy, quy trình làm việc ☐ ✅ ☐ 6 Tính cầu tiến Sẵn sàng nhận feedback và cải thiện bản thân ☐ ✅ ☐ 7 Giao tiếp Trình bày ý tưởng, báo cáo công việc rõ ràng ☐ ✅ ☐ 8 Hợp tác nhóm Làm việc hiệu quả với đồng nghiệp, tham gia nhóm ✅ ☐ ☐ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, đối tác, môi trường làm việc ✅ ☐ ☐ 10 Tư duy giải quyết vấn đề Nhận diện vấn đề, đề xuất giải pháp, sáng tạo ☐ ✅ ☐ 11 Đóng góp vào dự án/tổ chức Hiệu quả công việc, sáng kiến cải tiến, ghi nhận từ team ✅ ☐ ☐ 12 Tổng thể Đánh giá chung về toàn bộ quá trình thực tập ☐ ✅ ☐ Cần cải thiện Nâng cao tính kỹ luật, chấp hành nghiêm chỉnh nội quy của công ty hoặc bất kỳ trong một tổ chức nào Cải thiện trong cách tư duy giải quyết vấn đề Học cách giao tiếp tốt hơn trong giao tiếp hằng ngày và trong công việc, xử lý tình huống "
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/7-feedback/",
	"title": "Chia sẻ, đóng góp ý kiến",
	"tags": [],
	"description": "",
	"content": "Đánh giá chung 1. Môi trường làm việc\nMôi trường làm việc rất thân thiện và cởi mở. Các thành viên trong FCJ luôn sẵn sàng hỗ trợ khi mình gặp khó khăn, kể cả ngoài giờ làm việc. Không gian làm việc gọn gàng, thoải mái, giúp mình tập trung tốt hơn. Tuy nhiên, mình nghĩ có thể bổ sung thêm một số buổi giao lưu hoặc team bonding để mọi người hiểu nhau hơn.\n2. Sự hỗ trợ của mentor / team admin\nMentor hướng dẫn rất chi tiết, giải thích rõ ràng khi mình chưa hiểu và luôn khuyến khích mình đặt câu hỏi. Team admin hỗ trợ các thủ tục, tài liệu và tạo điều kiện để mình làm việc thuận lợi. Mình đánh giá cao việc mentor cho phép mình thử và tự xử lý vấn đề thay vì chỉ đưa đáp án.\n3. Sự phù hợp giữa công việc và chuyên ngành học\nCông việc mình được giao phù hợp với kiến thức mình đã học ở trường, đồng thời mở rộng thêm những mảng mới mà mình chưa từng được tiếp cận. Nhờ vậy, mình vừa củng cố kiến thức nền tảng, vừa học thêm kỹ năng thực tế.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nTrong quá trình thực tập, mình học được nhiều kỹ năng mới như sử dụng công cụ quản lý dự án, kỹ năng làm việc nhóm, và cả cách giao tiếp chuyên nghiệp trong môi trường công ty. Mentor cũng chia sẻ nhiều kinh nghiệm thực tế giúp mình định hướng tốt hơn cho sự nghiệp.\n5. Văn hóa \u0026amp; tinh thần đồng đội\nVăn hóa công ty rất tích cực: mọi người tôn trọng lẫn nhau, làm việc nghiêm túc nhưng vẫn vui vẻ. Khi có dự án gấp, mọi người cùng nhau cố gắng, hỗ trợ không phân biệt vị trí. Điều này giúp mình cảm thấy mình là một phần của tập thể, dù chỉ là thực tập sinh.\n6. Chính sách / phúc lợi cho thực tập sinh\nCông ty có hỗ trợ phụ cấp thực tập và tạo điều kiện về thời gian linh hoạt khi cần thiết. Ngoài ra, việc được tham gia các buổi đào tạo nội bộ là một điểm cộng lớn.\n"
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]