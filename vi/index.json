[
{
	"uri": "https://phucdat25.github.io/OJT/vi/",
	"title": "Báo cáo thực tập",
	"tags": [],
	"description": "",
	"content": "Báo cáo thực tập Thông tin sinh viên: Họ và tên: Nguyễn Phúc Đạt\nSố điện thoại: 0584825767\nEmail: datnpse182125@fpt.edu.vn\nTrường: Đại học FPT\nNgành: Công nghệ thông tin\nLớp: AWS082025\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 08/09/2025 đến ngày 08/12/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/3-blogstranslated/3.1-blog1/",
	"title": "Blog 1",
	"tags": [],
	"description": "",
	"content": "Cách Heroku di chuyển hàng trăm nghìn cơ sở dữ liệu PostgreSQL tự quản lý sang Amazon Aurora Bởi: Stefan Pieterse, Rocket (John), Jonathan K. Brown và Justin Downing\nNgày: 10 tháng 4, 2025\nChủ đề: Advanced (300), Amazon Aurora, Customer Solutions, Migration, PostgreSQL compatible\nTrong bài viết này, chúng tôi sẽ thảo luận cách Heroku đã di chuyển multi-tenant PostgreSQL database từ môi trường tự quản lý PostgreSQL trên Amazon Elastic Compute Cloud (Amazon EC2) sang Amazon Aurora PostgreSQL-Compatible Edition. Heroku đã hoàn tất quá trình này mà không gây ảnh hưởng đến khách hàng, đồng thời tăng độ tin cậy nền tảng và giảm gánh nặng vận hành. Chúng tôi sẽ phân tích kiến trúc tự quản lý trước đây, kiến trúc mới, cách hàng trăm nghìn cơ sở dữ liệu được di chuyển, và những cải thiện trong trải nghiệm khách hàng sau khi hoàn tất.\nTổng quan về Heroku Heroku là một nền tảng PaaS (platform as a service) được quản lý hoàn thiện, xây dựng trên Amazon Web Services (AWS), giúp triển khai, vận hành và mở rộng ứng dụng dễ dàng. Heroku được thành lập năm 2007 và được Salesforce mua lại năm 2010. Ngày nay, Heroku là nền tảng được lựa chọn cho hơn 13 triệu ứng dụng, từ các startup nhỏ đến doanh nghiệp có triển khai quy mô lớn.\nHeroku không chỉ đơn giản hóa việc triển khai và mở rộng ứng dụng bằng Dynos (container do Heroku quản lý) mà còn cung cấp các data solution add-ons như Heroku Postgres, Apache Kafka on Heroku, và Heroku Key-Value Store. Các dịch vụ này xử lý bảo mật, vá lỗi server, failovers, backups và các cấu hình phức tạp khác, giúp khách hàng tập trung phát triển ứng dụng thay vì quản lý hạ tầng dữ liệu. Tất cả các add-on của Heroku Data Services có thể được provision chỉ bằng một lệnh CLI hoặc click, tăng tính tích hợp, độ tin cậy và khả năng mở rộng.\nMột trong những add-on là Heroku Postgres — cung cấp cơ sở dữ liệu PostgreSQL có khả năng mở rộng, chi phí hợp lý, backup tự động, quản lý, tối ưu hiệu suất và tất cả những gì cần để vận hành database. Ví dụ Heroku Connect cho phép đồng bộ hóa dữ liệu Salesforce với Heroku Postgres một cách liền mạch.\nĐể giữ ứng dụng của khách hàng vận hành ổn định, Heroku phải đầu tư lớn. Đầu năm 2025, đội ngũ Heroku Data Services đã di chuyển dịch vụ Heroku Postgres Essential từ môi trường self-managed trên Amazon EC2 sang Amazon Aurora, loại bỏ gánh nặng vận hành và cho phép kỹ sư tập trung vào đổi mới.\nKiến trúc PostgreSQL tự quản lý trước đây và những thách thức Sơ đồ dưới đây minh họa kiến trúc cũ của Heroku:\nNhóm Heroku Data điều hành nhiều control plane để quản lý tài nguyên khách hàng. Khi một khách hàng tạo add-on Heroku Postgres, control plane gửi các API request tới AWS để tạo VPC, EC2 instances, Amazon Elastic Block Store (Amazon EBS) volumes, và Amazon Simple Storage Service (S3) paths theo yêu cầu gói add-on.\nKhi hạ tầng sẵn sàng, control plane thiết lập dịch vụ PostgreSQL và quản lý timeline, credentials, và continuous protection. Heroku có tự động hóa để kết nối vào các instance, đặt file cấu hình và thực thi lệnh để hoàn thành setup database. Khi database hoạt động, họ đẩy thông tin connection string vào cấu hình ứng dụng. Sau đó, control plane giám sát liên tục trạng thái instance, dịch vụ, usage và telemetry khác để giữ độ khả dụng và hiệu suất.\nKiến trúc này phục vụ Heroku hơn 10 năm. Nhưng khi quản lý một fleet các database instances quy mô lớn, độ phức tạp và gánh nặng vận hành tăng lên. Heroku phải viết nhiều mã để giám sát, phát hiện và khắc phục các lỗi hệ điều hành, cập nhật PostgreSQL, hỏng phần cứng.\nDù đã tự động hóa nhiều phần, kỹ sư Heroku vẫn ngày càng dành thời gian nhiều hơn cho bảo trì hạ tầng thay vì phát triển tính năng mới. Khi tìm giải pháp thay thế, Aurora trở thành lựa chọn rõ rệt.\nKiến trúc PostgreSQL mới với Aurora Minh họa kiến trúc mới:\nMột lợi thế nền tảng là control plane của Heroku được thiết kế để tương tác hiệu quả với các dịch vụ AWS Cloud. Hệ thống lấy cảm hứng từ mô hình finite-state machine — mỗi tài nguyên tồn tại ở một trạng thái và có thể chuyển sang trạng thái khác khi có hành động. Ví dụ: khi provision EC2 instance với tham số nhất định, nó vào trạng thái pending cho đến khi AWS hoàn tất yêu cầu, rồi vào trạng thái running.\nKhi chọn Aurora làm backend cho Heroku Postgres, Heroku Data không còn phải dựng và duy trì server infrastructure, custom AMIs, cài đặt và vá lỗi hệ điều hành hoặc di chuyển sang type mới. Khi khách hàng gửi yêu cầu provision, Heroku chỉ cần tạo và thiết lập một Aurora cluster; các phần bên dưới như instance, disk, replication, snapshot được AWS xử lý.\nĐiều này phù hợp với triết lý ephemeralization của Heroku: dùng ít tài nguyên nhưng làm được nhiều hơn. Bằng việc giảm độ phức tạp quản lý hạ tầng database tùy chỉnh, họ có thể ưu tiên giá trị gia tăng như enhanced observability, hỗ trợ database thông minh và tăng interoperability dữ liệu.\nCách Heroku di chuyển hơn 200.000 cơ sở dữ liệu Nhóm Heroku Data phải di chuyển hơn 200.000 cơ sở dữ liệu PostgreSQL tự quản lý sang Aurora. Đây là thách thức lớn, nhưng họ đã hoàn thành chỉ trong 4 tháng với tác động tối thiểu đến khách hàng.\nMặc dù thành thạo PostgreSQL, họ mới với Aurora. Vì vậy, AWS hợp tác đào tạo hơn 40 kỹ sư Heroku.\nNhóm sử dụng hai control plane song song:\nLegacy control plane cho hệ thống cũ Modern control plane cho hệ thống Aurora Heroku xây dựng hệ thống transfer chuyên biệt trong modern control plane, dùng công cụ pgcopydb để sao chép dữ liệu từ PostgreSQL cũ sang Aurora. So với pg_dump/pg_restore, cách này vượt trội nhờ parallel operations. Thời gian trung bình cho khóa, copy, cập nhật pointer và mở khóa \u0026lt; 2.2 phút (p50).\nĐể đảm bảo migration trơn tru, nhóm phát triển khả năng kiểm thử toàn diện: mô phỏng end-to-end migration, kiểm tra dữ liệu, xử lý sự cố trước khi ảnh hưởng khách hàng. Migration diễn ra liên tục, trung bình 2.000 database mỗi ngày. Nhờ kiểm tra kỹ, họ phát hiện và xử lý vấn đề trước khi ảnh hưởng người dùng.\nKhi hệ thống transfer sẵn sàng production, khách có hai lựa chọn:\nSelf-serve migration – khách yêu cầu di chuyển qua việc thay đổi gói dịch vụ Automated migration – hệ thống tự động di chuyển dần từng phần để tránh gián đoạn Heroku đã di chuyển thành công hàng trăm nghìn database từ PostgreSQL self-managed sang Aurora PostgreSQL với ảnh hưởng tối thiểu. Họ còn dùng AWS Countdown, chương trình hỗ trợ Enterprise của AWS để chuẩn bị và thực hiện các sự kiện như migration và launch, hỗ trợ quản lý quotas, capacity planning và hỗ trợ vận hành.\nLợi ích và ưu điểm của kiến trúc mới Chuyển sang kiến trúc database mới là đầu tư lâu dài của Heroku nhằm mang đến trải nghiệm đẳng cấp cho khách hàng.\nHeroku khi vận hành fleet PostgreSQL trên EC2 dành nhiều nỗ lực để cạnh tranh với việc phát triển tính năng mới. Kiến trúc mới trên Aurora giảm gánh nặng vận hành: không còn phải quản lý cập nhật phần mềm, vá lỗi hệ điều hành, PostgreSQL service hay các thư viện hỗ trợ.\nTổ chức giờ đây biết AWS giữ database khách hàng an toàn, ổn định và luôn sẵn sàng. Heroku có thêm thời gian phát triển tính năng mới, lắng nghe khách hàng và củng cố hợp tác với AWS.\nKiến trúc mới cho phép Heroku Data cung cấp tính năng tương lai như AI-enabled database administrator, auto scaling, sleep mode, near-zero downtime, tăng số lượng connection, mở rộng storage lên 128 TB, và hơn thế nữa. Với sự đơn giản của Heroku, việc gắn một database mạnh mẽ như vậy vào ứng dụng thực hiện chỉ bằng một dòng code.\nMigration sang Amazon Aurora cũng nâng cao bảo mật: mã hóa at rest dùng AWS KMS, in transit dùng SSL/TLS, vá lỗi tự động không cần maintenance window, kiểm soát quyền qua IAM authentication, cách ly mạng và ghi nhận hoạt động qua AWS CloudTrail. Các tính năng bảo mật doanh nghiệp này được tích hợp tự động trong Aurora mà không cần cấu hình thêm.\nKết luận Quá trình di chuyển từ PostgreSQL tự quản lý trên EC2 sang Aurora thể hiện sự chuẩn bị kỹ lưỡng và hợp tác giữa Heroku và AWS. Sau khi triển khai thành công cho hàng trăm nghìn database multi-tenant, bước tiếp theo của Heroku là di chuyển cơ sở dữ liệu single-tenant trong Heroku Private Spaces sang Aurora vào cuối năm 2025.\nVề các tác giả Stefan Pieterse là Principal Customer Solutions Manager tại AWS, người đã hỗ trợ nhiều khách hàng chiến lược trong quá trình di chuyển và hiện đại hóa workloads lên đám mây. Khi không làm việc, ông thường chạy bộ hoặc chơi cùng con trai ba tuổi.\nJohn “Rocket” Nichols là Solutions Architect tại AWS, nơi anh giúp các doanh nghiệp lớn xây dựng hệ thống resilient, hiệu suất cao và tối ưu chi phí. Anh cũng tổ chức livestream và làm rượu trong thời gian rảnh.\nJonathan K. Brown là Senior Product Manager tại Heroku, phụ trách Heroku Data Services. Anh có nền tảng vững chắc từ hàng không vũ trụ đến công nghệ cao, có BS/MS Engineering và MBA từ UC Berkeley, và yêu thích paragliding.\nJustin Downing là Software Engineer Architect tại Salesforce, tập trung vào kiến trúc và hệ thống Heroku Data Services. Khi không làm việc, anh khám phá thiên nhiên và trượt tuyết.\n"
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/3-blogstranslated/3.2-blog2/",
	"title": "Blog 2",
	"tags": [],
	"description": "",
	"content": "Đẩy nhanh nghiên cứu bệnh Alzheimer thông qua phân tích bộ gen chức năng quy mô lớn được hỗ trợ bởi điện toán đám mây AWS Bởi: Meghan Buder và Karthik Narasimhan\nNgày: 14 tháng 4, 2025\nChuyên mục: Amazon EC2, Customer Solutions, Healthcare, Public Sector\nBệnh Alzheimer là một rối loạn thoái hóa thần kinh tiến triển ảnh hưởng tới hàng triệu người trên toàn thế giới. Hiệp hội Alzheimer ước tính hơn 6 triệu người Mỹ đang mắc bệnh và con số này được dự đoán sẽ lên gần 13 triệu vào năm 2050. Sự gia tăng này đã thúc đẩy các nỗ lực nghiên cứu toàn cầu, với các nhà khoa học làm việc để hiểu các cơ chế phức tạp của bệnh, xác định các tác nhân tiềm tàng, và phát triển các liệu pháp hiệu quả hơn.\nĐi đầu trong nghiên cứu quan trọng này là Tiến sĩ Gao Wang, Phó Giáo sư Khoa Thần kinh học tại Đại học Columbia. Ông dẫn đầu Lab of Statistical Functional Genomics, nơi sử dụng sức mạnh của Amazon Web Services (AWS) cloud computing để thực hiện nghiên cứu genomics đột phá, giải mã các cơ sở di truyền phức tạp của bệnh Alzheimer và xác định các mục tiêu trị liệu tiềm năng.\nFunctional genetics trong nghiên cứu Alzheimer Nghiên cứu của Tiến sĩ Wang tập trung vào functional genetics, nơi mục tiêu không chỉ là xác định các thay đổi di truyền liên quan đến Alzheimer mà còn hiểu lý do những thay đổi này dẫn tới khởi phát bệnh. Phương pháp này đòi hỏi phân tích dữ liệu có chiều cao và quy mô lớn bằng các mô hình sinh học tính toán và thống kê tinh vi.\nNhờ máy tính đám mây, Tiến sĩ Wang tăng tốc độ phân tích, cho phép hiểu sâu hơn và tiến bộ nhanh hơn trong việc khám phá cơ chế phức tạp của Alzheimer. Ông nhấn mạnh:\n“Nếu toàn ngành có thể cho kết quả nhanh hơn và nếu kết quả là quan trọng, bạn có thể truyền cảm hứng cho các nghiên cứu tiếp theo và thúc đẩy lĩnh vực này tiến lên, hy vọng là nhiều năm trước đó. Các nhà nghiên cứu khác dựa vào dữ liệu chúng tôi sản xuất hoặc những điều chúng tôi tìm ra ban đầu vì chúng tôi có thể mở một số câu hỏi người khác có thể tập trung vào nghiên cứu của họ.”\nDự án FunGen-xQTL: Một nỗ lực hợp tác Một sáng kiến chính là FunGen-xQTL Project, hợp tác giữa 14 viện nghiên cứu, 28 học viên và 19 giảng viên tại Mỹ. Dự án tập trung nghiên cứu molecular quantitative trait loci (QTLs) trong các não lão hóa, trải rộng qua 62 bối cảnh phân tử trong tế bào và mô não.\nNhóm nghiên cứu tạo ra hồ sơ phân tử toàn diện gồm methyl hóa DNA, chỉnh sửa histone, biểu hiện gen, và mức protein từ mẫu não người. Qua đó, cung cấp cho cộng đồng khoa học Alzheimer dữ liệu genomics chức năng từ các nhóm người lão hóa được tuyển chọn và phân tích đa omics.\nMục tiêu là xác định các yếu tố di truyền ảnh hưởng đến bệnh Alzheimer, thiết lập các con đường nhân quả liên kết biến dị gen với nguy cơ bệnh, đồng thời phát triển nguồn QTL toàn diện hỗ trợ nghiên cứu các bệnh thoái hóa thần kinh và não lão hóa. Dự án đã bản đồ hóa các tính trạng phân tử trong các loại tế bào não khác nhau (microglia, astrocytes, neurons), đem lại hiểu biết chưa từng có về điều hòa di truyền theo loại tế bào.\nTăng tốc các đột phá khoa học với AWS Cloud Dự án FunGen-xQTL đòi hỏi hạ tầng vượt xa khả năng on-premises truyền thống. Một trở ngại lớn là nhu cầu tính toán khổng lồ: áp dụng mô hình Bayesian trên hàng chục nghìn biến di truyền, dưới hàng trăm kết hợp tế bào, mô, tổ tiên, và bệnh lý, được đánh giá trên ~30.000 gen.\nFunctional genetics còn đòi hỏi xử lý và phân tích lượng dữ liệu phức tạp, có chiều cao, để khám phá mối quan hệ giữa biến dị gen và khởi phát bệnh. Ngoài ra, việc chia sẻ dữ liệu quy mô lớn giữa các viện nghiên cứu mà không sao chép hoặc trùng lặp là một thách thức cả về kỹ thuật và hậu cần.\nTiến sĩ Wang sử dụng AWS cloud computing, cụ thể là MMCloud từ đối tác AWS MemVerge, để triển khai các ứng dụng container hóa trên AWS:\nXử lý song song quy mô lớn: MMCloud cho phép gửi hàng trăm nghìn job lên AWS và chạy trên các Amazon EC2 Spot Instances tiết kiệm chi phí. Giảm đáng kể thời gian xử lý: phân tích phức tạp giảm từ vài tuần xuống còn vài ngày. Hiệu quả chi phí: sử dụng Spot Instances tiết kiệm 50-80% so với On-Demand. Hợp tác dễ dàng: triển khai và quản lý các ứng dụng Jupyter và RStudio cho nhiều cộng tác viên học thuật. Khai thác sức mạnh của AWS Cloud cho các đột phá khoa học Cloud computing giúp các nhà nghiên cứu như Tiến sĩ Wang:\nXử lý và phân tích các tập dữ liệu genomics lớn hiệu quả. Tăng tốc thời gian công bố nghiên cứu và tác động khoa học. Áp dụng các mô hình thống kê và sinh học tính toán phức tạp để hiểu biến dị gen chức năng. Hợp tác toàn cầu dễ dàng thông qua chia sẻ dữ liệu và kết quả. Mở rộng tài nguyên linh hoạt, chi phí-hiệu quả, chỉ trả cho những gì sử dụng. Kết luận Nghiên cứu của Tiến sĩ Gao Wang tại Đại học Columbia, với sự hỗ trợ của AWS Cloud, đại diện cho phương pháp hiện đại để hiểu Alzheimer thông qua functional genetics. Công trình này mang lại hy vọng phát triển các liệu pháp hiệu quả và cuối cùng có thể tìm ra cách chữa căn bệnh kinh niên này.\nThông tin tác giả Meghan Buder – Quản lý phát triển kinh doanh kỹ thuật chính tại AWS, hỗ trợ các nhà nghiên cứu tận dụng cloud để thúc đẩy đổi mới. Trước đây cô làm việc trong lĩnh vực giáo dục và có bằng Thạc sĩ Mind, Brain, and Education từ Harvard Graduate School of Education.\nKarthik Narasimhan – Quản lý phát triển kinh doanh cao cấp cho genomics và life sciences tại AWS, hỗ trợ các nhà nghiên cứu tại các tổ chức giáo dục tăng tốc nghiên cứu. Anh có Tiến sĩ Khoa học Sinh học từ National University of Singapore và MBA từ University of Texas at Austin.\n"
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/3-blogstranslated/3.3-blog3/",
	"title": "Blog 3",
	"tags": [],
	"description": "",
	"content": "AWS Marketplace được đánh giá là “Awardable” cho các dự án của DoD trong P1 Solutions Marketplace Bởi: AWS Public Sector Blog Team\nNgày: 14 tháng 4, 2025\nChuyên mục: Announcements, AWS Marketplace, Compliance, Defense, Government, Public Sector, Security\nAmazon Web Services (AWS) vui mừng thông báo rằng AWS Marketplace đã được cấp trạng thái “Awardable” trong Department of Defense (DoD) Platform One (P1) Solutions Marketplace. Quy định này cho phép các tổ chức DoD dễ dàng truy cập và mua các giải pháp thông qua AWS Marketplace bằng các con đường mua sắm đã được thiết lập.\nTruy cập quan trọng cho nhiệm vụ P1 Solutions Marketplace là kho lưu trữ kỹ thuật số các video pitch dài năm phút được chọn sau cạnh tranh, nhằm đáp ứng các yêu cầu lớn của chính phủ về phần cứng, phần mềm và dịch vụ. Tất cả các giải pháp “awardable” đều đã được đánh giá thông qua ma trận điểm phức tạp và quy trình cạnh tranh.\nViệc AWS Marketplace được đưa vào mang lại cho khách hàng DoD khả năng tiếp cận hơn 4.000 nhà cung cấp đã được tin cậy và đáp ứng yêu cầu bảo mật và tuân thủ liên bang.\nQuy trình mua sắm được đơn giản hóa Với trạng thái này, các tổ chức DoD giờ đây có thể dùng các nhà cung cấp AWS Marketplace để:\nTruy cập các giải pháp đã được phê duyệt qua các công cụ hợp đồng sẵn có Tăng tốc thời gian triển khai công nghệ Duy trì tuân thủ các quy định mua sắm liên bang Tập trung hóa quản lý hóa đơn và giấy phép Theo dõi và tối ưu chi tiêu CNTT giữa các phòng ban Josh Weatherly, Giám đốc toàn cầu về hợp tác công nghiệp công khai và go-to-market cho AWS Marketplace, cho biết:\n“Việc đưa AWS Marketplace vào P1 Solutions Marketplace là bước tiến mang tính chuyển đổi trong việc kết nối DoD với đổi mới thương mại…”\nKhi lãnh đạo DoD thúc đẩy cải cách mua sắm và đẩy mạnh việc áp dụng các công nghệ mới, trạng thái awardable của AWS Marketplace sẽ đơn giản hóa và tăng tốc việc tiếp cận các đổi mới tiên tiến cho các nhiệm vụ quan trọng.\nTiến về phía trước với AWS Marketplace Các tổ chức DoD có thể truy cập các giải pháp AWS Marketplace qua cổng P1 Solutions Marketplace. Video của AWS Marketplace, “Amazon Web Services, Inc. Streamline Defense Procurement and License Management with AWS Marketplace”, chỉ dành cho khách hàng chính phủ trên P1 Solutions Marketplace, trình diễn một trường hợp sử dụng thực tế.\nAWS Marketplace đã được công nhận trong số các đơn đăng ký cạnh tranh vào P1 Solutions Marketplace, nơi các giải pháp phải thể hiện đổi mới, khả năng mở rộng và tác động tiềm năng đối với nhiệm vụ DoD. Thành tựu này dựa trên cam kết liên tục của AWS trong việc hỗ trợ nhu cầu công nghệ của chính phủ và quốc phòng thông qua các giải pháp đám mây an toàn, tuân thủ và dễ tiếp cận.\nKhách hàng chính phủ quan tâm đến việc truy cập AWS Marketplace qua P1 Solutions Marketplace có thể tạo tài khoản tại trang P1 Marketplace.\nĐể biết thêm thông tin về giải pháp AWS Marketplace dành cho ứng dụng quốc phòng và chính phủ, vui lòng liên hệ icmp@amazon.com.\n"
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/3-blogstranslated/3.4-blog4/",
	"title": "Blog 4",
	"tags": [],
	"description": "",
	"content": "\r⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/3-blogstranslated/3.5-blog5/",
	"title": "Blog 5",
	"tags": [],
	"description": "",
	"content": "\r⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/3-blogstranslated/3.6-blog6/",
	"title": "Blog 6",
	"tags": [],
	"description": "",
	"content": "\r⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/4-eventparticipated/4.1-event1/",
	"title": "Event 1",
	"tags": [],
	"description": "",
	"content": "Báo cáo tóm tắt sự kiện: Vietnam Cloud Day 2025 :Ho Chi Minh City Connect Edition for Builders Mục tiêu sự kiện Cung cấp cái nhìn về ứng dụng Generative AI trong doanh nghiệp Chia sẻ best practices về hiện đại hóa ứng dụng và di chuyển lên cloud Trình diễn công cụ AI giúp tăng tốc Software Development Lifecycle (SDLC) Khám phá chiến lược bảo mật và chuyển đổi VMware lên cloud Hỗ trợ lãnh đạo và kỹ sư đưa các dự án AI phù hợp với mục tiêu kinh doanh Diễn giả Eric Yeo – Country General Manager, Vietnam, Cambodia, Laos \u0026amp; Myanmar, AWS Dr. Jens Lottner – CEO, Techcombank Ms. Trang Phung – CEO \u0026amp; Co-Founder, U2U Network Jaime Valles – Vice President, General Manager Asia Pacific and Japan, AWS Jeff Johnson – Managing Director, ASEAN, AWS Vu Van – Co-founder \u0026amp; CEO, ELSA Corp Nguyen Hoa Binh – Chairman, Nexttech Group Dieter Botha – CEO, TymeX Hung Nguyen Gia – Head of Solutions Architect, AWS Son Do – Technical Account Manager, AWS Nguyen Van Hai – Director of Software Engineering, Techcombank Phuc Nguyen – Solutions Architect, AWS Alex Tran – AI Director, OCB Nguyen Minh Ngan – AI Specialist, OCB Nguyen Manh Tuyen – Head of Data Application, LPBank Securities Vinh Nguyen – Co-Founder \u0026amp; CTO, Ninety Eight Hung Hoang – Customer Solutions Manager, AWS Taiki Dang – Solutions Architect, AWS Nội dung chính Khai mạc \u0026amp; Keynotes Phát biểu khai mạc từ Đại diện Chính phủ Keynote – Eric Yeo: Chiến lược cloud adoption và AI tại Đông Nam Á Customer Keynote 1 – Dr. Jens Lottner: Hành trình chuyển đổi số của Techcombank Customer Keynote 2 – Ms. Trang Phung: Giải pháp fintech sáng tạo từ U2U Network AWS Keynote – Jaime Valles: Góc nhìn khu vực về Generative AI và hiện đại hóa cloud Thảo luận Panel: Navigating the GenAI Revolution Điều phối: Jeff Johnson, AWS Diễn giả: Vu Van, Nguyen Hoa Binh, Dieter Botha Nội dung: Lãnh đạo tổ chức trong thời kỳ GenAI bùng nổ Xây dựng văn hóa đổi mới Đồng bộ AI với chiến lược kinh doanh Quản lý thay đổi tổ chức khi áp dụng AI Track: Migration \u0026amp; Modernization Hoàn tất di chuyển và hiện đại hóa quy mô lớn với AWS Diễn giả: Son Do, Nguyen Van Hai Bài học từ các doanh nghiệp đã di chuyển workloads Best practices và con đường hiện đại hóa Case study: Xây dựng nền tảng vững chắc và roadmap chiến lược Hiện đại hóa ứng dụng với công cụ AI Diễn giả: Phuc Nguyen, Alex Tran Amazon Q Developer: Tăng tốc sinh code, nâng chất lượng phần mềm Tích hợp liền mạch với IDE, CLI, DevSecOps Tự động tạo tài liệu và unit test Trở thành collaborator thông minh sử dụng LLM Demo: Phân tích code phức tạp, đề xuất tối ưu, tự động hóa tasks Panel: Application Modernization Điều phối: Hung Nguyen Gia, AWS Diễn giả: Nguyen Minh Ngan, Nguyen Manh Tuyen, Vinh Nguyen Nội dung: Dùng AI để phát triển nhanh và chất lượng hơn Đồng bộ hóa hiện đại hóa ứng dụng với chiến lược kinh doanh Tự động hóa SDLC và nâng độ tin cậy phần mềm Transforming VMware với AI-driven Cloud Modernization Diễn giả: Hung Hoang, AWS Thúc đẩy adoption cloud cho VMware AWS Transform: migration nhanh, an toàn, tiết kiệm chi phí Playbook: patterns giảm downtime, roadmap lên EKS, RDS, serverless AWS Security at Scale Diễn giả: Taiki Dang, AWS Tăng cường bảo mật từ phát triển đến production Các nguyên tắc: nhận diện, phòng ngừa, phát hiện, phản hồi, khắc phục Ứng dụng AI trong phân tích và tự động hóa bảo mật Xây dựng hệ thống resilient, scalable, an toàn Key Takeaways / Bài học rút ra GenAI cần đồng bộ với chiến lược kinh doanh để đạt hiệu quả Công cụ AI như Q Developer tăng tốc SDLC, nâng chất lượng phần mềm Migration và hiện đại hóa trên AWS tăng tính linh hoạt, bền vững, hiệu quả vận hành Di chuyển VMware lên AWS giúp adoption cloud thuận lợi Security-by-design và AI-assisted operations nâng cao bảo mật doanh nghiệp "
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/4-eventparticipated/4.2-event2/",
	"title": "Event 2",
	"tags": [],
	"description": "",
	"content": "Báo Cáo Tổng Kết Sự Kiện: “AI/ML/GenAI on AWS Workshop (AWS Cloud Mastery Series #1)” Mục Tiêu Sự Kiện Giới thiệu tổng quan về AI, Machine Learning và GenAI trên AWS Trình bày các dịch vụ AI/ML của AWS và ứng dụng thực tế Minh họa cách xây dựng ứng dụng GenAI với Amazon Bedrock và AI Agent Giải thích về Retrieval-Augmented Generation (RAG) trong doanh nghiệp Giới thiệu Bedrock AgentCore và khả năng xây dựng AI agent cấp doanh nghiệp Diễn Giả Lâm Tuấn Kiệt – Chuyên gia AI Đinh Lê Hoàng Anh – Chuyên gia AI Danh Hoàng Hiếu Nghị – Chuyên gia DevOp Nội Dung Nổi Bật 1. Kiến Thức Cơ Bản về ML \u0026amp; AI (Lâm Tuấn Kiệt) Giới thiệu các khái niệm AI và Machine Learning Các kỹ thuật prompt quan trọng: Few-shot prompting Chain-of-thought prompting Tìm hiểu về Retrieval-Augmented Generation (RAG): Tăng độ chính xác nhờ dữ liệu nội bộ Hỗ trợ xây dựng AI agent thông minh AWS có sẵn nhiều công cụ hỗ trợ tích hợp RAG 2. Bộ Dịch Vụ AI của AWS (Đinh Lê Hoàng Anh) AWS cung cấp bộ dịch vụ AI mạnh mẽ, dùng ngay không cần đào tạo mô hình:\nAmazon Rekognition\nPhân tích hình ảnh/video, nhận diện khuôn mặt, vật thể Amazon Translate\nDịch đa ngôn ngữ bằng mô hình học sâu Amazon Textract\nTrích xuất văn bản từ tài liệu Giữ nguyên bố cục và cấu trúc Amazon Transcribe\nChuyển giọng nói thành văn bản Nhận diện người nói trong cuộc hội thoại Amazon Polly\nChuyển văn bản thành giọng nói tự nhiên Amazon Comprehend\nNLP: phân tích cảm xúc, thực thể, từ khóa Amazon Kendra\nCông cụ tìm kiếm doanh nghiệp thông minh Amazon Lookout Family\nPhát hiện bất thường cho thiết bị và dữ liệu IoT Amazon Personalize\nGợi ý cá nhân hóa theo thời gian thực 3. Bedrock AgentCore (Danh Hoàng Hiếu Nghị) Giới thiệu Bedrock AgentCore – công nghệ lõi xây dựng AI Agent Tự động điều phối reasoning, truy xuất dữ liệu, gọi API Kết hợp chặt chẽ với RAG và Foundation Models trên Bedrock Tạo ra chatbot, trợ lý ảo và agent nghiệp vụ mạnh mẽ Bài Học Chính Tư Duy Thiết Kế Luôn bắt đầu từ nhu cầu nghiệp vụ trước khi chọn mô hình AI Prompt engineering (few-shot, CoT) giúp cải thiện độ chính xác Dữ liệu chuẩn rất quan trọng khi xây dựng RAG Kiến Trúc Kỹ Thuật Các dịch vụ AI fully-managed giúp giảm vận hành Bedrock + AgentCore tạo nền tảng mạnh mẽ cho AI enterprise Kết hợp Rekognition, Textract, Kendra và Transcribe để xây dựng pipeline AI hoàn chỉnh Chiến Lược Hiện Đại Hóa Triển khai AI theo từng giai đoạn để tối ưu hiệu quả Ưu tiên dịch vụ quản lý sẵn để giảm độ phức tạp RAG giúp khai thác dữ liệu nội bộ an toàn và hiệu quả Ứng Dụng Vào Công Việc Dùng Amazon Kendra tìm kiếm nội bộ Tự động hóa xử lý tài liệu với Textract + Comprehend Xây dựng AI agent bằng Bedrock AgentCore Phân tích cuộc gọi: Transcribe → Comprehend → Kendra Dùng Rekognition cho xác thực hình ảnh/video Trải Nghiệm Sự Kiện Học Từ Chuyên Gia Từ cơ bản ML đến prompt nâng cao và GenAI workflow Hiểu rõ cách tích hợp dịch vụ AI của AWS vào thực tế Hiểu Sâu Kỹ Thuật Nắm bắt pipeline xử lý hình ảnh – âm thanh – văn bản – tìm kiếm Hiểu cách Bedrock AgentCore + RAG vận hành trong AI hiện đại Thảo Luận \u0026amp; Kết Nối Giao lưu với chuyên gia và người tham dự về các bài toán AI Hiểu rõ hơn cách chọn dịch vụ AWS phù hợp từng use case Bài Học Rút Ra AWS là hệ sinh thái đầy đủ cho xây dựng hệ thống AI GenAI mạnh nhất khi kết hợp dữ liệu nội bộ doanh nghiệp Bedrock AgentCore giúp đơn giản hóa việc xây dựng AI agent quy mô lớn "
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/4-eventparticipated/4.3-event3/",
	"title": "Event 3",
	"tags": [],
	"description": "",
	"content": "Báo Cáo Tổng Kết Sự Kiện: “DevOps on AWS (AWS Cloud Mastery Series #2)” Mục tiêu sự kiện Hiểu về văn hoá DevOps và các nguyên tắc cốt lõi Nắm vững CI/CD pipeline và GitHub workflow Tìm hiểu Infrastructure as Code (IaC) bằng CloudFormation và CDK Áp dụng DevOps best practices và tối ưu chi phí So sánh các công cụ IaC và cách chọn công cụ phù hợp Diễn giả Trương Quang Tính – AWS Community Builder, Platform Engineer (Timex) Hoàng Kha – DevOps Specialist Nguyễn Bảo – Chuyên gia Infrastructure \u0026amp; IaC Nguyễn Thịnh – Chuyên gia AWS CDK Các điểm nổi bật 1. Văn hoá DevOps và nền tảng (Trương Quang Tính) Dev → DevOps → Operations Các yếu tố văn hoá DevOps: Hợp tác \u0026amp; trách nhiệm chung Tự động hoá mọi thứ Học tập \u0026amp; thử nghiệm liên tục Đo lường minh bạch DevOps thế hệ mới: DevOps, Cloud, Platform, SRE DevOps metrics: độ ổn định deployment, độ linh hoạt, hiệu suất Tổng quan DevOps journey 2. CI/CD \u0026amp; DevOps Practices (Hoàng Kha) Kiến trúc CI/CD pipeline GitHub workflow tối ưu Tối ưu chi phí Sử dụng open-source trong DevOps CI – Phân chia \u0026amp; quản lý repo, quy trình làm việc của developer CD – khái niệm và quy trình Centralized CI Best practices khi branching/merging Lý do build bị fail Testing ở mọi stage CI với containers: module hoá container Code rules: Khi nào tạo branch Quy tắc pull request Quy tắc đặt tên Tổ chức source code 3. IaC với CloudFormation (Nguyễn Bảo) ClickOps vs IaC: dùng code thay vì bấm trên console CloudFormation: Công cụ IaC của AWS Stack \u0026amp; Template Template YAML CloudFormation workflow Configuration drift \u0026amp; drift detection 4. AWS CDK – IaC hiện đại (Nguyễn Thịnh) Khái niệm Construct (L1, L2, L3) App và Stack AWS CLI với --profile AWS Amplify chạy trên CloudFormation + CDK Production \u0026amp; Sandbox là hai stack riêng Sequence diagram, giải thích code Circular dependency với SDK và CloudFormation 5. Lựa chọn công cụ IaC (Bảo) Terraform OpenTofu Pulumi ACC Sandbox (ghi chú ngắn) Giải pháp thay thế Những bài học rút ra Tư duy thiết kế DevOps là thay đổi văn hoá, không chỉ công cụ Tự động hóa và trách nhiệm chung cải thiện chất lượng Học tập liên tục thúc đẩy đổi mới Kiến trúc kỹ thuật CI/CD đảm bảo chất lượng và tốc độ release IaC loại bỏ sai lệch cấu hình Container hoá giúp dễ scale và module hoá CDK giúp đơn giản hóa CloudFormation Chiến lược hiện đại hoá Thay thế ClickOps bằng IaC Sử dụng Git để quản lý pipeline Áp dụng best practices cho branching/testing Chọn công cụ IaC dựa trên nhu cầu thực tế Áp dụng vào công việc Tăng cường hợp tác theo văn hoá DevOps Triển khai CI/CD với GitHub Actions Chuyển sang IaC với CloudFormation/CDK Module hoá hệ thống bằng containers Chuẩn hoá quy trình quản lý code Đánh giá công cụ IaC phù hợp Trải nghiệm sự kiện Buổi chia sẻ “DevOps on AWS” giúp tôi hiểu rõ hơn về văn hoá DevOps, CI/CD, IaC và cách áp dụng vào thực tế. Các diễn giả đưa ra nhiều ví dụ thực tiễn về tối ưu workflow, cải thiện chất lượng và nâng cao tốc độ triển khai.\nNhững kiến thức về container, branching, testing và IaC giúp tôi định hướng rõ hơn cho việc hiện đại hóa quy trình DevOps trong dự án của mình.\n"
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/4-eventparticipated/4.4-event4/",
	"title": "Event 4",
	"tags": [],
	"description": "",
	"content": "Báo Cáo Tổng Kết Sự Kiện: “AWS Cloud Mastery Series #3” Mục Tiêu Sự Kiện Hiểu các khái niệm cốt lõi về AWS IAM. Nắm được mô hình bảo mật đa lớp trên AWS. Khám phá GuardDuty, Security Hub, KMS, mã hóa và quy trình ứng phó sự cố. Học cách kiểm soát truy cập, phát hiện mối đe dọa và bảo vệ dữ liệu. Cải thiện bảo mật hệ thống trên quy mô doanh nghiệp. Diễn Giả Chan Doan Cong Ly Le Duc Anh TranHuynh Hoang Long Hoang Kevin Tran Duc Anh Nguyen Tuan Thinh Nguyen Do Thanh Dat Thinh Dat Kha Van Thinh Lam Viet Nguyen Long Mendel Grabski Tinh Truong Điểm Nổi Bật IAM – Identity \u0026amp; Access Management (TranHuynh Hoang Long) Quản lý user và group. Best practices: tránh \u0026ldquo;*\u0026rdquo;, dùng nguyên tắc quyền tối thiểu, bật MFA. Bảo mật đăng nhập AWS. SSO cho nhiều ứng dụng. Service Control Policies (Hoang) Chính sách cấp tổ chức dành cho doanh nghiệp. Permission Boundaries để giới hạn quyền tối đa. Dải credentials: long-term vs short-term (STS). MFA: TOTP, FIDO2. Quay vòng credentials bằng Secrets Manager. IAM Access Analyzer. CloudTrail Organization-Level (Kevin, Thinh, Dat) Theo dõi toàn tổ chức. Quan sát bảo mật đa lớp. EventBridge cho cảnh báo và tự động hóa. GuardDuty (Thinh) Các vấn đề doanh nghiệp gặp phải. Nguồn dữ liệu từ CloudTrail và AWS services. Advanced Protection Plans. Runtime Monitoring bằng GuardDuty Agent. AWS Security Hub (Dat) CSPM – quản lý tư thế bảo mật trên cloud. Network Security (Kha Van) Tấn công theo hướng outbound, inbound và east-west. Security Group: stateful, default deny. Bảo mật tầng ứng dụng. SG Sharing qua VPC và Transit Gateway. NACLs: hoạt động ở subnet. Route 53 DNS. SG/NACL/firewall chống lại các vector tấn công. Data Protection \u0026amp; KMS (Thinh Lam, Viet Nguyen) Quy trình và policy của KMS. AWS managed key vs CMK. Rotation key theo chu kỳ. Phân loại dữ liệu. Access guardrails. Encryption \u0026amp; Secrets (Viet Nguyen) Mã hóa khi truyền: S3, DynamoDB. Quản lý secrets bằng ACM. Incident Response (Mendel, Tinh Truong) Mối đe dọa hiện đại → cần giải pháp hiện đại. Foundations và các lớp kiểm soát. Chiến lược phòng ngừa. Bài Học Rút Ra IAM là nền tảng bảo mật AWS; phải bật MFA và dùng least privilege. SCPs \u0026amp; permission boundaries giúp quản lý doanh nghiệp hiệu quả. GuardDuty + CloudTrail + EventBridge tạo chuỗi giám sát tự động. Security Group \u0026amp; NACL cần được dùng kết hợp đúng cách. KMS và key rotation giúp bảo vệ dữ liệu quan trọng. Security đa lớp gồm identity, network, data và incident response. Cloud security hiện đại dựa trên automation và phân tích hành vi. Ứng Dụng Vào Công Việc Áp dụng MFA, least privilege và IAM best practices vào DevOps \u0026amp; vận hành. Bật CloudTrail toàn tổ chức cho logging đầy đủ. Dùng GuardDuty và Security Hub để phát hiện mối đe dọa. Áp dụng best practice VPC: SG, NACL, DNS protection. Mã hóa dữ liệu bằng KMS và quản lý secrets bằng Secrets Manager/ACM. Tự động hóa cảnh báo qua EventBridge. Xây dựng quy trình incident response theo chuẩn AWS. Trải Nghiệm Sự Kiện Sự kiện mang lại lượng kiến thức thực tế về bảo mật doanh nghiệp trên AWS. Các diễn giả chia sẻ trực quan và bám sát nhu cầu thực tiễn. Bao phủ từ IAM cơ bản đến bảo mật nâng cao. Rất phù hợp cho cloud engineer, DevOps, security analyst cần tăng cường kiến thức bảo mật AWS. "
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/5-workshop/5.1-workshop-overview/",
	"title": "Giới thiệu",
	"tags": [],
	"description": "",
	"content": "Thành phần kiến trúc IoT AWS IoT Core đóng vai trò là MQTT broker bảo mật, cho phép thiết bị IoT giao tiếp với đám mây thông qua cơ chế publish/subscribe bằng chứng chỉ và policy. Thiết bị ESP32 kết nối Internet qua Wi-Fi và gửi dữ liệu cảm biến (nhiệt độ, độ ẩm, v.v.) lên AWS thông qua MQTT topic. Amazon DynamoDB được sử dụng để lưu trữ dữ liệu cảm biến, phục vụ truy vấn, phân tích và tích hợp với các ứng dụng IoT phía sau. Tổng quan Workshop Trong workshop này, bạn sẽ làm việc với thiết bị IoT và các dịch vụ AWS Cloud.\nESP32 đóng vai trò thiết bị cảm biến, kết nối đến AWS IoT Core bằng chứng chỉ bảo mật và giao thức MQTT. AWS IoT Core nhận dữ liệu từ ESP32. Bạn sẽ tạo IoT Rule để chuyển tiếp dữ liệu nhận được. DynamoDB lưu trữ các bản ghi dữ liệu cảm biến được gửi từ IoT Core, mô phỏng môi trường backend cho việc phân tích, giám sát hoặc xử lý dữ liệu. Kết thúc workshop, bạn sẽ có:\nMột thiết bị ESP32 kết nối thành công với AWS IoT Core và gửi dữ liệu thời gian thực. Pipeline truyền dữ liệu tự động từ IoT Core → DynamoDB. Nền tảng cơ bản để mở rộng sang các ứng dụng IoT nâng cao như dashboard giám sát, cảnh báo bất thường, phân tích dữ liệu,\u0026hellip; "
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/1-worklog/",
	"title": "Nhật ký công việc",
	"tags": [],
	"description": "",
	"content": "Week 1: Tìm hiểu về AWS và các dịch vụ điện toán đám mây cơ bản\n→ Tìm hiểu kiến thức cơ bản về AWS, các mô hình điện toán đám mây, và thực hành các dịch vụ cốt lõi như EC2, S3, và VPC.\nWeek 2: Thực hành với IAM, EC2 và S3\n→ Thực hành cấu hình IAM, quản lý EC2 instance và thao tác lưu trữ, truy xuất dữ liệu với Amazon S3.\nWeek 3: Cấu hình bảo mật mạng và lưu trữ dữ liệu\n→ Hiểu về bảo mật mạng trong AWS, tạo và quản lý key pairs, gắn EBS volumes vào EC2 instance.\nWeek 4: Triển khai ứng dụng web và cấu hình Elastic IP\n→ Triển khai và quản lý web server trên EC2, cấu hình Elastic IP và lưu trữ website tĩnh hoặc động.\nWeek 5: Quản lý cơ sở dữ liệu và sao lưu với Amazon RDS\n→ Tạo và cấu hình cơ sở dữ liệu RDS, thực hiện sao lưu snapshot và kết nối RDS với ứng dụng web.\nWeek 6: Triển khai WordPress và thực hành nhập/xuất máy ảo (VM)\n→ Cài đặt và triển khai WordPress trên AWS EC2, thiết lập AMI, Load Balancer và Auto Scaling Group.\n→ Học và thực hành nhập/xuất máy ảo (VM) giữa môi trường on-premises và AWS.\nWeek 7: Triển khai WordPress và thực hành nhập/xuất máy ảo (VM)\n→ Tự động hóa việc khởi động/dừng EC2 bằng AWS Lambda kết hợp Slack webhook.\n→ Giám sát tài nguyên AWS bằng Grafana và CloudWatch.\n→ Quản lý tài nguyên AWS hiệu quả hơn bằng cách sử dụng thẻ (tag) và nhóm tài nguyên (resource group).\nTuần 8: Quản lý truy cập EC2 và làm quen với AWS Systems Manager\nTuần 9: Giám sát mạng với VPC Flow Logs, ủy quyền truy cập bảng điều khiển thanh toán, quản lý sử dụng tài nguyên và phát hiện bất thường sao lưu\nTuần 10: Bảo mật AWS\nTuần 11: Quản lý dữ liệu và bảo mật\nTuần 12: Tối ưu chi phí và thực hành cơ sở dữ liệu AWS\n"
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/1-worklog/1.1-week1/",
	"title": "Nhật ký công việc Tuần 1",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 1: Hiểu các dịch vụ cơ bản của AWS. Tạo tài khoản AWS Free Tier. Các công việc cần thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Tìm hiểu về AWS và các nhóm dịch vụ của nó + Compute (Tính toán) + Storage (Lưu trữ) + Networking (Mạng) + Database (Cơ sở dữ liệu) 09/08/2025 09/08/2025 https://www.youtube.com/@AWSStudyGroup 3 - Tạo tài khoản AWS Free Tier - Thực hành: + Tạo tài khoản AWS mới + Bật xác thực đa yếu tố (MFA) cho AWS + Tạo nhóm Admin và người dùng Admin 09/09/2025 11/09/2025 https://000001.awsstudygroup.com/ Thứ 7 - Quản lý chi phí với AWS Budgets - Thực hành: + Tạo Budget bằng Template + Tạo Cost Budget + Tạo RI Budget + Tạo Usage Budget + Tạo Savings Plans Budget 09/13/2025 09/13/2025 https://000007.awsstudygroup.com/ CN - Kiến thức cơ bản về mạng với Amazon Virtual Private Cloud (VPC) - Thực hành: + Giới thiệu Amazon VPC + Cấu hình tường lửa trong VPC 09/14/2025 09/15/2025 https://000003.awsstudygroup.com/1-introduce/ Kết quả đạt được trong tuần 1: Hiểu được AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute (Tính toán) Storage (Lưu trữ) Networking (Mạng) Database (Cơ sở dữ liệu) Tạo và cấu hình thành công tài khoản AWS Free Tier.\nHiểu cách quản lý chi phí bằng AWS Budgets.\nLàm quen với Amazon VPC (Virtual Private Cloud).\n"
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/1-worklog/1.2-week2/",
	"title": "Nhật ký công việc Tuần 2",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 2: Hiểu các kiến thức cơ bản về mạng với Amazon Virtual Private Cloud (VPC). Tìm hiểu các kiến thức cơ bản về tính toán (Compute) với Amazon Elastic Compute Cloud (EC2). Các công việc cần thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Tiếp tục các bước cơ bản với VPC - Thực hành: + Tạo VPC + Tạo Subnet + Tạo Internet Gateway + Tạo Route Table + Tạo Security Group + Kích hoạt VPC Flow Logs 09/15/2025 09/15/2025 https://000003.awsstudygroup.com/3-prerequisite/ 3 - Triển khai Amazon EC2 Instances - Thực hành: + Tạo máy chủ EC2 + Kiểm tra kết nối 09/16/2025 09/16/2025 https://000003.awsstudygroup.com/4-createec2server/ 4 - Tiếp tục triển khai Amazon EC2 Instances - Thực hành: + Tạo NAT Gateway + Sử dụng Reachability Analyzer + Tạo EC2 Instance Connect Endpoint 09/17/2025 09/17/2025 https://000003.awsstudygroup.com/4-createec2server/ 6 - Tiếp tục triển khai Amazon EC2 Instances - Thực hành: + AWS Systems Manager Session Manager + Giám sát và cảnh báo bằng CloudWatch 09/19/2025 09/19/2025 https://000003.awsstudygroup.com/4-createec2server/ Thứ 7 - Thiết lập kết nối VPN Site-to-Site trong AWS - Thực hành: + Tạo VPC cho VPN + Tạo EC2 làm Customer Gateway + Tạo Virtual Private Gateway + Tạo Customer Gateway + Tạo VPN Connection + Cấu hình Customer Gateway + Chỉnh sửa AWS VPN Tunnel + Tạo Transit Gateway + Tạo Transit Gateway Attachment + Cấu hình Route Tables 09/20/2025 09/20/2025 https://000003.awsstudygroup.com/5-vpnsitetosite/ CN - Kiến thức cơ bản về Amazon Elastic Compute Cloud (EC2) - Thực hành: + Tạo VPC và Security Group cho Linux và Windows + Khởi chạy Microsoft Windows Server 2022 Instance + Khởi chạy Amazon Linux Instance + Tạo Customer Gateway + Làm quen với các thao tác cơ bản trên EC2 09/21/2025 09/21/2025 https://000004.awsstudygroup.com/ Kết quả đạt được trong tuần 2: Hiểu về VPC và biết cách:\nTạo VPC Tạo Subnet Tạo Internet Gateway Tạo Route Table Tạo Security Group Biết cách tạo và kiểm tra kết nối EC2.\nHiểu cách sử dụng EC2 Instance Connect Endpoint để giúp EC2 private kết nối Internet mà không cần public IP.\nNắm được cách kết nối trung tâm dữ liệu On-premise với Amazon VPC thông qua VPN cứng (hard VPN) hoặc VPN mềm (soft VPN) tùy yêu cầu cụ thể.\nThực hành khởi chạy Instance:\nKhởi chạy Microsoft Windows Server 2022 Instance Khởi chạy Amazon Linux Instance "
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/1-worklog/1.3-week3/",
	"title": "Nhật ký công việc Tuần 3",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Tuần 3: Tiếp tục học về các khái niệm cơ bản của điện toán với Amazon Elastic Compute Cloud (EC2). Tìm hiểu cách cấp quyền cho ứng dụng truy cập vào các dịch vụ AWS. Hiểu và thực hành với Amazon S3 và RDS. Học cách xây dựng ứng dụng trên Amazon Lightsail. Các công việc thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Thực hành: + Khôi phục quyền truy cập vào Windows Instances + Khôi phục quyền truy cập vào Linux Instances + Kết nối Remote Desktop tới EC2-Ubuntu + Lưu trữ bản sao Amazon EBS Snapshots + Chia sẻ AMI 22/09/2025 22/09/2025 https://000004.awsstudygroup.com/5-amazonec2basic/ 3 - Triển khai ứng dụng Quản lý Người dùng AWS trên Amazon Linux 2 - Triển khai ứng dụng Node.js trên Amazon EC2 Windows - Thực hành: + Chuẩn bị máy chủ LAMP + Kiểm tra máy chủ LAMP + Cấu hình máy chủ cơ sở dữ liệu + Cài đặt phpMyAdmin + Cài đặt Node.js trên Amazon Linux 2 + Triển khai ứng dụng trên Linux Instance + Cài đặt XAMPP trên Windows Instance + Cài đặt Node.js trên Windows Instance + Triển khai ứng dụng Quản lý Người dùng AWS trên Windows Server + Quản trị chi phí \u0026amp; mức sử dụng với IAM 23/09/2025 23/09/2025 https://000004.awsstudygroup.com/6-awsfcjmanagement-linux/ 4 - Cấp quyền cho ứng dụng truy cập dịch vụ AWS bằng IAM Role. - Thực hành: + Tạo EC2 Instance + Tạo S3 bucket + Tạo người dùng IAM và cặp Access Key + Sử dụng Access Key + Tạo IAM Role + Gán IAM Role cho EC2 24/09/2025 24/09/2025 https://000048.awsstudygroup.com/ 5 - Tìm hiểu về Simple Storage Service (S3) - Tìm hiểu về Amazon Relational Database Service (RDS) Thực hành: + Tạo S3 và tải dữ liệu lên S3 + Kích hoạt tính năng website tĩnh + Cấu hình chặn truy cập công khai + Cấu hình truy cập công khai cho đối tượng + Kiểm tra website + Chặn toàn bộ truy cập công khai + Cấu hình Amazon CloudFront + Kiểm tra Amazon CloudFront + Bật phiên bản bucket (Bucket Versioning) + Di chuyển đối tượng + Tạo RDS Security Group (sau khi tạo VPC và EC2) + Tạo DB Subnet Group + Triển khai ứng dụng + Sao lưu và khôi phục 25/09/2025 25/09/2025 https://000057.awsstudygroup.com/ https://000005.awsstudygroup.com/ 6 - Workshop Amazon Lightsail - Thực hành: + Triển khai cơ sở dữ liệu trên Lightsail + Triển khai WordPress Instance + Cấu hình Ubuntu + Cấu hình mạng + Cấu hình WordPress + Triển khai lại WordPress Instance + Cấu hình mạng + Triển khai WordPress + Triển khai ứng dụng thương mại điện tử Prestashop + Cấu hình mạng 26/09/2025 26/09/2025 https://000045.awsstudygroup.com/ Thành tựu đạt được trong Tuần 3: Biết cách cấp quyền cho ứng dụng thông qua Access Key / Secret Access Key. Biết cách cấp quyền cho ứng dụng thông qua IAM Role trên EC2. Hiểu và thực hành Amazon S3 và RDS, bao gồm: Tạo S3 và tải dữ liệu lên S3 Cấu hình chặn truy cập công khai Di chuyển các đối tượng trong S3 Tạo instance cơ sở dữ liệu RDS Xây dựng 3 ứng dụng trên Lightsail: Triển khai WordPress Instance Triển khai Prestashop E-Commerce Instance Triển khai Akaunting Instance "
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/1-worklog/1.4-week4/",
	"title": "Nhật ký công việc Tuần 4",
	"tags": [],
	"description": "",
	"content": "Mục tiêu trong Tuần 4 Tìm hiểu về Lightsail Container Học cách triển khai ứng dụng với Amazon EC2 Auto Scaling Xây dựng hệ thống DNS lai (Hybrid DNS) Các nhiệm vụ thực hiện trong tuần Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Tiếp tục Workshop Amazon Lightsail + Bảo mật ứng dụng (Application Security) + Tạo Snapshot + Tạo Alarm 29/09/2025 29/09/2025 https://000045.awsstudygroup.com/ 3 - Chạy ứng dụng trên Amazon Lightsail Container - Thực hành: + Tạo dịch vụ Container trên AWS + Triển khai image công khai + Tạo Lightsail Instance + Cấu hình AWS CLI + Cài đặt Docker trên Ubuntu cho AWS Lightsail + Xây dựng image container + Push image container + Thực hiện triển khai mới (New Deploy) 30/09/2025 30/09/2025 https://000046.awsstudygroup.com/ 4 - Học về Auto Scaling cho ứng dụng với Amazon EC2 Auto Scaling - Thực hành: + Thiết lập hạ tầng mạng (Network Infrastructure) + Khởi tạo EC2 Instance + Tạo cơ sở dữ liệu với RDS + Chuẩn bị dữ liệu cho Database + Triển khai Web Server + Cấu hình metric cho Predictive Scaling + Tạo Launch Template + Tạo Target Group + Tạo Load Balancer + Kiểm thử + Tạo Auto Scaling Group + Kiểm thử scaling thủ công, theo lịch và tự động + Đọc các metric của Predictive Scaling 01/10/2025 01/10/2025 https://000006.awsstudygroup.com/ 5 - AWS CloudWatch Workshop: + Xem Metrics + Biểu thức tìm kiếm (Search expressions) + Biểu thức toán học (Math expressions) + Nhãn động (Dynamic Labels) + CloudWatch Logs + CloudWatch Logs Insights + CloudWatch Metric Filter + CloudWatch Alarms + CloudWatch Dashboards 02/10/2025 02/10/2025 https://000008.awsstudygroup.com/ Thứ 7 - Thiết lập Hybrid DNS với Route 53 Resolver + Tạo Key Pair + Khởi tạo CloudFormation Template + Cấu hình Security Group + Kết nối RDGW + Triển khai Microsoft AD + Tạo Route 53 Outbound Endpoint + Tạo Route 53 Resolver Rules + Tạo Route 53 Inbound Endpoints + Kiểm tra kết quả 04/10/2025 04/10/2025 https://000010.awsstudygroup.com/ Thành tựu đạt được trong Tuần 4 Triển khai và vận hành thành công ứng dụng trên Amazon Lightsail Container, bao gồm:\nTạo và cấu hình dịch vụ container trên AWS. Triển khai image container công khai. Cấu hình AWS CLI để quản lý container trong Lightsail. Triển khai thành công ứng dụng với Amazon EC2 Auto Scaling, giúp hệ thống có khả năng mở rộng tự động theo tải.\nSử dụng AWS CloudWatch để giám sát và thiết lập cảnh báo (Monitoring \u0026amp; Alerting).\nCấu hình hệ thống DNS lai (Hybrid DNS) bằng Route 53 Resolver, bao gồm:\nTạo cặp khóa (Key Pair) và triển khai CloudFormation Template. Cấu hình Security Group và kết nối đến RDGW. Triển khai Microsoft Active Directory và thiết lập các Endpoint (Outbound/InBound) cho Route 53 Resolver. Tạo và kiểm thử các Route 53 Resolver Rules để đảm bảo việc phân giải DNS hoạt động ổn định giữa môi trường On-premises và AWS. "
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/1-worklog/1.5-week5/",
	"title": "Nhật ký công việc Tuần 5",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 5: Học cách sử dụng AWS Command Line Interface (CLI) Tìm hiểu kiến thức cơ bản và thực hành về Amazon ElastiCache - Redis Học và thực hành triển khai AWS Managed Directory Service Nhiệm vụ thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Học cách sử dụng CLI - Thực hành + Cài đặt AWS CLI + Xem tài nguyên qua CLI + AWS CLI với Amazon S3 + AWS CLI với Amazon SNS + AWS CLI với IAM + AWS CLI với VPC + AWS CLI với Internet Gateway + Tạo EC2 bằng AWS CLI - Học kiến thức cơ bản và thực hành về Amazon DynamoDB\n+ Tạo bảng + Ghi dữ liệu + Đọc dữ liệu + Cập nhật dữ liệu + Truy vấn dữ liệu + Tạo chỉ mục phụ toàn cục (GSI) + Truy vấn chỉ mục phụ toàn cục + Sử dụng AWS CloudShell + Cấu hình AWS CLI 06/10/2025 06/10/2025 https://000011.awsstudygroup.com/ https://000060.awsstudygroup.com/ 3 - Học kiến thức cơ bản và thực hành Amazon ElastiCache - Redis + Tạo subnet group bằng console và CLI + Tạo cluster bằng console và CLI + Cấp quyền truy cập cho cluster + Kết nối đến cluster node 07/10/2025 07/10/2025 https://000061.awsstudygroup.com/ 4 - Học và thực hành lưu trữ trang web tĩnh trên Amazon S3 + Tạo bucket S3 + Tải tệp index.html mẫu lên + Cấu hình Amazon CloudFront - Thực hành AWS WorkSpaces + Chuẩn bị triển khai Amazon WorkSpaces + Triển khai Amazon WorkSpaces + Truy cập WorkSpaces bằng trình duyệt + Truy cập WorkSpaces bằng ứng dụng WorkSpaces Client 08/10/2025 08/10/2025 https://000094.awsstudygroup.com/ https://000093.awsstudygroup.com/ 5 - Thực hành Edge Computing với CloudFront và Lambda@Edge + Tạo CloudFront Distribution + Thêm EC2 Origin + Kiểm thử ứng dụng + Kiểm thử xóa bộ nhớ đệm (Distribution Invalidations) + Cấu hình trang lỗi tùy chỉnh + Tạo Origin Group + Cấu hình Response Headers + Tạo Cache Behavior + Tạo hàm Lambda@Edge + Triển khai Lambda@Edge lên CloudFront 09/10/2025 09/10/2025 https://000130.awsstudygroup.com/ T7 - Học và thực hành triển khai AWS Managed Directory Service + Triển khai AWS Managed Directory Service + Triển khai EC2 + Đổi tên máy tính + Cấu hình EC2 + Kiểm tra kết nối giữa các máy chủ 11/10/2025 11/10/2025 https://000095.awsstudygroup.com/ Thành tựu đạt được trong tuần 5: AWS CLI và CloudShell\nĐã cài đặt và cấu hình thành công AWS CLI Thực hành sử dụng AWS CloudShell để quản lý tài nguyên qua dòng lệnh Amazon DynamoDB\nTạo và quản lý bảng dữ liệu DynamoDB Thực hiện thành công các thao tác CRUD (Tạo, Đọc, Cập nhật, Xóa) Lưu trữ trang web tĩnh \u0026amp; WorkSpaces\nLưu trữ nội dung web tĩnh bằng Amazon S3 Cấu hình CloudFront để phân phối nội dung toàn cầu Triển khai và truy cập Amazon WorkSpaces qua trình duyệt và ứng dụng client Điện toán biên (Edge Computing) với CloudFront và Lambda@Edge\nTạo và cấu hình CloudFront Distribution Thiết lập EC2 origin, cache behavior và trang lỗi tùy chỉnh Phát triển và triển khai hàm Lambda@Edge để xử lý tại biên Dịch vụ thư mục quản lý (Managed Microsoft Active Directory)\nTriển khai thành công AWS Managed Directory Service Cấu hình và kết nối EC2 với thư mục quản lý Kiểm thử giao tiếp giữa các máy chủ trong môi trường Directory "
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/1-worklog/1.6-week6/",
	"title": "Nhật ký công việc Tuần 6",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 6: Học và triển khai triển khai WordPress trên AWS Cloud Thực hành tạo và quản lý Máy ảo (Virtual Machines) Học và thực hành quy trình nhập/xuất máy ảo (VM Import/Export) giữa hệ thống tại chỗ và AWS Nhiệm vụ thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 3 - Học và triển khai cài đặt WordPress trên AWS Cloud + Cài đặt WordPress trên EC2 + Tạo AMI từ Webserver Instance + Tạo Launch Template + Tạo Load Balancer + Tạo Auto Scaling Group + Tạo bản sao cơ sở dữ liệu (DB snapshot) + Khôi phục từ DB snapshot + Tạo CloudFront cho Web Server 14/10/2025 14/10/2025 https://000101.awsstudygroup.com/ 4 - Thực hành: Tạo một Máy ảo mới 15/10/2025 15/10/2025 https://000014.awsstudygroup.com/1-deploy-application-server/ 6 - Thực hành quy trình VM Import/Export + Xuất máy ảo từ hệ thống tại chỗ + Tải máy ảo lên AWS + Nhập máy ảo vào AWS + Triển khai Instance từ AMI + Thiết lập quyền truy cập (ACL) cho S3 bucket + Xuất máy ảo từ AMI 17/10/2025 17/10/2025 https://000014.awsstudygroup.com/ Thành tựu tuần 6: Đã triển khai thành công WordPress trên AWS EC2 Đã thực hành tạo và cấu hình máy ảo Hoàn thành quy trình nhập/xuất máy ảo (VM Import/Export): Xuất máy ảo từ hệ thống tại chỗ Tải lên và nhập vào AWS dưới dạng AMI Triển khai và kiểm thử các instance mới thành công "
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/1-worklog/1.7-week7/",
	"title": "Nhật ký công việc Tuần 7",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 7: Học và thực hành về hàm Lambda trong AWS để tự động hóa và tối ưu chi phí Cài đặt và sử dụng Grafana để giám sát tài nguyên trên AWS Học cách quản lý tài nguyên AWS bằng cách sử dụng thẻ (tags) một cách hiệu quả Nhiệm vụ thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 3 - Học và thực hành về các hàm Lambda để tăng hiệu quả chi phí trong môi trường AWS. + Tạo Web-hook Slack + Tạo thẻ cho Instance + Tạo Role cho Lambda + Hàm dừng Instance + Hàm khởi động Instance + Kiểm tra kết quả 21/10/2025 21/10/2025 https://000022.awsstudygroup.com/ 4 - Thực hành sử dụng Grafana để giám sát tài nguyên trên AWS + Cài đặt Grafana + Giám sát bằng Grafana 22/10/2025 22/10/2025 https://000029.awsstudygroup.com/ 5 - Thực hành với Amazon CloudWatch + Xem các chỉ số (Metrics) + Biểu thức tìm kiếm (Search expressions) + Biểu thức toán học (Math expressions) + Nhãn động (Dynamic Labels) + Nhật ký CloudWatch (CloudWatch Logs) 23/10/2025 23/10/2025 https://000036.awsstudygroup.com/ 6 - Thực hành quản lý tài nguyên bằng thẻ (Tags) + Tạo EC2 Instance với thẻ + Quản lý thẻ trong tài nguyên AWS + Lọc tài nguyên theo thẻ + Tạo nhóm tài nguyên (Resource Group) 24/10/2025 24/10/2025 https://000027.awsstudygroup.com/ Thành tựu tuần 7: Đã triển khai các hàm Lambda để tự động khởi động và dừng EC2 Instance Cấu hình tích hợp Slack với Lambda bằng cách sử dụng Web-hook Cài đặt và thiết lập Grafana để trực quan hóa các chỉ số AWS Thực hành các tính năng của CloudWatch như xem chỉ số, biểu thức toán học và nhãn động Tạo và quản lý các thẻ tài nguyên, đồng thời xây dựng nhóm tài nguyên để tổ chức hiệu quả hơn "
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/1-worklog/1.8-week8/",
	"title": "Nhật ký công việc Tuần 8",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 8: Thực hành kiểm soát truy cập EC2 bằng Resource Tags và IAM Policy Làm quen với AWS Systems Manager, bao gồm Patch Manager, Run Command và Session Manager Nhiệm vụ thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Thực hành quy trình kiểm soát truy cập dịch vụ EC2 bằng Resource Tags + Tạo IAM Policy + Tạo IAM Role + Chuyển đổi Role + Truy cập bảng điều khiển EC2 tại vùng Tokyo + Truy cập bảng điều khiển EC2 tại vùng Bắc Virginia + Tạo EC2 instance khi có và không có Tag phù hợp + Chỉnh sửa Tag của EC2 Instance + Kiểm tra Policy 27/10/2025 27/10/2025 https://000028.awsstudygroup.com/ 3 - Thực hành với AWS Systems Manager + Patch Manager + Run Command 28/10/2025 28/10/2025 https://000031.awsstudygroup.com/ 4 - Ôn tập giữa kỳ 29/10/2025 29/10/2025 5 - Ôn tập giữa kỳ 30/10/2025 30/10/2025 6 - Tìm hiểu và thực hành Amazon Systems Manager - Session Manager + Chuẩn bị VPC và EC2 + Kết nối đến Public Instance + Kích hoạt DNS hostnames + Tạo VPC Endpoint + Kết nối đến Instance + Cập nhật IAM Role + Tạo S3 Bucket + Giám sát nhật ký phiên làm việc + Thực hiện Port Forwarding 31/10/2025 31/10/2025 https://000058.awsstudygroup.com/ Thành tựu tuần 8: Đã tạo và kiểm thử thành công IAM Policy, Role và Tag để giới hạn truy cập EC2 theo vùng Sử dụng AWS Systems Manager để quản lý và vá lỗi EC2 từ xa Cấu hình và kết nối EC2 thông qua Session Manager, lưu nhật ký phiên làm việc vào S3 và thực hiện port forwarding "
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/1-worklog/1.9-week9/",
	"title": "Nhật ký công việc Tuần 9",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Tuần 9: Hiểu và thực hành VPC Flow Logs để giám sát lưu lượng mạng Tìm hiểu cách phân quyền truy cập bảng điều khiển thanh toán (Billing Console) bằng IAM Policies Thực hành quản lý giới hạn tài nguyên và chi phí bằng IAM Restrictions Thực hành phát hiện bất thường trong sao lưu EBS (EBS Backup Anomaly Detection) Nhiệm vụ thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Tìm hiểu và thực hành tính năng VPC Flow Logs + Tạo Stack\n+ Tạo VPC Flow Logs\n+ Kích hoạt VPC Flow Logs\n+ Giám sát hạ tầng mạng (Network Infrastructure Monitoring)\n- Thực hành phân quyền truy cập bảng điều khiển thanh toán (Billing Console)\n+ Tạo nhóm người dùng IAM\n+ Kích hoạt quyền truy cập\n+ Tạo IAM Policy\n+ Gán Policy\n+ Kiểm tra truy cập 03/11/2025 03/11/2025 https://000074.awsstudygroup.com/ https://000075.awsstudygroup.com/ 3 - Tìm hiểu và thực hành quản lý tài nguyên và chi phí bằng IAM trên AWS + Giới hạn theo Region + Giới hạn theo họ EC2 + Giới hạn theo kích thước Instance + Giới hạn theo dung lượng EBS Volume 04/11/2025 04/11/2025 https://000064.awsstudygroup.com/ 4 - Thực hành tự động hóa sao lưu và lưu trữ snapshot bằng Data Lifecycle Manager + Sử dụng lịch trình một chính sách (Single Policy Schedule) + Sử dụng nhiều lịch trình (Multiple Policy Schedules) + Kiểm tra kết quả 05/11/2025 05/11/2025 https://000088.awsstudygroup.com/ 5 - Thực hành phát hiện bất thường trong sao lưu AWS Backup cho EBS Volumes + Chuẩn bị S3, EBS, CloudFormation + Kiểm tra tài nguyên đã tạo + Tạo bản sao lưu (Backup) 06/11/2025 06/11/2025 https://000089.awsstudygroup.com/ 6 - Thực hành AWS Toolkit cho VS Code: Amazon Q \u0026amp; CodeWhisperer + Cài đặt AWS Toolkit for Visual Studio Code + Kết nối tài khoản AWS + Thay đổi vùng (Region) + Xác thực người dùng (Authentication) + Tương tác với các dịch vụ AWS (Interacting with Services) 07/11/2025 07/11/2025 https://000087.awsstudygroup.com/ Kết quả đạt được trong Tuần 9: Tạo và kích hoạt thành công VPC Flow Logs để giám sát lưu lượng mạng Phân quyền truy cập bảng điều khiển thanh toán bằng IAM Roles và Policies tùy chỉnh Cấu hình giới hạn tài nguyên sử dụng theo Region, loại Instance, và dung lượng EBS Tự động hóa việc tạo và lưu trữ snapshot bằng Data Lifecycle Manager Thực hiện phát hiện bất thường trong sao lưu (Backup Anomaly Detection) cho EBS Kết nối tài khoản AWS với VS Code Toolkit, trải nghiệm Amazon Q và CodeWhisperer để hỗ trợ phát triển "
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/2-proposal/",
	"title": "Đề xuất Dự Án Hệ Thống Giám Sát &amp; Cảnh Báo An Toàn IoT",
	"tags": [],
	"description": "",
	"content": "1. Tổng Quan Dự Án Tên Dự Án Hệ Thống Giám Sát \u0026amp; Cảnh Báo An Toàn IoT Cho Smart Home Trên Nền Tảng AWS Mô Tả Dự Án Phát triển hệ thống giám sát và cảnh báo an toàn IoT toàn diện cho ngôi nhà thông minh, kết hợp tích hợp sensor phần cứng, giao thức bảo mật tiên tiến, kiến trúc backend serverless và dashboard trực quan real-time. Hệ thống cung cấp khả năng giám sát end-to-end các thông số môi trường (nhiệt độ, độ ẩm, phát hiện khí gas, chuyển động) với các biện pháp bảo mật mạnh mẽ và phân tích dữ liệu trên cloud.\nThông Tin Đội Ngũ Quy Mô Đội: 5 thành viên (sinh viên năm 3 đại học) Cấu Trúc Đội: 2 Kỹ Sư IC Design (Chuyên gia Hardware/Firmware) 2 Kỹ Sư Phần Mềm (Chuyên gia Backend/Frontend) 1 Chuyên Gia Bảo Mật (Expert Cybersecurity \u0026amp; PKI) Thời Gian Thực Hiện 3 tháng (Tháng 9/2025 - Tháng 11/2025)\nTổng Ngân Sách $100 USD phân bổ cho hai thành phần chính:\nPhát triển WebApp: $10 IoT Hardware \u0026amp; Firmware: $40 Quy Mô Ứng Dụng Smart Home - Một ngôi nhà tiêu biểu với 3 sensor nodes phủ sóng các khu vực quan trọng.\n2. Mục Tiêu Dự Án Mục Tiêu Chính Phát triển hệ sinh thái IoT cho giám sát smart home Triển khai hệ thống giám sát real-time cho các thông số môi trường và an toàn Tạo backend serverless có khả năng mở rộng sử dụng các dịch vụ AWS được quản lý Xây dựng giao diện dashboard trực quan cho giám sát và quản lý thiết bị Chỉ Số Thành Công Chính Kết Nối Thiết Bị: 99.9% uptime cho kết nối thiết bị IoT Hiệu Suất Real-time: \u0026lt;100ms độ trễ cho cảnh báo quan trọng Trải Nghiệm Người Dùng: Dashboard responsive có thể truy cập trên web và mobile Hiệu Quả Chi Phí: Giữ trong ngân sách $100 trong khi đạt được production-ready prototype 3. Kiến Trúc Kỹ Thuật 3.1 Lớp Phần Cứng (Thiết Bị IoT) Vi Điều Khiển: ESP32 với khả năng WiFi tích hợp Cảm Biến: Nhiệt độ/độ ẩm (DHT11), Phát hiện khí gas (MQ series), Cảm biến lửa MKE-S04 IR Giao Tiếp: MQTT over TLS 1.3 cho truyền dữ liệu an toàn 3.2 Tích Hợp Dịch Vụ AWS Cloud Dịch Vụ Mục Đích Chi Phí Ước Tính Hàng Tháng AWS IoT Core Gateway thiết bị và messaging $3-8 (cho smart home) AWS IoT Rules Định tuyến và lọc thông điệp Miễn phí AWS Lambda Logic business serverless $10.25 Amazon DynamoDB Database NoSQL cho dữ liệu sensor $0.36 Amazon S3 Lưu trữ và sao lưu dữ liệu $1-2 Amazon SES Dịch vụ gửi email thông báo $1-2 API Gateway Endpoints RESTful API $6.25 Amazon Cognito Xác thực và phân quyền người dùng $1-2 AWS Amplify Hosting frontend và CI/CD $1-2 Amazon Route 53 Quản lý DNS và domain $1-2 3.3 Sơ Đồ Kiến Trúc Hệ Thống 4. Phân Tích Ngân Sách 4.1 Phát Triển WebApp ($10) Framework Frontend: Công cụ phát triển React.js/Vue.js - free Testing \u0026amp; Deployment: AWS S3/CloudFront hosting - $10 Thư Viện Phát Triển: Chart.js, Material-UI, WebSocket libraries - free Tài Liệu \u0026amp; Đào Tạo: Tài nguyên technical writing - free 4.2 IoT Hardware \u0026amp; Firmware ($40) Board Phát Triển: 3x ESP32 development kits cho smart home - $15 Cảm Biến \u0026amp; Linh Kiện: Sensor nhiệt độ, độ ẩm, khí gas, chuyển động - $10 Nguồn Điện \u0026amp; Vỏ Bảo Vệ: Housing và quản lý nguồn - $10 Linh Kiện Kết Nối: WiFi modules và antenna - $5 5. Kế Hoạch Thực Hiện Giai Đoạn 1: Nền Tảng (Tháng 1) Tuần 1-2: Kiến Trúc \u0026amp; Lập Kế Hoạch Thiết kế kiến trúc hệ thống và tài liệu hóa Setup tài khoản AWS và cấu hình dịch vụ Chuẩn bị môi trường phát triển Đào tạo đội ngũ về AWS services và giao thức bảo mật Tuần 3-4: Phát Triển Cốt Lõi Thiết kế sơ đồ hardware và sourcing linh kiện Phát triển firmware cơ bản cho tích hợp sensor Thiết kế backend API và các Lambda function ban đầu Thiết kế database schema Giai Đoạn 2: Tích Hợp (Tháng 2) Tuần 5-6: Tích Hợp Hardware-Software Lắp ráp linh kiện Triển khai communication từ thiết bị lên cloud Phát triển pipeline dữ liệu real-time Setup xác thực người dùng Tuần 7-8: Phát Triển Frontend Thiết kế UI/UX dashboard Phát triển dashboard frontend Triển khai responsive cho mobile Giai Đoạn 3: Testing \u0026amp; Deployment (Tháng 3) Tuần 9-10: Testing Tích Hợp Hệ Thống Testing và validation hệ thống end-to-end Tối ưu hiệu suất và load testing User acceptance testing và tích hợp feedback Sửa lỗi và cải tiến Tuần 11-12: Chuẩn Bị Sản Xuất Hoàn thiện tài liệu Production deployment và setup monitoring Validation hệ thống cuối cùng Chuẩn bị presentation và demonstration dự án 6. Sản Phẩm Bàn Giao 6.1 Sản Phẩm Hardware IoT Sensor Boards: 12 prototype hoàn chính với sensor tích hợp cho smart home Tài Liệu Hardware: Schematics và hướng dẫn lắp ráp Hướng Dẫn Manufacturing: Tài liệu sẵn sàng sản xuất để scale-up 6.2 Sản Phẩm Software Backend API: RESTful services với tài liệu toàn diện Frontend Dashboard: Ứng dụng web responsive với giám sát real-time Mobile Interface: Progressive Web App (PWA) cho truy cập mobile device Database Schema: Data models tối ưu cho dữ liệu time-series sensor 7. Đánh Giá Rủi Ro \u0026amp; Giảm Thiểu 7.1 Rủi Ro Kỹ Thuật Rủi Ro Tác Động Xác Suất Chiến Lược Giảm Thiểu Delay linh kiện hardware Cao Trung bình Order sớm, duy trì backup suppliers Vượt chi phí AWS service Trung bình Thấp Monitoring chi phí, sử dụng free tier hiệu quả Phát hiện lỗ hổng bảo mật Cao Thấp Testing bảo mật thường xuyên, follow AWS best practices Độ phức tạp integration Trung bình Trung bình Integration từng bước, comprehensive testing 7.2 Rủi Ro Quản Lý Dự Án Rủi Ro Tác Động Xác Suất Chiến Lược Giảm Thiểu Thành viên team không có sẵn Trung bình Thấp Cross-training, documentation, backup assignments Delay timeline Trung bình Trung bình Buffer time allocation, milestone tracking Ràng buộc ngân sách Cao Thấp Weekly budget tracking, cost optimization 8. Kết Quả Mong Đợi \u0026amp; Tác Động 8.1 Thành Tựu Kỹ Thuật Hệ Thống IoT Hoạt Động: production-ready prototype thể hiện tất cả tính năng chính Hiệu Suất Real-time: Thời gian phản hồi dưới giây cho cảnh báo và thông báo quan trọng Kiến Trúc Có Khả Năng Mở Rộng: Thiết kế cloud-native sẵn sàng mở rộng 8.2 Kết Quả Học Tập Kiến Trúc Cloud: Trải nghiệm thực tế với AWS services và serverless computing Phát Triển IoT: Hiểu biết về tích hợp thiết bị IoT và phát triển firmware Full-Stack Development: Trải nghiệm complete software development lifecycle Quản Lý Dự Án: Kinh nghiệm thực tế trong agile development và team collaboration 8.3 Ứng Dụng Tương Lai Quản Lý Smart Home: Giám sát môi trường cho nhà ở thông minh IoT Thương Mại: Hệ thống giám sát thiết bị và predictive maintenance Healthcare Monitoring: Tracking môi trường bệnh nhân và thiết bị y tế Giám Sát Môi Trường: Mạng giám sát chất lượng không khí và khí hậu 9. Kết Luận Dự án Hệ Thống Giám Sát \u0026amp; Cảnh Báo An Toàn IoT này thể hiện cách tiếp cận toàn diện đến phát triển IoT hiện đại, kết hợp thiết kế hardware tiên tiến, giao thức bảo mật mạnh mẽ, và kiến trúc cloud có khả năng mở rộng. Với ngân sách $100 và timeline 3 tháng, đội ngũ 5 sinh viên tận tụy sẽ giao một production-ready prototype thể hiện best practices trong IoT security, cloud computing, và full-stack development.\nDự án không chỉ phục vụ như một trải nghiệm học tập xuất sắc mà còn tạo ra nền tảng cho các ứng dụng thực tế trong smart home, giám sát công nghiệp, và bảo vệ môi trường. Bằng cách tận dụng AWS managed services và tập trung vào nguyên tắc thiết kế security-first, chúng tôi hướng đến tạo ra một hệ thống đáp ứng cả nhu cầu hiện tại và yêu cầu scalability tương lai.\nThông Tin Liên Hệ Dự Án:\nProject Manager: Trần Quang Huy Security Lead: Trần Quang Huy Email: huytqse182122@fpt.edu.vn Project Repository: https://github.com/saltless-bruh/D2F_FCJ Đề xuất này được gửi để xem xét và phê duyệt. Chúng tôi mong được cơ hội thể hiện khả năng kỹ thuật và giao kết quả xuất sắc trong timeline và ngân sách đề xuất.\nTài Liệu Dự Án Tài Liệu Liên Quan\rD2F_FCJ_Proposal.docx\r(229 ko)\r"
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/5-workshop/5.2-prerequiste/",
	"title": "Kết nối ESP32 với IoT Core",
	"tags": [],
	"description": "",
	"content": "Kết nối ESP32 với AWS IoT Core Trong lab này, chúng ta sẽ làm việc tại Region Singapore – ap-southeast-1.\nĐể chuẩn bị môi trường workshop, hãy tạo IoT Core Thing theo đường link sau (nhấp vào để mở):\nESP32_01 Thing\nKhi triển khai, giữ nguyên các cấu hình mặc định.\nChọn IoT Core Chọn Create Things Chọn Create single thing Chọn Next Nhập tên thiết bị (Thing Name) cho ESP32 Chọn Next Chọn Recommended Option Chọn Next Chọn Create Policy Chọn Next Đặt tên Policy Chọn Add Four New Statements Dựa vào đoạn Code mẫu để điền Resource Name Chọn Policy Action như hình mẫu Điền Policy Resource theo thông tin của bạn Chọn Create Chọn Create Policy Chọn policy vừa tạo ESP32_POLICY Chọn Create thing 🟦 Thêm mã nguồn kết nối ESP32 với AWS IoT Core Sao chép đoạn code sau và cập nhật thông tin Wi-Fi, Endpoint, Certificate:\n{ #ifndef AWS_CONFIG_H #define AWS_CONFIG_H #include \u0026lt;pgmspace.h\u0026gt; // ======================= Wi-Fi ======================= #define WIFI_SSID \u0026#34;ABC\u0026#34; // Tên Wi-Fi của bạn #define WIFI_PASSWORD \u0026#34;***\u0026#34; // Mật khẩu Wi-Fi // ================== AWS IoT Core ===================== // Endpoint của IoT Core (Lấy trong AWS console) #define AWS_IOT_ENDPOINT \u0026#34;\u0026#34; // Tên thiết bị phải trùng với Thing Name #define AWS_IOT_CLIENT_ID \u0026#34;ESP32_01\u0026#34; // Topics đúng với policy của bạn #define AWS_IOT_PUBLISH_TOPIC \u0026#34;esp32/pub\u0026#34; #define AWS_IOT_SUBSCRIBE_TOPIC \u0026#34;esp32/sub\u0026#34; // CA Root static const char AWS_CERT_CA[] PROGMEM = R\u0026#34;EOF( )EOF\u0026#34;; // Device Certificate static const char AWS_CERT_CRT[] PROGMEM = R\u0026#34;KEY( )KEY\u0026#34;; // Private Key static const char AWS_CERT_PRIVATE[] PROGMEM = R\u0026#34;KEY( )KEY\u0026#34;; #endif } "
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/1-worklog/1.10-week10/",
	"title": "Nhật ký công việc Tuần 10",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Tuần 10: Hiểu và thực hành các chủ đề bảo mật AWS, bao gồm giới hạn vai trò, Security Hub và KMS. Kích hoạt, sử dụng và phân tích các phát hiện từ AWS Security Hub để đánh giá mức độ tuân thủ và tình trạng bảo mật. Triển khai mã hóa dữ liệu khi lưu trữ bằng AWS KMS trên các dịch vụ như Amazon S3, AWS CloudTrail và Amazon Athena. Các nhiệm vụ trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Tìm hiểu về IAM Permission Boundary + Tạo Restriction Policy + Tạo IAM Limited User + Kiểm tra giới hạn quyền của IAM User 10/11/2025 10/11/2025 https://000030.awsstudygroup.com/ 3 - Thực hành tạo Role và tăng cường bảo mật bằng cách đặt giới hạn theo địa chỉ IP và thời gian + Tạo IAM Group + Tạo IAM User + Tạo Admin IAM Role + Cấu hình Switch Role + Giới hạn quyền truy cập Role 11/11/2025 11/11/2025 https://000044.awsstudygroup.com/ 4 - Bắt đầu với AWS Security Hub + Kích hoạt Security Hub + Xem điểm số cho từng bộ tiêu chí 12/11/2025 12/11/2025 https://000018.awsstudygroup.com/ 5 - Mã hóa dữ liệu khi lưu trữ bằng AWS KMS + Tạo Key Management Service + Tạo Amazon S3 + Tạo AWS CloudTrail và Amazon Athena + Kiểm tra và chia sẻ dữ liệu đã mã hóa trên S3 13/11/2025 13/11/2025 https://cloudjourney.awsstudygroup.com/ Thành tựu Tuần 10: Đã cấu hình IAM Permission Boundaries bằng cách tạo Restriction Policy, tạo IAM Limited User và kiểm tra việc giới hạn quyền được áp dụng chính xác. Đã tạo IAM Roles, Groups và Users; áp dụng các giới hạn bổ sung như lọc theo địa chỉ IP và giới hạn theo thời gian; và cấu hình chuyển đổi Role. Đã kích hoạt AWS Security Hub, xem điểm đánh giá và phân tích các phát hiện từ nhiều bộ tiêu chí bảo mật khác nhau. Đã tạo và cấu hình KMS Key, áp dụng mã hóa dữ liệu lưu trữ cho Amazon S3, bật CloudTrail logging, truy vấn nhật ký bằng Athena và kiểm thử chia sẻ dữ liệu đã mã hóa trên S3. "
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/1-worklog/1.11-week11/",
	"title": "Nhật ký công việc Tuần 11",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 11: Thực hành sử dụng Amazon S3 và Amazon Macie để phân loại và bảo vệ dữ liệu Triển khai AWS Cognito trên nhiều site để quản lý xác thực tập trung Làm quen với AWS Backup để tạo kế hoạch sao lưu, cài đặt thông báo và thử nghiệm phục hồi dữ liệu Thực hành thiết lập kết nối VPC Peering giữa hai VPC Học và triển khai các biện pháp bảo mật tốt nhất cho Amazon S3, bao gồm mã hóa, kiểm soát truy cập và bắt buộc HTTPS Các nhiệm vụ trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Thực hành sử dụng S3 và Amazon Macie + Chuẩn bị S3 và bật Macie + Tạo Custom data identifiers + Tạo một Macie job + Chạy Macie job và kiểm tra kết quả 17/11/2025 17/11/2025 https://000090.awsstudygroup.com/ 3 - Triển khai AWS Cognito trên nhiều site + Chuẩn bị tài nguyên + Giải thích về code + Triển khai và kiểm tra Cognito Cross Sites 18/11/2025 18/11/2025 https://000141.awsstudygroup.com/ 4 - Làm quen với AWS Backup + Chuẩn bị S3 và triển khai hạ tầng + Tạo kế hoạch sao lưu + Cài đặt thông báo + Thử nghiệm phục hồi dữ liệu 19/11/2025 19/11/2025 https://000013.awsstudygroup.com/ 5 - Thực hành thiết lập VPC Peering giữa hai VPC + Chuẩn bị CloudFormation Template, SG, EC2 + Cập nhật Network ACL + VPC Peering + Cập nhật Route Tables + Thiết lập Cross-Peer DNS 20/11/2025 20/11/2025 https://000019.awsstudygroup.com/ 6 - Thực hành các biện pháp bảo mật tốt nhất để bảo vệ dữ liệu trên Amazon S3 + Chuẩn bị CloudFormation Template, thiết lập mạng an toàn, tạo access key, EC2, S3 + Bắt buộc HTTPS + Bắt buộc mã hóa SSE-S3 + Chặn Public ACLs + Cấu hình S3 Block Public Access + Giới hạn truy cập qua S3 VPC Endpoint 21/11/2025 21/11/2025 https://000069.awsstudygroup.com/ Thành tựu tuần 11: Cấu hình thành công S3 và Amazon Macie, tạo custom data identifiers, chạy Macie job và kiểm tra kết quả Triển khai và kiểm tra AWS Cognito trên nhiều site, đảm bảo xác thực và quản lý truy cập chính xác Tạo kế hoạch sao lưu với AWS Backup, cài đặt thông báo và thử nghiệm phục hồi dữ liệu thành công Thiết lập kết nối VPC Peering giữa hai VPC, cập nhật route tables, network ACLs và bật Cross-VPC DNS resolution Triển khai các biện pháp bảo mật S3: bắt buộc HTTPS, bật SSE-S3 encryption, chặn public ACLs, cấu hình S3 Block Public Access và giới hạn truy cập qua VPC Endpoint "
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/1-worklog/1.12-week12/",
	"title": "Nhật ký công việc Tuần 12",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Tuần 12: Thực hành kết nối nhiều VPC bằng AWS Transit Gateway, bao gồm tạo attachments và cấu hình route tables. Hiểu và thực hành các mô hình tối ưu chi phí của AWS: Savings Plans, Reserved Instances và Reserved DB Instances. Thực hành phân quyền truy cập Billing Console bằng IAM: tạo Group, Policy và kiểm thử quyền truy cập. Tìm hiểu và thực hành các thao tác cơ bản với Amazon DynamoDB: tạo bảng, đọc/ghi dữ liệu, cập nhật, truy vấn, tạo Global Secondary Index và sử dụng AWS CLI trong CloudShell để thao tác. Các nhiệm vụ thực hiện trong tuần này: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Sử dụng AWS Transit Gateway để kết nối nhiều VPC + Tạo Transit Gateway + Tạo Transit Gateway Attachments + Tạo Transit Gateway Route Tables + Thêm tuyến Transit Gateway vào Route Tables của VPC 24/11/2025 24/11/2025 https://000020.awsstudygroup.com/ 3 - Thực hành Savings Plans, Reserved Instance và Reserved DB Instance + Savings Plans Recommendation + Mua Savings Plans + Reserved Instance + Reserved DB Instances 25/11/2025 25/11/2025 https://000042.awsstudygroup.com/ 4 - Thực hành phân quyền truy cập Billing Console\n+ Tạo IAM User Group\n+ Bật quyền truy cập\n+ Tạo IAM Policy\n+ Gán Policy\n+ Kiểm thử quyền truy cập 26/11/2025 26/11/2025 https://000075.awsstudygroup.com/ 5 - Tìm hiểu và thực hành Amazon DynamoDB\n+ Tạo bảng + Ghi dữ liệu + Đọc dữ liệu + Cập nhật dữ liệu + Truy vấn dữ liệu + Tạo Global Secondary Index + Truy vấn GSI + Sử dụng AWS CloudShell + Cấu hình AWS CLI 27/11/2025 27/11/2025 https://000060.awsstudygroup.com/ Thành tựu Tuần 12: Tạo thành công AWS Transit Gateway, cấu hình attachments, tạo bảng định tuyến Transit Gateway và cập nhật route tables của VPC để kết nối nhiều VPC với nhau. Phân tích và áp dụng Savings Plans Recommendations, mua Savings Plans, thực hành tạo Reserved Instances và Reserved DB Instances nhằm tối ưu chi phí. Thiết lập phân quyền Billing Console bằng IAM: tạo nhóm người dùng, bật quyền truy cập, tạo IAM Policy tùy chỉnh, gán Policy và kiểm thử truy cập thành công. Thực hành với Amazon DynamoDB: tạo bảng, chèn dữ liệu, đọc và truy vấn dữ liệu, cập nhật mục dữ liệu, tạo và truy vấn Global Secondary Index; đồng thời sử dụng CloudShell và AWS CLI để thao tác DynamoDB qua dòng lệnh. "
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/3-blogstranslated/",
	"title": "Các bài blogs đã dịch",
	"tags": [],
	"description": "",
	"content": "Blog 1 - Heroku di chuyển cơ sở dữ liệu PostgreSQL sang Amazon Aurora Bài blog này giải thích cách Heroku di chuyển hàng trăm nghìn cơ sở dữ liệu PostgreSQL tự quản trên Amazon EC2 sang Amazon Aurora PostgreSQL-Compatible Edition. Bạn sẽ tìm hiểu những thách thức khi quản lý các hệ thống cơ sở dữ liệu quy mô lớn, cách Aurora giảm gánh nặng vận hành đồng thời tăng độ tin cậy và khả năng mở rộng, và cách Heroku sử dụng công cụ di chuyển song song cùng kiểm thử kỹ lưỡng để chuyển dữ liệu mà ảnh hưởng tối thiểu tới khách hàng. Bài viết cũng nêu các lợi ích của kiến trúc mới, bao gồm tăng khả năng quan sát, tính năng AI cho quản trị cơ sở dữ liệu, và gần như không gián đoạn dịch vụ.\nBlog 2 - Đẩy nhanh nghiên cứu Alzheimer thông qua phân tích bộ gen chức năng quy mô lớn với AWS Cloud Bài blog này cho thấy cách phòng thí nghiệm của Tiến sĩ Gao Wang tại Đại học Columbia sử dụng điện toán đám mây AWS để thúc đẩy nghiên cứu Alzheimer thông qua genomics chức năng. Bạn sẽ tìm hiểu cách phân tích QTL phân tử quy mô lớn giúp khám phá cơ chế di truyền của Alzheimer, cách các công cụ đám mây như MMCloud và EC2 Spot Instances cho phép xử lý song song hàng trăm nghìn công việc, đồng thời tăng tốc khám phá, giảm chi phí và hỗ trợ hợp tác toàn cầu. Bài viết còn đề cập việc tích hợp dữ liệu đa omics để xác định mục tiêu trị liệu và các dấu sinh học (biomarkers).\nBlog 3 - AWS Marketplace được đánh giá “Awardable” cho các dự án DoD trong P1 Solutions Marketplace Bài blog này giới thiệu cách AWS Marketplace đạt trạng thái “Awardable” trong Platform One (P1) Solutions Marketplace của Bộ Quốc phòng Mỹ (DoD). Bạn sẽ tìm hiểu cách trạng thái này giúp các tổ chức DoD truy cập dễ dàng hơn hơn 4.000 giải pháp đã được xác minh, tăng tốc triển khai công nghệ, đảm bảo tuân thủ quy định mua sắm liên bang, tập trung quản lý giấy phép và hóa đơn, đồng thời tối ưu chi phí CNTT. Bài viết cũng minh họa cách AWS Marketplace hỗ trợ các nhiệm vụ quốc phòng quan trọng bằng việc kết nối DoD với các công nghệ thương mại tiên tiến.\n"
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/5-workshop/5.3-s3-vpc/",
	"title": "Kết nối IoT Core với DynamoDB",
	"tags": [],
	"description": "",
	"content": "Sử dụng IoT Rule Trong phần này, bạn sẽ tạo bảng DynamoDB để lưu dữ liệu từ ESP32.\nChọn Create Rule Đặt tên cho Rule Chọn Next Nhập câu lệnh SQL SELECT * FROM \u0026rsquo;esp32/pub\u0026rsquo; Tại Action 1, chọn DynamoDB Chọn Create DynamoDB Table để tạo bảng Chọn Create Table Chọn Keys đúng với table details (Partition Key / Sort Key nếu có) Quay lại Rule → chọn Create New Rule Đặt tên Rule → chọn Create Chọn Next Chọn Explore Item để xem dữ liệu đã được lưu "
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/4-eventparticipated/",
	"title": "Các events đã tham gia",
	"tags": [],
	"description": "",
	"content": "Trong quá trình thực tập, em đã tham gia 4 events, với mỗi event là một trải nghiệm đáng nhớ với những kiến thức mới, hay và bổ ích, cùng với đó là nhứng món quà và những khoảnh khắc rất tuyệt vời.\nEvent 1 Tên sự kiện: Vietnam Cloud Day 2025 : Ho Chi Minh City Connect Edition for Builders\nThời gian: 09:00 ngày 18/09/2025\nĐịa điểm: Tầng 26 \u0026amp; 36, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 2 Tên sự kiện: AI/ML/GenAI on AWS Workshop (AWS Cloud Mastery Series #1)\nThời gian: 09:00 ngày 15/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 3 Tên sự kiện: ​DevOps on AWS AWS Cloud Mastery Series #2\nThời gian: 08:30 ngày 17/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 4 Tên sự kiện: AWS Well-Architected Security Pillar AWS Cloud Mastery Series #3\nThời gian: 08:30 ngày 29/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\n"
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/5-workshop/",
	"title": "Workshop",
	"tags": [],
	"description": "",
	"content": "Kết nối ESP32 với AWS IoT Core \u0026amp; Lưu trữ dữ liệu vào DynamoDB Overview AWS IoT Core cho phép thiết bị IoT như ESP32 kết nối an toàn với AWS Cloud thông qua MQTT. Khi kết hợp với DynamoDB, dữ liệu từ thiết bị có thể được lưu trữ và phân tích một cách linh hoạt, phục vụ cho các ứng dụng IoT thực tế.\nTrong workshop này, bạn sẽ học cách:\nKết nối ESP32 với AWS IoT Core bằng MQTT và Certificate. Publish dữ liệu từ ESP32 lên Cloud. Sử dụng IoT Rule để ghi dữ liệu vào DynamoDB. Bạn sẽ thực hiện hai phần chính:\nESP32 → IoT Core – Đăng ký thiết bị, tạo certificate, lập trình ESP32 gửi dữ liệu cảm biến. IoT Core → DynamoDB – Tạo DynamoDB table, cấu hình IoT Rule để lưu data tự động. Content Workshop overview Prerequisite Connect ESP32 with AWS IoT Core Clean up "
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/5-workshop/5.6-cleanup/",
	"title": "Dọn dẹp tài nguyên",
	"tags": [],
	"description": "",
	"content": "Dọn dẹp tài nguyên Để tránh phát sinh chi phí sau khi kết thúc buổi lab, hãy tiến hành xóa các tài nguyên đã tạo.\n1. Xóa thiết bị trong AWS IoT Core Mở AWS IoT Core Vào Manage → Things Chọn ESP32 Thing đã tạo Chọn Delete Xóa kèm Certificate \u0026amp; Policy liên quan 2. Xóa Rule IoT Vào Message Routing → Rules Chọn Rule đã tạo Chọn Delete Rule 3. Xóa bảng DynamoDB Mở DynamoDB Chọn Tables Chọn bảng dữ liệu được tạo trong lab Chọn Delete Table "
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/6-self-evaluation/",
	"title": "Tự đánh giá",
	"tags": [],
	"description": "",
	"content": "Trong suốt thời gian thực tập tại Công ty TNHH Amazon Web Services Vietnam từ 08/09/2025 đến 08/12/2025, tôi đã có cơ hội học hỏi, rèn luyện và áp dụng kiến thức đã được trang bị tại trường vào môi trường làm việc thực tế.\nTôi đã tham gia tìm hiểu và thực hành về cloud và các dịch vụ của AWS, qua đó cải thiện kỹ năng lập trình, sử dụng dịch vụ của AWS, viết báo cáo, giao tiếp….\nVề tác phong, tôi luôn cố gắng hoàn thành tốt nhiệm vụ, tuân thủ nội quy, và tích cực trao đổi với đồng nghiệp để nâng cao hiệu quả công việc.\nĐể phản ánh một cách khách quan quá trình thực tập, tôi xin tự đánh giá bản thân dựa trên các tiêu chí dưới đây:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết về ngành, áp dụng kiến thức vào thực tế, kỹ năng sử dụng công cụ, chất lượng công việc ☐ ✅ ☐ 2 Khả năng học hỏi Tiếp thu kiến thức mới, học hỏi nhanh ☐ ✅ ☐ 3 Chủ động Tự tìm hiểu, nhận nhiệm vụ mà không chờ chỉ dẫn ☐ ✅ ☐ 4 Tinh thần trách nhiệm Hoàn thành công việc đúng hạn, đảm bảo chất lượng ☐ ✅ ☐ 5 Kỷ luật Tuân thủ giờ giấc, nội quy, quy trình làm việc ☐ ✅ ☐ 6 Tính cầu tiến Sẵn sàng nhận feedback và cải thiện bản thân ☐ ✅ ☐ 7 Giao tiếp Trình bày ý tưởng, báo cáo công việc rõ ràng ☐ ✅ ☐ 8 Hợp tác nhóm Làm việc hiệu quả với đồng nghiệp, tham gia nhóm ✅ ☐ ☐ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, đối tác, môi trường làm việc ✅ ☐ ☐ 10 Tư duy giải quyết vấn đề Nhận diện vấn đề, đề xuất giải pháp, sáng tạo ☐ ✅ ☐ 11 Đóng góp vào dự án/tổ chức Hiệu quả công việc, sáng kiến cải tiến, ghi nhận từ team ✅ ☐ ☐ 12 Tổng thể Đánh giá chung về toàn bộ quá trình thực tập ☐ ✅ ☐ Cần cải thiện Nâng cao tính kỹ luật, chấp hành nghiêm chỉnh nội quy của công ty hoặc bất kỳ trong một tổ chức nào Cải thiện trong cách tư duy giải quyết vấn đề Học cách giao tiếp tốt hơn trong giao tiếp hằng ngày và trong công việc, xử lý tình huống "
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/7-feedback/",
	"title": "Chia sẻ, đóng góp ý kiến",
	"tags": [],
	"description": "",
	"content": "Đánh giá chung 1. Môi trường làm việc\nMôi trường làm việc rất thân thiện và cởi mở. Các thành viên trong FCJ luôn sẵn sàng hỗ trợ khi mình gặp khó khăn, kể cả ngoài giờ làm việc. Không gian làm việc gọn gàng, thoải mái, giúp mình tập trung tốt hơn. Tuy nhiên, mình nghĩ có thể bổ sung thêm một số buổi giao lưu hoặc team bonding để mọi người hiểu nhau hơn.\n2. Sự hỗ trợ của mentor / team admin\nMentor hướng dẫn rất chi tiết, giải thích rõ ràng khi mình chưa hiểu và luôn khuyến khích mình đặt câu hỏi. Team admin hỗ trợ các thủ tục, tài liệu và tạo điều kiện để mình làm việc thuận lợi. Mình đánh giá cao việc mentor cho phép mình thử và tự xử lý vấn đề thay vì chỉ đưa đáp án.\n3. Sự phù hợp giữa công việc và chuyên ngành học\nCông việc mình được giao phù hợp với kiến thức mình đã học ở trường, đồng thời mở rộng thêm những mảng mới mà mình chưa từng được tiếp cận. Nhờ vậy, mình vừa củng cố kiến thức nền tảng, vừa học thêm kỹ năng thực tế.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nTrong quá trình thực tập, mình học được nhiều kỹ năng mới như sử dụng công cụ quản lý dự án, kỹ năng làm việc nhóm, và cả cách giao tiếp chuyên nghiệp trong môi trường công ty. Mentor cũng chia sẻ nhiều kinh nghiệm thực tế giúp mình định hướng tốt hơn cho sự nghiệp.\n5. Văn hóa \u0026amp; tinh thần đồng đội\nVăn hóa công ty rất tích cực: mọi người tôn trọng lẫn nhau, làm việc nghiêm túc nhưng vẫn vui vẻ. Khi có dự án gấp, mọi người cùng nhau cố gắng, hỗ trợ không phân biệt vị trí. Điều này giúp mình cảm thấy mình là một phần của tập thể, dù chỉ là thực tập sinh.\n6. Chính sách / phúc lợi cho thực tập sinh\nCông ty có hỗ trợ phụ cấp thực tập và tạo điều kiện về thời gian linh hoạt khi cần thiết. Ngoài ra, việc được tham gia các buổi đào tạo nội bộ là một điểm cộng lớn.\n"
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://phucdat25.github.io/OJT/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]